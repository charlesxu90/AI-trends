title,year,source,authors,class,keywords,abstract,pdf_link,topic,google_scholar_link
Dynamic Dual-Output Diffusion Models,2022,CVPR,Yaniv Benny;Lior Wolf,,,,https://openaccess.thecvf.com/content/CVPR2022/papers/Benny_Dynamic_Dual-Output_Diffusion_Models_CVPR_2022_paper.pdf,diffusion models,https://scholar.google.com/scholar?q=Dynamic+Dual-Output+Diffusion+Models
High-Resolution Image Synthesis With Latent Diffusion Models,2022,CVPR,Robin Rombach;Andreas Blattmann;Dominik Lorenz;Patrick Esser;Bj√∂rn Ommer,,,,https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf,diffusion models,https://scholar.google.com/scholar?q=High-Resolution+Image+Synthesis+With+Latent+Diffusion+Models
Come-Closer-Diffuse-Faster: Accelerating Conditional Diffusion Models for Inverse Problems Through Stochastic Contraction,2022,CVPR,Hyungjin Chung;Byeongsu Sim;Jong Chul Ye,,,,https://openaccess.thecvf.com/content/CVPR2022/papers/Chung_Come-Closer-Diffuse-Faster_Accelerating_Conditional_Diffusion_Models_for_Inverse_Problems_Through_Stochastic_CVPR_2022_paper.pdf,diffusion models,https://scholar.google.com/scholar?q=Come-Closer-Diffuse-Faster:+Accelerating+Conditional+Diffusion+Models+for+Inverse+Problems+Through+Stochastic+Contraction
Perception Prioritized Training of Diffusion Models,2022,CVPR,Jooyoung Choi;Jungbeom Lee;Chaehun Shin;Sungwon Kim;Hyunwoo Kim;Sungroh Yoon,,,,https://openaccess.thecvf.com/content/CVPR2022/papers/Choi_Perception_Prioritized_Training_of_Diffusion_Models_CVPR_2022_paper.pdf,diffusion models,https://scholar.google.com/scholar?q=Perception+Prioritized+Training+of+Diffusion+Models
DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation,2022,CVPR,Gwanghyun Kim;Taesung Kwon;Jong Chul Ye,,,,https://openaccess.thecvf.com/content/CVPR2022/papers/Kim_DiffusionCLIP_Text-Guided_Diffusion_Models_for_Robust_Image_Manipulation_CVPR_2022_paper.pdf,diffusion models,https://scholar.google.com/scholar?q=DiffusionCLIP:+Text-Guided+Diffusion+Models+for+Robust+Image+Manipulation
Vector Quantized Diffusion Model for Text-to-Image Synthesis,2022,CVPR,Shuyang Gu;Dong Chen;Jianmin Bao;Fang Wen;Bo Zhang;Dongdong Chen;Lu Yuan;Baining Guo,,,,https://openaccess.thecvf.com/content/CVPR2022/papers/Gu_Vector_Quantized_Diffusion_Model_for_Text-to-Image_Synthesis_CVPR_2022_paper.pdf,diffusion models,https://scholar.google.com/scholar?q=Vector+Quantized+Diffusion+Model+for+Text-to-Image+Synthesis
Pseudoinverse-Guided Diffusion Models for Inverse Problems,2023,ICLR,"['Jiaming Song', 'Arash Vahdat', 'Morteza Mardani', 'Jan Kautz']",poster,"['diffusion models', 'inverse problems']","Diffusion models have become competitive candidates for solving various inverse problems. Models trained for specific inverse problems work well but are limited to their particular use cases, whereas methods that use problem-agnostic models are general but often perform worse empirically. To address this dilemma, we introduce Pseudoinverse-guided Diffusion Models ($\Pi$GDM), an approach that uses problem-agnostic models to close the gap in performance. $\Pi$GDM directly estimates conditional scores from the measurement model of the inverse problem without additional training. It can address inverse problems with noisy, non-linear, or even non-differentiable measurements, in contrast to many existing approaches that are limited to noiseless linear ones. We illustrate the empirical effectiveness of $\Pi$GDM on several image restoration tasks, including super-resolution, inpainting and JPEG restoration. On ImageNet, $\Pi$GDM is competitive with state-of-the-art diffusion models trained on specific tasks, and is the first to achieve this with problem-agnostic diffusion models. $\Pi$GDM can also solve a wider set of inverse problems where the measurement processes are composed of several simpler ones.",https://api.openreview.net/pdf/210093330709030207aa90dbfe2a1f525ac5fb7d.pdf,diffusion models,https://scholar.google.com/scholar?q=Pseudoinverse-Guided+Diffusion+Models+for+Inverse+Problems
Dual Diffusion Implicit Bridges for Image-to-Image Translation,2023,ICLR,"['Xuan Su', 'Jiaming Song', 'Chenlin Meng', 'Stefano Ermon']",poster,[],"Common image-to-image translation methods rely on joint training over data from both source and target domains. The training process requires concurrent access to both datasets, which hinders data separation and privacy protection; and existing models cannot be easily adapted for translation of new domain pairs. We present Dual Diffusion Implicit Bridges (DDIBs), an image translation method based on diffusion models, that circumvents training on domain pairs. Image translation with DDIBs relies on two diffusion models trained independently on each domain, and is a two-step process: DDIBs first obtain latent encodings for source images with the source diffusion model, and then decode such encodings using the target model to construct target images. Both steps are defined via ordinary differential equations (ODEs), thus the process is cycle consistent only up to discretization errors of the ODE solvers. Theoretically, we interpret DDIBs as concatenation of source to latent, and latent to target Schrodinger Bridges, a form of entropy-regularized optimal transport, to explain the efficacy of the method. Experimentally, we apply DDIBs on synthetic and high-resolution image datasets, to demonstrate their utility in a wide variety of translation tasks and their inherent optimal transport properties.",https://api.openreview.net/pdf/91f1c96de0279c81fb44166262ba54d69daf0fe4.pdf,diffusion models,https://scholar.google.com/scholar?q=Dual+Diffusion+Implicit+Bridges+for+Image-to-Image+Translation
