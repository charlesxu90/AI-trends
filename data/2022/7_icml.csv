title,year,source,authors,class,keywords,abstract,pdf_link
Estimating the Impact of Coordinated Inauthentic Behavior on Content Recommendations in Social Networks,2022,ICML,"['Swapneel S Mehta', 'Atilim Gunes Baydin', 'Bogdan State', 'Richard Bonneau', 'Jonathan Nagler', 'Philip Torr']",oral,"['coordinated inauthentic behavior', 'agent based modeling', 'recommender systems', 'social networks']","Online disinformation is a dynamic and pervasive problem on social networks as evidenced by a spate of public disasters in light of active efforts to combat it.
Since the massive amounts of content generated each day on these platforms is impossible to manually curate, ranking and recommendation algorithms are a key apparatus that drive user interactions.
However, the vulnerability of ranking and recommendation algorithms to attack from coordinated campaigns spreading misleading information has been established both theoretically and anecdotally.
Unfortunately it is unclear how effective countermeasures to disinformation are in practice due to the limited view we have into the operation of such platforms.
We develop a multiagent simulation of a popular social network, Reddit, that aligns with the state-action space available to real users based on the platform's affordances. 
We collect millions of real-world interactions from Reddit to estimate the network for each user in our dataset and utilise Reddit's self-described content ranking strategies to compare the impact of coordinated activity on content spread by each algorithm.
We expect that this will inform the design of robust content distribution systems that are resilient against targeted attacks by groups of malicious actors.
",https://api.openreview.net/pdf/93eb841cc83e32617d408975da07ed6750af898e.pdf
Differentiable agent-based epidemiological modeling for end-to-end learning,2022,ICML,"['Ayush Chopra', 'Alexander Rodríguez', 'Jayakumar Subramanian', 'Balaji Krishnamurthy', 'B. Aditya Prakash', 'Ramesh Raskar']",oral,"['Paper', 'Computational Epidemiology', 'Agent-based Models', 'Differentiable Simulations']","Mechanistic simulators are an indispensable tool for epidemiology to explore the behavior of complex, dynamic infections under varying conditions and navigate uncertain environments. ODE-based models are the dominant paradigm that enable fast simulations and are tractable to gradient-based optimization, but make simplifying assumptions about population homogeneity. Agent-based models (ABMs) are an increasingly popular alternative paradigm that can represent the heterogeneity of contact interactions with granular detail and agency of individual behavior. However, conventional ABM frameworks are not differentiable and present challenges in scalability; due to which it is non-trivial to connect them to auxiliary data sources easily. In this paper we introduce GradABM which is a new scalable, fast and differentiable design for epidemiological ABMs. GradABM runs simulations with million-size populations in few seconds on commodity hardware and enables fast forward and differentiable inverse simulations. This makes it amenable to be merged with deep neural networks and seamlessly integrate heterogeneous data sources to help with calibration, forecasting and policy evaluation. We demonstrate the efficacy of GradABM via extensive experiments with real COVID-19 and influenza datasets. We are optimistic that the current work will bring ABM and AI communities closer together.
",https://api.openreview.net/pdf/ade3d8f88b347878efc3134b538c0b975f736c35.pdf
Exploring social theory integration in agent-based modelling using multi-objective grammatical evolution,2022,ICML,"['Tuong Manh Vu', 'Charlotte Buckley', 'Joao A. Duro', 'Robin C. Purshouse']",oral,"['agent-based modelling', 'inverse generative social science', 'genetic programming', 'grammatical evolution', 'multi-objective evolutionary algorithm']","In Generative Social Science, modellers design agents at the micro-level to generate macro-level a target social phenomenon. In the Inverse Generative Social Science (iGSS), from a target phenomenon, the goal is to search for possible explanatory model structures. This model discovery process is a promising tool to improve the explanatory capability and theory exploration of computational social science. This paper presents a framework for iGSS and applies Grammatical Evolution to an empirically-calibrated agent-based model of alcohol use. Results of the model discovery process find many alternative rules for agent behaviours with different trade-offs. Future work should involve domain experts to evaluate the discovered structures in terms of theoretical credibility and knowledge contribution.",https://api.openreview.net/pdf/35c0914ae05ab49bce622d565760d5c0f693186f.pdf
Evology: an Empirically-Calibrated Market Ecology Agent-Based Model for Trading Strategy Search,2022,ICML,"['Aymeric Vie', 'Maarten Peter Scholl', 'Doyne James Farmer']",oral,"['Agent-Based Model', 'Market Ecology', 'Trading Strategy Search']","Market ecology views financial markets as ecosystems of diverse, interacting and evolving trading strategies. We present a heterogeneous, empirically calibrated multi-agent market ecology agent-based model. We outline its potential as a valuable and challenging training ground for optimising trading strategies using machine learning algorithms and defining research tasks.",https://api.openreview.net/pdf/7d425d16f0efb691dff74189b8842339906d635c.pdf
Towards Better Understanding of Self-Supervised Representations,2022,ICML,"['Neha Mukund Kalibhat', 'Kanika Narang', 'Hamed Firooz', 'Maziar Sanjabi', 'Soheil Feizi']",poster,"['self-supervised learning', 'failure modes', 'interpretability']","Self-supervised learning methods have shown impressive results in downstream classification tasks. However, there is limited work in understanding and interpreting their learned representations. In this paper, we study the representation space of several state-of-the-art self-supervised models including SimCLR, SwaV, MoCo V2 and BYOL. Without the use of class label information, we first discover discriminative features that are highly active for various subsets of samples and correspond to unique physical attributes in images. We show that, using such discriminative features, one can compress the representation space of self-supervised models up to 50% without affecting downstream linear classification significantly. Next, we propose a sample-wise Self-Supervised Representation Quality Score (or, Q-Score) that can be computed without access to any label information. Q-Score, utilizes discriminative features to reliably predict if a given sample is likely to be mis-classified in the downstream classification task achieving AUPRC of 0.91 on SimCLR and BYOL trained on ImageNet-100. Q-Score can also be used as a regularization term to remedy low-quality representations leading up to 8% relative improvement in accuracy on all 4 self-supervised baselines on ImageNet-100, CIFAR-10, CIFAR-100 and STL-10. Moreover, through heatmap analysis, we show that Q-Score regularization enhances discriminative features and reduces feature noise, thus improving model interpretability.",https://api.openreview.net/pdf/1e6dca7498dd2d90dbba51906d9a674dd7f7b13b.pdf
Causal Balancing for Domain Generalization,2022,ICML,"['Xinyi Wang', 'Michael Saxon', 'Jiachen Li', 'Hongyang Zhang', 'Kun Zhang', 'William Yang Wang']",poster,"['domain generalization', 'causality', 'latent variable model', 'spurious correlation']","While machine learning models rapidly advance the state-of-the-art on various real-world tasks, out-of-domain (OOD) generalization remains a challenging problem given the vulnerability of these models to spurious correlations. We propose a causally-motivated balanced mini-batch sampling strategy to train robust classifiers that is minimax optimal across a diverse enough environment space, by utilizing multiple training sets from different environments. We provide an identifiability guarantee of the latent covariates in the proposed causal graph and show that our proposed approach samples train data from a balanced, spurious-free distribution under an ideal scenario. Experiments are conducted on three domain generalization datasets, demonstrating empirically that our balanced mini-batch sampling strategy improves the performance of four different established domain generalization model baselines compared to the random mini-batch sampling strategy. ",https://api.openreview.net/pdf/d3f33bc78391604ae24cdbec4a178bd947c7c097.pdf
In the Eye of the Beholder: Robust Prediction with Causal User Modeling,2022,ICML,"['Amir Feder', 'Guy Horowitz', 'Yoav Wald', 'Roi Reichart', 'Nir Rosenfeld']",poster,"['Invariant Prediction', 'Behavioral User Modeling', 'Bounded Rationality', 'Causal Representation Learning']","Accurately predicting the relevance of items to users is crucial to the success of many social platforms. Conventional approaches train models on logged historical data; but recommendation systems, media services, and online marketplaces all exhibit a constant influx of new content---making relevancy a moving target, to which standard predictive models are not robust. In this paper, we propose a learning framework for relevance prediction that is robust to changes in the data distribution. Our key observation is that robustness can be obtained by accounting for \emph{how users causally perceive the environment}. We model users as boundedly-rational decision makers whose causal beliefs are encoded by a causal graph, and show how minimal information regarding the graph can be used to contend with distributional changes. Experiments in multiple settings demonstrate the effectiveness of our approach.",https://api.openreview.net/pdf/3de06b889d478b026980424d7aa94f0e2a47acb1.pdf
Causal Prediction Can Induce Performative Stability,2022,ICML,['Bogdan Kulynych'],poster,"['performative prediction', 'causal features']","Predictive models affect the world through inducing a strategic response or reshaping the environment in which they are deployed---a property called performativity. This results in the need to constantly adapt and re-design the model. We formalize one possible mechanism through which performativity can arise using the language of causal modeling. We show that using features which form a Markov blanket of the target variable for prediction closes the feedback loop in this setting. Thus, a predictive model that takes as input such causal features might not require any further adaptation after deployment even if it changes the environment.",https://api.openreview.net/pdf/1a0415d75c8525c31b22306ebc9d5c87a0df977b.pdf
Evaluating and Improving Robustness of Self-Supervised Representations to Spurious Correlations,2022,ICML,"['Kimia Hamidieh', 'Haoran Zhang', 'Marzyeh Ghassemi']",poster,"['Representation Learning', 'Self-Supervised Learning', 'Spurious Correlations']","Recent empirical studies have found inductive biases in supervised learning toward simple features that may be spuriously correlated with the label, resulting in suboptimal performance on minority subgroups. Despite the growing popularity of methods which learn representations from unlabeled data, it is unclear how potential spurious features may be manifested in the learnt representations. In this work, we explore whether recent Self-Supervised Learning (SSL) methods would produce representations which exhibit similar behaviors under spurious correlation. First, we show that classical approaches in combating spurious correlations, such as dataset re-sampling during SSL, do not consistently lead to invariant representation. Second, we find that spurious information is represented disproportionately heavily in the later layers of the encoder. Motivated by these findings, we propose a method to remove spurious information from these representations during pre-training, by pruning or re-initializing later layers of the encoder. We find that our method produces representations which outperform the baseline on three datasets, without the need for group or label information during SSL.",https://api.openreview.net/pdf/1addca9f8b8eb53ccb07208f03cf86d68c746bab.pdf
Domain Adaptation under Open Set Label Shift,2022,ICML,"['Saurabh Garg', 'Sivaraman Balakrishnan', 'Zachary Chase Lipton']",poster,"['Domain Adaptation', 'Label shift', 'PU learning', 'deep learning', 'open set domain adaptation', 'identifiability']","We introduce the problem of domain adaptation under Open Set Label Shift (OSLS) where the label distribution can change arbitrarily and a new class may arrive during deployment, but the class-conditional distributions $p(x|y)$ are domain-invariant. The learner's goals here are two-fold: (a) estimate the target label distribution, including the novel class; and (b) learn a target classifier. %for the target domain. First, we establish necessary and sufficient conditions for identifying these quantities. Second, we propose practical methods for both tasks. Unlike typical Open Set Domain Adaptation (OSDA) problems, which tend to be ill-posed and amenable only to heuristics, OSLS offers a well-posed problem amenable to more principled machinery. Experiments across numerous semi-synthetic benchmarks on vision, language, and medical datasets demonstrate that our methods consistently outperform OSDA baselines, achieving $10$--$25\%$ improvements in target domain accuracy. Finally, we analyze the proposed methods,  establishing finite-sample convergence to the true label marginal and convergence to optimal classifier for linear models in a Gaussian setup.",https://api.openreview.net/pdf/9de2fcf9f6b0eecf3893b6541f6b16c5d888d2c7.pdf
Towards Domain Adversarial Methods to Mitigate Texture Bias,2022,ICML,"['Dhruva Kashyap', 'Sumukh K Aithal', 'Rakshith C', 'Natarajan Subramanyam']",poster,"['Generalization', 'Domain Adaptation', 'Shape Texture Bias']","Shape-texture conflict is key to our understanding of the behavior of Convolutional Neural Networks (CNNs) and their observably good performance. This work proposes a domain adversarial training-inspired technique as a novel approach to mitigate texture bias. In our work, instead of looking at the domains as the source from which the images are from, we look at the domains as inherent features of the image.
The model is trained in a method similar to Domain Adversarial training, where we define the source and target domains as the dataset and its augmented versions with minimal texture information (edge maps and stylized images), respectively. We show that using domain invariant learning to capture a prior based on the shape-texture information helps models learn robust representations. We perform extensive experiments on three subsets of ImageNet, namely, ImageNet-20, ImageNet-200, ImageNet-9. The results show that the proposed method outperforms standard Empirical Risk Minimization (ERM) in terms of test accuracy and also as evidenced by the high accuracy on the Out-Of-Distribution (OOD) datasets ImageNet-R and NICO. 
",https://api.openreview.net/pdf/1169309b3736fd20e0aa1029c945d1a0d641441f.pdf
Invariance Discovery for Systematic Generalization in Reinforcement Learning,2022,ICML,"['Mirco Mutti', 'Riccardo De Santi', 'Emanuele Rossi', 'Juan Felipe Calderon', 'Michael M. Bronstein', 'Marcello Restelli']",poster,[],"In the sequential decision making setting, an agent aims to achieve systematic generalization over a large, possibly infinite, set of environments. Such environments are modeled as discrete Markov decision processes with both states and actions represented through a feature vector. The underlying structure of the environments allows the transition dynamics to be factored into two components: one that is environment-specific and another one that is shared. Consider a set of environments that share the laws of motion as an illustrative example. In this setting, the agent can take a finite amount of reward-free interactions from a subset of these environments. The agent then must be able to approximately solve any planning task defined over any environment in the original set, relying on the above interactions only. Can we design a provably efficient algorithm that achieves this ambitious goal of systematic generalization? In this paper, we give a partially positive answer to this question. First, we provide the first tractable formulation of systematic generalization by employing a causal viewpoint. Then, under specific structural assumptions, we provide a simple learning algorithm that allows us to guarantee any desired planning error up to an unavoidable sub-optimality term, while showcasing a polynomial sample complexity.",https://api.openreview.net/pdf/c1dce4f3c73618211aa7493c13e7ee70fbcb7865.pdf
Probing Classifiers are Unreliable for Concept Removal and Detection,2022,ICML,"['Abhinav Kumar', 'Chenhao Tan', 'Amit Sharma']",poster,"['Fairness', 'Probing', 'Null-Space Removal', 'Adversarial Removal', 'Spurious Correlation']","Neural network models trained on text data have been found to encode undesired linguistic or sensitive attributes in their representation. Removing such attributes is non-trivial because of a complex relationship between the attribute, text input, and the learnt representation. Recent work has proposed post-hoc and adversarial methods to remove such unwanted attributes from a model's representation. Through an extensive theoretical and empirical analysis, we show that these methods can be counter-productive: they are unable to remove the attributes entirely, and in the worst case may end up destroying all task-relevant features. The reason is the methods' reliance on a probing classifier as a proxy for the attribute, which we prove is difficult to train correctly in presence of spurious correlation.  ",https://api.openreview.net/pdf/7758b28d61790aba01c4cc4db1b0f0014317bfc1.pdf
Are We Viewing the Problem of Robust Generalisation through the Appropriate Lens?,2022,ICML,"['Mohamed Omran', 'Bernt Schiele']",poster,"['robustness', 'generalisation', 'systematic', 'combinatorial']","We discuss different approaches to the challenge of robust object recognition under distribution shifts. We advocate a view of this challenge that is more closely informed by the problem of visual recognition, and which emphasizes dynamic model behaviour as opposed to centering the statistical properties of training and test distributions. We introduce an experimental setting geared towards developing models that can exhibit robust behaviour in a reliable and scalable manner. We refer to this requirement as ""systematic robustness"", which involves excluding certain combinations of classes and image attributes systematically during training. Unlike prior work which studies systematic generalisation in DNNs or their susceptibility to spurious correlations, we use synthetic operations and data sampling to scale such experiments up to large naturalistic datasets.",https://api.openreview.net/pdf/5286e47701d0e3bc52deda0a8775989cf6e9f7c1.pdf
Monitoring Shortcut Learning using Mutual Information,2022,ICML,"['Mohammed Adnan', 'Yani Ioannou', 'Kenyon Tsai', 'Angus Galloway', 'Hamid Tizhoosh', 'Graham W. Taylor']",poster,"['shortcuts', 'shortcut learning', 'spurious correlation', 'mutual information', 'information theory']","The failure of deep neural networks to generalize to out-of-distribution data is a well-known problem and raises concerns about the deployment of trained networks in safety-critical domains such as healthcare, finance, and autonomous vehicles. We study a particular kind of distribution shift — shortcuts or spurious correlations in the training data. Shortcut learning is often only exposed when models are evaluated on real-world data that does not contain the same spurious correlations, posing a serious dilemma for AI practitioners to properly assess the effectiveness of a trained model for real-world applications. In this work, we propose to use the mutual information (MI) between the learned representation and the input as a metric to find where in training the network latches onto shortcuts. Experiments demonstrate that MI can be used as a domain-agnostic metric for detecting shortcut learning.",https://api.openreview.net/pdf/f76547de8313f926b41667a7f9d43561b40bd7b8.pdf
Selection Bias Induced Spurious Correlations in Large Language Models,2022,ICML,['Emily McMilin'],poster,"['spurious correlations', 'large language models', 'causal inference']","In this work we show how large language models (LLMs) can learn statistical dependencies between otherwise unconditionally independent variables due to dataset selection bias. To demonstrate the effect, we developed a masked gender task that can be applied to BERT-family models to reveal spurious correlations between predicted gender pronouns and a variety of seemingly gender-neutral variables like date and location, on pre-trained (unmodified) BERT and RoBERTa large models. Finally, we provide an online demo, inviting readers to experiment further.",https://api.openreview.net/pdf/ece713570db8eebb68eaaebdd685359675f9ab47.pdf
Invariance Principle Meets Out-of-Distribution Generalization on Graphs,2022,ICML,"['Yongqiang Chen', 'Yonggang Zhang', 'Yatao Bian', 'Han Yang', 'MA KAILI', 'Binghui Xie', 'Tongliang Liu', 'Bo Han', 'James Cheng']",poster,"['Graph Neural Networks', 'Out-of-Distribution Generalization', 'Causal Invariance']","Despite recent success in using the invariance principle for out-of-distribution (OOD) generalization on Euclidean data (e.g., images), studies on graph data are still limited. Different from images, the complex nature of graphs poses unique challenges to adopting the invariance principle. In particular, distribution shifts on graphs can appear in a variety of forms such as attributes and structures, making it difficult to identify the invariance. Moreover, domain or environment partitions, which are often required by OOD methods on Euclidean data, could be highly expensive to obtain for graphs. To bridge this gap, we propose a new framework to capture the invariance of graphs for guaranteed OOD generalization under various distribution shifts. Specifically, we characterize potential distribution shifts on graphs with causal models, concluding that OOD generalization on graphs is achievable when models focus only on subgraphs containing the most information about the causes of labels. Accordingly, we propose an information-theoretic objective to extract the desired subgraphs that maximally preserve the invariant intra-class information. Learning with these subgraphs is immune to distribution shifts. Extensive experiments on both synthetic and real-world datasets, including a challenging setting in AI-aided drug discovery, validate the superior OOD generalization ability of our method.",https://api.openreview.net/pdf/736116f2dfef2598ed2641172dcc3c8dfa3174b1.pdf
Latent Variable Models for Bayesian Causal Discovery,2022,ICML,"['Jithendaraa Subramanian', 'Yashas Annadani', 'Ivaxi Sheth', 'Stefan Bauer', 'Derek Nowrouzezahrai', 'Samira Ebrahimi Kahou']",poster,"['Causal representation learning', 'Bayesian Inference', 'latent variable models']","Learning predictors that do not rely on spurious correlations involves building causal representations. However, learning such a representation is very challenging. We, therefore, formulate the problem of learning a causal representation from high dimensional data and study causal recovery with synthetic data. This work introduces a latent variable decoder model, Decoder BCD, for Bayesian causal discovery and performs experiments in mildly supervised and unsupervised settings. We present a series of synthetic experiments to characterize important factors for causal discovery and show that using known intervention targets as labels helps in unsupervised Bayesian inference over structure and parameters of linear Gaussian additive noise latent structural causal models.",https://api.openreview.net/pdf/a6edf5a113a182e98cd92284e3ae5ebf9f6d0f5d.pdf
Understanding Generalization and Robustess of Learned Representations of Chaotic Dynamical Systems,2022,ICML,"['Luã Streit', 'Vikram Voleti', 'Tegan Maharaj']",poster,"['Representation Learning', 'Deep learning', 'Dynamical Systems', 'Generalization', 'Robustness', 'Time Series', 'Ordinary Differential Equations', 'OOD Generalization']","We investigate the generalization capabilities of different methods of learning representations via an extensible synthetic dataset of real-world chaotic dynamical systems introduced by Gilpin (2021).
We propose an evaluation framework built on top of this dataset, called ValiDyna, which uses probes and multi-task learning to study robustness and out-of-distribution (OOD) generalization of learned representations across a range of settings, including changes in losses, architecture, etc. as well as changes in the distribution of the dynamical systems' initial conditions and parameters.
Our evaluation framework is of interest for generalization and robustess broadly, but we focus our assessment here on evaluating learned representations of ecosystem dynamics, with the goal of using these representations in ecological impact assesments, with applications to biodiversity conservation and climate change mitigation.",https://api.openreview.net/pdf/15e67cb8b46cdb60c46c889b1e0f981211b55831.pdf
Policy Architectures for Compositional Generalization in Control,2022,ICML,"['Allan Zhou', 'Vikash Kumar', 'Chelsea Finn', 'Aravind Rajeswaran']",poster,"['mdp', 'invariance', 'rl']","Several tasks in control, robotics, and planning can be specified through desired goal configurations for entities in the environment. Learning goal-conditioned policies is a natural paradigm to solve such tasks. Current approaches, however, struggle to learn and generalize as task complexity increases, such as due to variations in number of entities or compositions of goals. To overcome these challenges, we first introduce the Entity-Factored Markov Decision Process (EFMDP), a formal framework for modeling the entity-based compositional structure in control tasks. Subsequently, we outline policy architecture choices that can successfully leverage the geometric properties of the EFMDP model. Our framework theoretically motivates the use of Self-Attention and Deep Set architectures for control, and results in flexible policies that can be trained end-to-end with standard reinforcement and imitation learning algorithms. On a suite of simulated robot manipulation tasks, we find that these architectures achieve significantly higher success rates with less data, compared to the standard multilayer perceptron. Our structured policies also enable broader and more compositional generalization, producing policies that \textbf{extrapolate} to different numbers of entities than seen in training, and \textbf{stitch} together (i.e. compose) learned skills in novel ways. Video results can be found at https://sites.google.com/view/comp-gen-anon.",https://api.openreview.net/pdf/9b1d26688f549b1a869b8abf68512af675b687bf.pdf
Representation Learning as Finding Necessary and Sufficient Causes,2022,ICML,"['Yixin Wang', 'Michael Jordan']",poster,"['Causal inference', 'representation learning', 'non-spuriousness', 'disentanglement', 'probabilities of causation']","Representation learning constructs low-dimensional representations to
summarize essential features of high-dimensional data. This learning
problem is often approached by describing various desiderata
associated with learned representations; e.g., that they be
non-spurious or efficient. It can be challenging, however, to turn
these intuitive desiderata into formal criteria that can be measured
and enhanced based on observed data.  In this paper, we take a causal
perspective on representation learning, formalizing non-spuriousness
and efficiency (in supervised representation learning) using
counterfactual quantities and observable consequences of causal
assertions.  This yields computable metrics that can be used to assess
the degree to which representations satisfy the desiderata of interest
and learn non-spurious representations from single observational
datasets.",https://api.openreview.net/pdf/66329176e82e4cd396b58e0d072a205335d8bb83.pdf
Unsupervised Learning under Latent Label Shift,2022,ICML,"['Pranav Mani', 'Manley Roberts', 'Saurabh Garg', 'Zachary Chase Lipton']",poster,"['unsupervised learning', 'label shift', 'topic modeling', 'domain adaptation', 'mixture proportion estimation', 'unsupervised structure discovery', 'anchor word', 'deep learning']","What sorts of structure might enable a learner to discover classes from unlabeled data? Traditional unsupervised learning approaches risk recovering incorrect classes based on spurious feature-space similarity. In this paper, we introduce unsupervised learning under Latent Label Shift (LLS), where label marginals $p_d(y)$ shift but class conditionals $p(\mathbf{x}|y)$ do not. This setting suggests a new principle for identifying classes: elements that shift together across domains belong to the same true class. For finite input spaces, we establish an isomorphism between LLS and topic modeling; for continuous data, we show that if each label's support contains a separable region, analogous to an anchor word, oracle access to $p(d|\mathbf{x})$ suffices to identify $p_d(y)$ and $p_d(y|\mathbf{x})$ up to permutation of latent labels. Thus motivated, we introduce a practical algorithm that leverages domain-discriminative models as follows: (i) push examples through domain discriminator $p(d|\mathbf{x})$; (ii) discretize the data by clustering examples in $p(d|\mathbf{x})$ space; (iii) perform non-negative matrix factorization on the discrete data; (iv) combine recovered $p(y|d)$ with discriminator outputs $p(d|\mathbf{x})$ to compute $p_d(y|\mathbf{x}) \; \forall d$. In semi-synthetic experiments, we show that our algorithm can use domain information to overcome a failure mode of standard unsupervised classification in which feature-space similarity does not indicate true groupings.",https://api.openreview.net/pdf/c8f24ba55b2421106844314a7bfb4ae078ce7944.pdf
A Study of Causal Confusion in Preference-Based Reward Learning,2022,ICML,"['Jeremy Tien', 'Jerry Zhi-Yang He', 'Zackory Erickson', 'Anca Dragan', 'Daniel S. Brown']",poster,"['causal reward confusion', 'preference learning', 'reward learning']","While there is much empirical and theoretical analysis of causal confusion and reward gaming behaviors in reinforcement learning and behavioral cloning approaches, we provide the first systematic study of causal confusion in the context of learning reward functions from preferences. We identify a set of three benchmark domains where we observe causal confusion when learning reward functions from offline datasets of pairwise trajectory preferences: a simple reacher domain, an assistive feeding domain, and an itch-scratching domain. To gain insight into this observed causal confusion, we perform a sensitivity analysis on the effect of different factors---the reward model capacity and feature dimensionality---on the robustness of rewards learned from preferences. We find evidence that learning rewards from preferences is highly sensitive and non-robust to spurious features and increasing model capacity. %, but not as sensitive to the type of training data. Videos, code, and supplemental results are available at https://sites.google.com/view/causal-reward-confusion.",https://api.openreview.net/pdf/4a3efd2be712ede94d4419990a93203e0b8fa932.pdf
Learning to induce causal structure,2022,ICML,"['Nan Rosemary Ke', 'Silvia Chiappa', 'Jane X Wang', 'Jorg Bornschein', 'Anirudh Goyal', 'Melanie Rey', 'Matthew Botvinick', 'Theophane Weber', 'Michael Curtis Mozer', 'Danilo Jimenez Rezende']",poster,['causal learning'],"The fundamental challenge in causal induction is to infer the underlying graph structure given observational and/or interventional data. Most existing causal induction algorithms operate by generating candidate graphs and evaluating them using either score-based methods (including continuous optimization) or independence tests. In our work, 
we instead treat the inference process as a black box and design a neural network architecture that learns the mapping from \emph{both observational and interventional data} to graph structures via supervised training on synthetic graphs. The learned model generalizes to new synthetic graphs, is robust to train-test distribution shifts, and achieves state-of-the-art performance on naturalistic graphs for low sample complexity.",https://api.openreview.net/pdf/3daaadd827e77b68a72480d637da70095f26f92f.pdf
Repeated Environment Inference for Invariant Learning,2022,ICML,"['Aayush Mishra', 'Anqi Liu']",poster,"['Invariant Learning', 'Environment Inference']","We study the problem of invariant learning when the environment labels are unknown. We focus on the Invariant representation notion when the Bayes optimal conditional label distribution is the same across different environments. Previous work conducts the Environment Inference (EI) by maximizing the penalty term in the Invariant Risk Minimization (IRM) framework. The EI step uses a reference model which focuses on spurious correlations to efficiently reach a good environment partition. However, it is not clear how to find such a reference model. In this work, we propose to repeat the EI process and retrain an ERM model on the \textit{majority} environment inferred by the EI step in the previous step. Under mild assumptions, we find that this iterative process helps learn a representation capturing the spurious correlation better than the single step. This results in better Environment Inference and better Invariant Learning.  We show that this method outperforms baselines on both synthetic and real-world datasets.",https://api.openreview.net/pdf/f51fbd07e00d62d835506e286d198daabdca2d43.pdf
Finding Spuriously Correlated Visual Attributes,2022,ICML,"['Revant Teotia', 'Chengzhi Mao', 'Carl Vondrick']",poster,"['Spurious Correlations', 'Interpretability']","Deep neural models often learn to use spurious features in image datasets, which raises concerns when the models are deployed to critical applications, such as medical imaging.  Identifying spurious features is essential to developing robust models. Existing methods to find spurious features do not give semantic meaning to the features and rely on human interpretation to decide if they are spurious or not. In this paper, we propose to find spurious visual attributes in the dataset. We first linearly transform the latent features into visual attributes and then learn correlations between the attributes and object classes by training a simple linear classifier. Correlated visual attributes are easily interpretable because they are in natural language having well defined meanings which makes it easier to find if they are spurious or not. Through visualizations and experiments, we show how to find spurious visual attributes, their extent in existing dataset and failure mode examples showing negative impact of learned spurious correlations on out-of-distribution generalization.",https://api.openreview.net/pdf/e55b3c175bb1cfdfb56ea8786fcc839d33311670.pdf
BARACK: Partially Supervised Group Robustness With Guarantees,2022,ICML,"['Nimit Sharad Sohoni', 'Maziar Sanjabi', 'Nicolas Ballas', 'Aditya Grover', 'Shaoliang Nie', 'Hamed Firooz', 'Christopher Re']",poster,"['group robustness', 'spurious correlations', 'partial supervision', 'image classification']","While neural networks have shown remarkable success on classification tasks in terms of average-case performance, they often fail to perform well on certain groups of the data, for instance when spurious correlations are present. Unfortunately, group information may be expensive to obtain; thus, recent works in robustness and fairness have proposed ways to improve worst-group performance even when group labels are unavailable. However, these methods generally underperform methods that utilize group information at training time. In this work, we assume access to a small number of group labels alongside a larger dataset without group labels. We propose BARACK, a simple two-step framework to utilize this partial group information to improve worst-group performance: train a model to predict the missing group labels for the training data, and then use these predicted group labels in a robust optimization objective. Theoretically, we provide generalization bounds for our approach in terms of the worst-group performance, which scale with respect to both the total number of training points and the number of training points with group labels. Empirically, across four spurious correlation and robustness benchmark tasks, our method outperforms the baselines that do not use group information, even when only 1-33% of points have group labels.",https://api.openreview.net/pdf/b8bbc7783923fa19a65e28eb5062edc8d2062b10.pdf
Towards Environment-Invariant Representation Learning for Robust Task Transfer,2022,ICML,"['Benjamin Eyre', 'Richard Zemel', 'Elliot Creager']",poster,"['Domain-Generalization', 'Invariant-Learning', 'Transfer-Learning']","To train a classification model that is robust to distribution shifts upon deployment, auxiliary labels indicating the various “environments” of data collection can be leveraged to mitigate reliance on environment-specific features. In this paper we attempt to determine where in the network the environment invariance property can be located for such a model, with the hopes of adapting a single pre-trained invariant model for use in multiple tasks. We discuss how to evaluate whether a model has formed an environment-invariant internal representation - as opposed to an invariant final classifier function - and propose an objective that encourages learning such a representation. We also extend color-biased digit recognition to a transfer setting where the target task requires an invariant model, but lacks the environment labels needed to train an invariant model from scratch, thus motivating the transfer of an invariant representation trained on a source task with environment labels.",https://api.openreview.net/pdf/d4c72c76f12d9261c17de88ee3b1183494902545.pdf
Evaluating Systemic Error Detection Methods using Synthetic Images,2022,ICML,"['Gregory Plumb', 'Nari Johnson', 'Ángel Cabrera', 'Marco Tulio Ribeiro', 'Ameet Talwalkar']",poster,[],"We introduce SpotCheck, a framework for generating synthetic datasets to use for evaluating methods for discovering blindspots (i.e., systemic errors) in image classifiers. We use SpotCheck to run controlled studies of how various factors influence the performance of blindspot discovery methods. Our experiments reveal several shortcomings of existing methods, such as relatively poor performance in settings with multiple blindspots and sensitivity to hyperparameters. Further, we find that a method based on dimensionality reduction, PlaneSpot, is competitive with existing methods, which has promising implications for the development of interactive tools.",https://api.openreview.net/pdf/0e30585048ed4443b2b89962f27a994f8de87170.pdf
"""Why did the Model Fail?"": Attributing Model Performance Changes to Distribution Shifts",2022,ICML,"['Haoran Zhang', 'Harvineet Singh', 'Shalmali Joshi']",poster,"['distribution shifts', 'Shapley attribution', 'causal graph']","Performance of machine learning models may differ significantly in novel environments compared to during training due to shifts in the underlying data distribution. Attributing performance changes to specific data shifts is critical for identifying sources of model failures and designing stable models. In this work, we design a novel method for attributing performance difference between environments to shifts in the underlying causal mechanisms. To this end, we construct a cooperative game where the contribution of each mechanism is quantified as their Shapley value. We demonstrate the ability of the method to identify sources of spurious correlation and attribute performance drop to shifts in label and/or feature distributions on synthetic and real-world datasets.",https://api.openreview.net/pdf/3b3b7470aef56293234972699066401602e4296c.pdf
Invariant and Transportable Representations for Anti-Causal Domain Shifts,2022,ICML,"['Yibo Jiang', 'Victor Veitch']",poster,"['causality', 'spurious correlation', 'invariant prediction', 'domain shift', 'image classification', 'domain adaptation']","Real-world classification problems must contend with domain shift, the (potential) mismatch between the domain where a model is deployed and the domain(s) where the training data was gathered. Methods to handle such problems must specify what structure is common between the domains and what varies. A natural assumption is that causal (structural) relationships are invariant in all domains. Then, it is tempting to learn a predictor for label $Y$ that depends only on its causal parents. However, many real-world problems are ``anti-causal'' in the sense that $Y$ is a cause of the covariates $X$---in this case, $Y$ has no causal parents and the naive causal invariance is useless. In this paper, we study representation learning under a particular notion of domain shift that both respects causal invariance and that naturally handles the ``anti-causal'' structure. We show how to leverage the shared causal structure of the domains to learn a representation that both admits an invariant predictor and that also allows fast adaptation in new domains. The key is to translate causal assumptions into learning principles that disentangle ``invariant'' and ``non-stable'' features. Experiments on both synthetic and real-world data demonstrate the effectiveness of the proposed learning algorithm. Full paper is available at \url{https://arxiv.org/abs/2207.01603}.",https://api.openreview.net/pdf/ba27fed75259bc6e080b681d8f79f6743e445672.pdf
Contrastive Adapters for Foundation Model Group Robustness,2022,ICML,"['Michael Zhang', 'Christopher Re']",poster,"['foundation models', 'adapters', 'group robustness', 'large pretrained models']","While large pretrained foundation models (FMs) have shown remarkable zero-shot classification robustness to dataset-level distribution shifts, their robustness to group shifts is relatively underexplored. We study this problem, and first find that popular FMs such as CLIP may not be robust to various group shifts. On prior robustness benchmarks, they achieve up to an 80.7 percentage point (pp) gap between average and worst-group accuracy. Unfortunately, current methods to improve robustness require retraining, which can be prohibitively expensive for large FMs. We find existing ways to efficiently improve large model inference, e.g., by training adapters (lightweight MLPs) on top of FM embeddings, can also hurt group robustness compared to zero-shot. We thus propose a first adapter training method designed to improve FM robustness to group shifts. While prior work only trains adapters with class labels, we add a contrastive objective to explicitly learn similar embeddings for initially dissimilar FM embeddings. Across the same benchmarks, contrastive adapting effectively and efficiently improves group robustness, raising worst-group accuracy by 16.0 to 56.0 pp over zero-shot without any FM finetuning. Beyond FM robustness, contrastive adapting achieves near-state-of-the-art robustness on Waterbirds and CelebA, while only training 1% of other methods' model parameters.",https://api.openreview.net/pdf/21abed5751b4ce1e0151558259a914f0bacd677a.pdf
HyperInvariances: Amortizing Invariance Learning,2022,ICML,"['Ruchika Chavhan', 'Henry Gouk', 'Jan Stuehmer', 'Timothy Hospedales']",poster,"['Invariance Learning', 'Contrastive Learning', 'Multi-task Learning']","Providing invariances in a given learning task conveys a key inductive bias that can lead to sample-efficient learning and good generalisation, if correctly specified. However, the ideal invariances for many problems of interest are often not known, which has led both to a body of engineering lore as well as attempts to provide frameworks for  invariance learning. However, invariance learning is expensive and data intensive for popular neural architectures. We introduce the notion of amortizing invariance learning. In an up-front learning phase, we learn a low-dimensional manifold of feature extractors spanning invariance to different transformations using a hyper-network. Then, for any problem of interest, both model and invariance learning are rapid and efficient by fitting a low-dimensional invariance descriptor an output head. Empirically, this framework can identify appropriate invariances in different downstream tasks and lead to comparable or better test performance than conventional approaches. Our HyperInvariance framework is also theoretically appealing as it enables generalisation-bounds that provide an interesting new operating point in the trade-off between model fit and complexity.",https://api.openreview.net/pdf/16c8d6a1b70cdc4c906f5532ce6e71ed172a9171.pdf
Conditional Distributional Invariance through Implicit Regularization,2022,ICML,['Tanmay Gupta'],poster,"['machine learning', 'deep learning', 'causality', 'text classification', 'image classification', 'invariant learning', 'spurious correlations']","A significant challenge faced by models trained via standard Empirical Risk Minimization (ERM) is that they might learn features of the input X which help it predict label Y in the training set which shouldn’t matter, i.e. associations which might not hold in test data. Causality lends itself very well to separate such spurious correlations from genuine, causal, ones. In this paper, we present a simple causal model for data and a method using which we can train a classifier to predict a category Y from an input X, while being invariant to a variable Z which is spuriously associated with Y. Notably, this method is just a slightly modified ERM problem without any explicit regularization. We empirically demonstrate that our method does better than regular ERM on standard metrics on benchmark datasets. ",https://api.openreview.net/pdf/dd99e87a407b29cb1b5eec4400df94b62e0411b1.pdf
Enhancing Unit-tests for Invariance Discovery,2022,ICML,"['Piersilvio De Bartolomeis', 'Antonio Orvieto', 'Giambattista Parascandolo']",poster,[],"Recently, Aubin et al. (2021) proposed a set of linear low-dimensional problems to precisely evaluate different types of out-of-distribution generalization. In this paper, we show that one of these problems can already be solved by established algorithms, simply by better hyper-parameter tuning.  We then propose an enhanced version of the linear unit-tests. To the best of our hyper-parameter search and within the set of algorithms evaluated, AND-mask is the best performing algorithm on this new suite of tests. Our findings on synthetic data are further reinforced by experiments on an image classification task where we introduce spurious correlations.

",https://api.openreview.net/pdf/4abc308bc9e1de8312402b3dfc5e42cd86e36052.pdf
Diversify and Disambiguate: Learning from Underspecified Data,2022,ICML,"['Yoonho Lee', 'Huaxiu Yao', 'Chelsea Finn']",poster,"['Spurious correlations', 'underspecification', 'ambiguity', 'ensembles']","Many datasets are underspecified, meaning that there are several equally viable solutions to a given task. Underspecified datasets can be problematic for methods that learn a single hypothesis because different functions that achieve low training loss can focus on different predictive features and thus have widely varying predictions on out-of-distribution data. We propose DivDis, a simple two-stage framework that first learns a collection of diverse hypotheses for a task by leveraging unlabeled data from the test distribution. We then disambiguate by selecting one of the discovered hypotheses using minimal additional supervision, in the form of additional labels or inspection of function visualization. We demonstrate the ability of DivDis to find robust hypotheses in image classification and natural language processing problems with underspecification.",https://api.openreview.net/pdf/4756e1ad7ba04d47db72f69e543f02a38e7bf6ab.pdf
Unsupervised Causal Generative Understanding of Images,2022,ICML,"['Titas Anciukevičius', 'Patrick Fox-Roberts', 'Edward Rosten', 'Paul Henderson']",poster,"['generative model', 'neural rendering', 'causality', 'unsupervised learning', 'computer vision']","We present a novel causal generative model for unsupervised object-centric 3D scene understanding that generalizes robustly to out-of-distribution images.
This model is trained to reconstruct multi-view images via a latent representation describing the shapes, colours and positions of the 3D objects they show.
We then propose an inference algorithm that can infer this latent representation given a single out-of-distribution image as input.
We conduct extensive experiments applying our approach to test datasets that have zero probability under the training distribution.
Our approach significantly out-performs baselines that do not capture the true causal image generation process.",https://api.openreview.net/pdf/c9790505cc1987febc9d39bc62c4c71fd1861399.pdf
Causal Discovery using Model Invariance through Knockoff Interventions,2022,ICML,"['Wasim Ahmad', 'Maha Shadaydeh', 'Joachim Denzler']",poster,"['Causal inference', 'Nonlinear time series', 'Model invariance', 'Knockoffs']","Cause-effect analysis is crucial to understanding the underlying mechanism of a system. We propose to exploit model invariance through interventions on the predictors to infer causality in nonlinear multivariate systems of time series. We model non-linear interactions in time series using DeepAR and then expose the model to different environments using Knockoffs-based interventions to test model invariance. Knockoff samples are pairwise exchangeable, in-distribution, and statistically null variables generated without knowing the response. We test model invariance where we show that the distribution of the response residual does not change significantly upon interventions on non-causal predictors. We evaluate our method on real and synthetically generated time series. Overall our method outperforms other widely used causality methods, i.e, VAR Granger causality, VARLiNGAM, and PCMCI+.",https://api.openreview.net/pdf/c57f432527af81be6cccd28742ff81ceef848f37.pdf
Using causal modeling to analyze generalization of biomarkers in high-dimensional domains: a case study of adaptive immune repertoires,2022,ICML,"['Milena Pavlovic', 'Ghadi S. Al Hajj', 'Victor Greiff', 'Johan Pensar', 'Geir Kjetil Sandve']",poster,"['diagnostics', 'adaptive immune receptor repertoires', 'generalization', 'robustness', 'causal inference', 'biomarkers']","Machine learning is increasingly used to discover diagnostic and prognostic biomarkers from high-dimensional molecular data. However, a variety of factors related to experimental design may affect the ability to learn generalizable and clinically applicable diagnostics. Here, we discuss building a diagnostic based on a specific, recently established high-dimensional biomarker – adaptive immune receptor repertoires (AIRRs), and investigate how causal modeling may improve the robustness and generalization of developed diagnostics. We examine how the main biological and experimental factors of the AIRR domain may influence the learned biomarkers, especially in the presence of dataset shifts, and provide simulations of such effects. We conclude that causal modeling could improve AIRR-based diagnostics, but also
that causal modeling itself might find a powerful testbed with complex, high-dimensional variables in the AIRR field.",https://api.openreview.net/pdf/df6583377a79b38268c49f237224378c37d3665e.pdf
The Importance of Background Information for Out of Distribution Generalization,2022,ICML,"['Jupinder Parmar', 'Khaled Kamal Saab', 'Brian Pogatchnik', 'Daniel Rubin', 'Christopher Ré']",poster,"['Machine Learning', 'Domain Generalization', 'Robustness', 'Medical Imaging']","Domain generalization in medical image classification is an important problem for trustworthy machine learning to be deployed in healthcare. We find that existing approaches for domain generalization which utilize ground-truth abnormality segmentations to control feature attributions have poor out-of-distribution (OOD) performance relative to the standard baseline of empirical risk minimization (ERM). We investigate what regions of an image are important for medical image classification and show that parts of the background, that which is not contained in the abnormality segmentation, provides helpful signal. We then develop a new task-specific mask which covers all relevant regions. Utilizing this new segmentation mask significantly improves the performance of the ex- isting methods on the OOD test sets. To obtain better generalization results than ERM, we find it necessary to scale up the training data size in addition to the usage of these task-specific masks.",https://api.openreview.net/pdf/0ac8b0b4c5f116cb472db4448ab8f878d4484884.pdf
Out-of-Distribution Failure through the Lens of Labeling Mechanisms: An Information Theoretic Approach,2022,ICML,"['Soroosh Shahtalebi', 'Zining Zhu', 'Frank Rudzicz']",poster,"['Out-of-distribution generalization', 'domain generalization', 'generalization bound']","Machine learning models typically fail in deployment environments where the distribution of data does not perfectly match that of the training domains. This phenomenon is believed to stem from networks' failure to capture the invariant features that generalize to unseen domains. However, we attribute this phenomenon to the limitations that the labeling mechanism employed by humans imposes on the learning algorithm. We conjecture that providing multiple labels for each datapoint where each could describe the existence of particular objects/concepts on the data point, decreases the risk of capturing non-generalizable correlations by the model. We theoretically show that learning over a multi-label regime, where $K$ labels for each data point are present, tightens the expected generalization gap by a factor of $1/\sqrt{K}$ compared to a similar case where only one label for each data point is in hand. Also, we show that learning under this regime is much more sample efficient and requires a fraction of training data to provide competitive results.",https://api.openreview.net/pdf/ff2db66f210b0373f78f1f8073d085f2507de4c4.pdf
How much Data is Augmentation Worth?,2022,ICML,"['Jonas Geiping', 'Gowthami Somepalli', 'Ravid Shwartz-Ziv', 'Andrew Gordon Wilson', 'Tom Goldstein', 'Micah Goldblum']",poster,"['Data Augmentations', 'out-of-domain', 'Stochasticity', 'Flatness', 'Neural Networks', 'Invariance']","Despite the clear performance benefits of data augmentations, little is known about why they are so effective. In this paper, we disentangle several key mechanisms through which data augmentations operate. Establishing an exchange rate between augmented and additional real data, we find that augmentations can provide nearly the same performance gains as additional data samples for in-domain generalization and even greater performance gains for out-of-distribution test sets. We also find that neural networks with hard-coded invariances underperform those with invariances learned via data augmentations. Our experiments suggest that these benefits to generalization arise from the additional stochasticity conferred by randomized augmentations, leading to flatter minima.",https://api.openreview.net/pdf/49973d34af19e82673280f753d1cf86052947424.pdf
On the Generalization and Adaption Performance of Causal Models,2022,ICML,"['Nino Scherrer', 'Anirudh Goyal', 'Stefan Bauer', 'Yoshua Bengio', 'Nan Rosemary Ke']",poster,"['Causal Models', 'Generalization', 'Speed of Adaptation', 'Causal Structure in Neural Networks']","Learning models that offer robust out-of-distribution generalization and fast adaptation is a key challenge in modern machine learning. Modelling causal structure into neural networks holds the promise to accomplish robust zero and few-shot adaptation. Recent advances in differentiable causal discovery have proposed to factorize the data generating process into a set of modules, i.e. one module for the conditional distribution of every variable where only causal parents are used as predictors. Such a modular decomposition of knowledge enables adaptation to distributions shifts by only updating a subset of parameters. In this work, we systematically study the generalization and adaption performance of such modular neural causal models by comparing it to monolithic models and structured models where the set of predictors is not constrained to causal parents. Our analysis shows that the modular neural causal models outperform other models on both zero and few-shot adaptation in low data regimes and offer robust generalization. We also found that the effects are more significant for sparser graphs as compared to denser graphs.",https://api.openreview.net/pdf/4274a20c0a92b11c4868f614182f341e3f8b2476.pdf
Learning Switchable Representation with Masked Decoding and Sparse Encoding,2022,ICML,"['Kohei Hayashi', 'Masanori Koyama']",poster,"['Domain adaptation', 'unsupervised representation learning', 'identifiability', 'sparseness']","In this study, we explore the unsupervised learning based on private/shared factor decomposition, which decomposes the latent space into private factors that vary only in a specific domain the shared factors that vary in all domains. We study when/how we can force the model to respect the true private/shared factor decomposition that underlies the dataset. We show that, when we train a masked decoder and an encoder with sparseness regularization in the latent space, we can identify the true private/shared decomposition up to mixing within each component. We empirically confirm this result and study the efficacy of this training strategy as a representation learning method. ",https://api.openreview.net/pdf/d70ab70e715a7429e646e3ed9d8245ef0db3aa8f.pdf
Improving Group-based Robustness and Calibration via Ordered Risk and Confidence Regularization,2022,ICML,"['Seungjae Shin', 'Byeonghu Na', 'HeeSun Bae', 'JoonHo Jang', 'Hyemi Kim', 'Kyungwoo Song', 'Youngjae Cho', 'Il-chul Moon']",poster,"['robustness', 'dataset bias', 'spurious correlation']","Neural network trained via empirical risk minimization achieves high accuracy on average but low accuracy on certain groups, especially when there is a spurious correlation. To construct the unbiased model from spurious correlation, we build a hypothesis that the inference to the samples without spurious correlation should take relative precedence over the inference to the spuriously biased samples. Based on the hypothesis, we propose the relative regularization to induce the training risk of each group to follow the specific order, which is sorted according to the degree of spurious correlation for each group. In addition, we introduce the ordering regularization based on the predictive confidence of each group to improve the model calibration, where other robust models still suffer from large calibration errors. These result in our complete algorithm, Ordered Risk and Confidence regularization (ORC). Our experiments demonstrate that ORC improves both the group robustness and calibration performances against the various types of spurious correlation in both synthetic and real-world datasets.",https://api.openreview.net/pdf/e79200d4ebc76dc957925b8beb6c8d8ce7a7befe.pdf
Towards Group Robustness in the Presence of Partial Group Labels,2022,ICML,"['Vishnu Suresh Lokhande', 'Kihyuk Sohn', 'Jinsung Yoon', 'Madeleine Udell', 'Chen-Yu Lee', 'Tomas Pfister']",poster,[],"Learning invariant representations is a fundamental requirement for training machine learning models that are influenced by spurious correlations. These spurious correlations, present in the training datasets, wrongly direct the neural network predictions resulting in reduced performance on certain groups, especially the minority groups. Robust training against such correlations requires the knowledge of group membership on every training sample. This need is impractical in situations where the data labeling efforts, for minority/rare groups, are significantly laborious or where the individuals comprising the dataset choose to conceal sensitive information pertaining to the groups. On the other hand, the presence of data collection efforts often results in datasets that contain partially labeled group information. Recent works, addressing the problem, have tackled fully unsupervised scenarios where no labels for groups are available. We aim to fill a missing gap in the literature that addresses a more realistic setting by leveraging partially available group information during training. First, we construct a constraint set and derive a high probability bound for the group assignment to belong to the set. Second, we propose an algorithm that optimizes for a worst-off group assignment from the constraint set. Through experiments on image and tabular datasets, we show improvements in the minority group's performance while preserving overall accuracy across groups.",https://api.openreview.net/pdf/536ce1ef33d92e88145e12067954bafe13d652e3.pdf
Towards Multi-level Fairness and Robustness on Federated Learning,2022,ICML,"['Fengda Zhang', 'Kun Kuang', 'Yuxuan Liu', 'Long Chen', 'Jiaxun Lu', 'yunfeng shao', 'Fei Wu', 'Chao Wu', 'Jun Xiao']",poster,"['Federated Learning', 'Fairness', 'Robustness', 'Federated Optimization']","Federated learning (FL) has emerged as an important machine learning paradigm where a global model is trained based on the private data from distributed clients. However, federated model can be biased due to the spurious correlation or distribution shift over subpopulations, and it may disproportionately advantage or disadvantage some of the subpopulations, leading to the problem of unfairness and non-robustness. In this paper, we formulate the problem of multi-level fairness and robustness on FL to train a global model performing well on existing clients, different subgroups formed by sensitive attribute(s), and newly added clients at the same time. To solve this problem, we propose a unifed optimization objective from the view of federated uncertainty set with theoretical analyses. We also develop an effcient federated optimization algorithm named Federated Mirror Descent Ascent with Momentum Acceleration (FMDA-M) with convergence guarantee. Extensive experimental results show that FMDA-M outperforms the existing FL algorithms on multilevel fairness and robustness.",https://api.openreview.net/pdf/ece18d5ba5fa1dbf7a4dddb7bb3f1b2e72c41c78.pdf
Learning Debiased Classifier with Biased Committee,2022,ICML,"['Nayeong Kim', 'Sehyun Hwang', 'Sungsoo Ahn', 'Jaesik Park', 'Suha Kwak']",poster,"['Debiasing', 'Spurious correlation', 'bootstrap ensemble', 'self-supervised learning', 'image classification']","This paper proposes a new method for training debiased classifiers with no bias supervision. The key idea of the method is to employ a committee of classifiers as an auxiliary module that identifies bias-conflicting data and assigns large weights to them when training the main classifier. The committee is learned as a bootstrapped ensemble so that a majority of its classifiers are biased as well as being diverse, and intentionally fail to predict classes of bias-conflicting data accordingly. The consensus within the committee on prediction difficulty provides a reliable cue for identifying and weighting bias-conflicting data. Moreover, the committee is trained also with knowledge transferred from the main classifier so that it gradually becomes debiased and emphasizes more difficult data as training progresses.
On five real-world datasets, our method outperforms previous arts using no bias label like ours and even surpasses those relying on bias labels occasionally.",https://api.openreview.net/pdf/eb9a2c23c98066414be42e5af11ade1088422046.pdf
Causal Omnivore: Fusing Noisy Estimates of Spurious Correlations,2022,ICML,"['Dyah Adila', 'Sonia Cromp', 'SICHENG MO', 'Frederic Sala']",poster,"['distribution shift', 'causal feature learning', 'spurious features']","Spurious correlations are one of the biggest pain points for users of modern machine learning. To handle this issue, many approaches attempt to learn features that are causally linked to the prediction variable. Such techniques, however, suffer from various flaws---they are often prohibitively complex or based on heuristics and strong assumptions that may fail in practice. There is no one-size-fits-all causal feature identification approach. To address this challenge, we propose a simple way to fuse multiple noisy estimates of causal features. Our approach treats the underlying causal structure as a latent variable and exploits recent developments in estimating latent structures without any access to ground truth. We propose new sources, including an automated way to extract causal insights from existing ontologies or foundation models. On multiple benchmark environmental shift datasets, our discovered features can train a model via vanilla empirical risk minimization that outperforms multiple baselines, including automated causal feature discovery techniques such as invariant risk minimization on three benchmark datasets.",https://api.openreview.net/pdf/126be2e2f9e1a9d5c8cec7471d6f10f98412a23d.pdf
Robust Calibration with Multi-domain Temperature Scaling,2022,ICML,"['Yaodong Yu', 'Stephen Bates', 'Yi Ma', 'Michael Jordan']",poster,"['uncertainty quantification', 'calibration', 'distribution shift']","Uncertainty quantification is essential for the reliable deployment of machine learning models to high-stakes application domains. Uncertainty quantification is all the more challenging when training distribution and test distribution are different, even the distribution shifts are mild. Despite the ubiquity of distribution shifts in real-world applications, existing uncertainty quantification approaches mainly study the in-distribution setting where the train and test distributions are the same. In this paper, we develop a systematic calibration model to handle distribution shifts by leveraging data from multiple domains. Our proposed method---multi-domain temperature scaling---uses the heterogeneity in the domains to improve calibration robustness under distribution shift. Through experiments on three benchmark data sets, we find our proposed method outperforms existing methods as measured on both in-distribution and out-of-distribution test sets.",https://api.openreview.net/pdf/82f21fcb39f3ba3e7dd57016b2def71278ed0c90.pdf
A Unified Causal View of Domain Invariant Representation Learning,2022,ICML,"['Zihao Wang', 'Victor Veitch']",poster,[]," Machine learning methods can be unreliable when deployed in domains that differ from the domains on which they were trained. To address this, we may wish to learn representations of data that are domain-invariant in the sense that we preserve data structure that is stable across domains, but throw out spuriously-varying parts. There are many representation-learning approaches of this type, including methods based on data augmentation, distributional invariances, and risk invariance. Unfortunately, when faced with any particular real-world domain shift, it is unclear which, if any, of these methods might be expected to work. The purpose of this paper is to show how the different methods relate to each other, and clarify the real-world circumstances under which each is expected to succeed. The key tool is a new notion of domain shift relying on the idea that causal relationships are invariant, but non-causal relationships (e.g., due to confounding) may vary. Considering this type of domain shift, a natural goal is to learn representations that are ``Counterfactually Invariant''. We find the popular domain-invariant representation learning methods enforce invariance that corresponds to the Counterfactual Invariance under different types of causal structures. Therefore, we should pick the method that matches the underlying causal structure. ",https://api.openreview.net/pdf/7c6d807be20f803b104b37717ea1a983357fb9ce.pdf
Evaluating Robustness to Dataset Shift via Parametric Robustness Sets,2022,ICML,"['Michael Oberst', 'Nikolaj Thams', 'David Sontag']",poster,"['Causality', 'Distribution Shift', 'Dataset Shift', 'Robustness']","We give a method for proactively identifying small, plausible shifts in distribution which lead to large differences in model performance. To ensure that these shifts are plausible, we parameterize them in terms of interpretable changes in causal mechanisms of observed variables. This defines a parametric robustness set of plausible distributions and a corresponding worst-case loss.  We construct a local approximation to the loss under shift, and show that problem of finding worst-case shifts can be efficiently solved.",https://api.openreview.net/pdf/53cdb3e74a47ed644a61a5a29325cdf1d318a14d.pdf
Causally motivated multi-shortcut identification and removal,2022,ICML,"['Jiayun Zheng', 'Maggie Makar']",poster,"['shortcut learning', 'spurious correlations', 'causality']","For predictive models to provide reliable guidance in decision making processes, they are often required to be accurate and robust to distribution shift. Shortcut learning--where a model relies on spurious correlations or shortcuts to predict the target label--undermines the robustness property, leading to models with poor out-of-distribution accuracy despite good in-distribution performance. 
Existing work on shortcut learning  either assumes that the set of possible shortcuts is known  a priori or is discoverable using interprability methods such as saliency maps. Instead, we propose a two step approach to (1) efficiently identify relevant shortcuts, and (2) leverage the identified shortcuts to build models that are robust to distribution shifts.  Our approach relies on having access to a (possibly) high dimensional set of auxiliary labels at training time, some of which correspond to possible shortcuts. We show both theoretically and empirically that our approach is able to identify a small sufficient set of shortcuts leading to more efficient predictors in finite samples. ",https://api.openreview.net/pdf/ba4f01f3d86ca0af55ba79af5e6f2d1712505e54.pdf
How robust are pre-trained models to distribution shift? ,2022,ICML,"['Yuge Shi', 'Imant Daunhawer', 'Julia E Vogt', 'Philip Torr', 'Amartya Sanyal']",poster,"['spurious correlation', 'pre-trained models', 'distribution shift', 'unsupervised learning', 'self-supervised learning', 'auto-encoder', 'variational auto-encoder']","The vulnerability of machine learning models to spurious correlations has mostly been discussed in the context of supervised learning (SL). However, there is a lack of insight on how spurious correlations affect the performance of popular self-supervised learning (SSL) and auto-encoder based models (AE). In this work, we shed light on this by evaluating the performance of these models on both real world and synthetic distribution shift datasets. Following observations that the linear head itself can be susceptible to spurious correlations, we develop a new evaluation scheme with the linear head trained on out-of-distribution (OOD) data, to isolate the performance of the pre-trained models from a potential bias of the linear head used for evaluation. With this new methodology, we show that SSL models are consistently more robust to distribution shifts and thus better at OOD generalisation than AE and SL models.",https://api.openreview.net/pdf/2210e36b8df67c46b2486ab8f59526a80d2406f6.pdf
Understanding Rare Spurious Correlations in Neural Networks,2022,ICML,"['Yao-Yuan Yang', 'Chi-Ning Chou', 'Kamalika Chaudhuri']",poster,"['rare spurious correlation', 'privacy']","Neural networks are known to use spurious correlations such as background information for classification. While prior work has looked at spurious correlations that are widespread in the training data, in this work, we investigate how sensitive neural networks are to rare spurious correlations, which may be harder to detect and correct, and may lead to privacy leaks.  We introduce spurious patterns correlated with a fixed class to a few training examples and find that it takes only a handful of such examples for the network to learn the correlation. Furthermore, these rare spurious correlations also impact accuracy and privacy. We empirically and theoretically analyze different factors involved in rare spurious correlations and propose mitigation methods accordingly. Specifically, we observe that $\ell_2$ regularization and adding Gaussian noise to inputs can reduce the undesirable effects.",https://api.openreview.net/pdf/e298d4af9ddcee59aeee154fffaa4280ef66985d.pdf
Optimization-based Causal Estimation from Heterogenous Environments,2022,ICML,"['Mingzhang Yin', 'Yixin Wang', 'David Blei']",poster,"['Causal estimation', 'Robust prediction', 'Optimization', 'Directional derivative', 'Interventional data']","This paper presents an optimization approach to causal estimation. In classical machine learning, the goal of optimization is to maximize predictive accuracy. However, some   covariates might exhibit non-causal association to the outcome. Such spurious associations provide predictive power for classical ML, but    prevent us from interpreting the result causally.  This paper   proposes CoCo, an optimization algorithm that bridges the gap   between pure prediction and causal inference. CoCo leverages   the recently-proposed idea of environments. Given datasets from multiple   environments---and ones that exhibit enough heterogeneity---CoCo maximizes an objective for which the only solution is the causal solution. We describe the theoretical   foundations of this approach and demonstrate its effectiveness on simulated and real datasets. Compared to classical ML and the recently-proposed IRMv1, CoCo provides more accurate estimates of the causal model.",https://api.openreview.net/pdf/717f32264da82abc767f39d516fca75afaa65c7c.pdf
Automated Invariance Testing for Machine Learning Models Using Sparse Linear Layers,2022,ICML,"['Zukang Liao', 'Michael Cheung']",poster,"['Automated invariance testing', 'sparse linear layers', 'feature selection', 'neural networks']","Machine learning testing and evaluation are largely overlooked by the community. In many cases, the only way to conduct testing is through formula-based scores, e.g., accuracy, f1, etc. However, these simple statistical scores cannot fully represent the performance of ML model. Therefore, new testing frameworks are attracting more attention. In this work, we propose a novel invariance testing approach that does not utilise traditional statistical scores. Instead, we train a series of sparse linear layers which are more easily to be compared due to their sparsity. We then use different divergence functions to numerically compare them and fuse the difference scores into a visual matrix. Additionally, testing using sparse linear layers allows us to conduct a novel testing oracle: associativity: by comparing merged weights and weights obtained by combined augmentation. Finally, we assess whether a model is invariant by checking the visual matrix, the associativity, and its sparse layers. We show that by using our testing framework, inter-rater reliability can be significantly improved.",https://api.openreview.net/pdf/2591fda8c13b39ceb935e852fc99b552d0ddc574.pdf
Fairness and robustness in anti-causal prediction,2022,ICML,"['Maggie Makar', ""Alexander D'Amour""]",poster,"['fairness', 'robustness', 'causality']","Robustness to distribution shift and fairness have independently emerged as two important desiderata required of modern machine learning models. Here, we discuss these connections through a causal lens, focusing on anti-causal prediction tasks, where the input to a classifier (e.g., an image) is assumed to be generated as a function of the target label and the protected attribute. By taking this perspective, we draw explicit connections between a common fairness criterion---separation---and a common notion of robustness---risk invariance. These connections provide new motivation for applying the separation criterion in anticausal settings, and show that fairness can be motivated entirely on the basis of achieving better performance. In addition, our findings suggest that robustness-motivated approaches can be used to enforce separation, and that they often work better in practice than methods designed to directly enforce separation. Using a medical dataset, we empirically validate our findings on the task of detecting pneumonia from X-rays, in a setting where differences in prevalence across sex groups motivates a fairness mitigation. Our findings highlight the importance of considering causal structure when choosing and enforcing fairness criteria.",https://api.openreview.net/pdf/a9bbe40b9dbad475bbb604db1e1bbd66e8fea1e0.pdf
Are Vision Transformers Robust to Spurious Correlations ?,2022,ICML,"['Soumya Suvra Ghosal', 'Yifei Ming', 'Yixuan Li']",poster,[],"Deep neural networks may be susceptible to learning spurious correlations that hold on average but not in atypical test samples. As with the recent emergence of vision transformer (ViT) models, it remains underexplored how spurious correlations are manifested in such architectures. In this paper, we systematically investigate the robustness of vision transformers to spurious correlations on three challenging benchmark datasets and compare their performance with popular CNNs. Our study reveals that when pre-trained on a sufficiently large dataset, ViT models are more robust to spurious correlations than CNNs. Key to their success is the ability to generalize better from the examples where spurious correlations do not hold. ",https://api.openreview.net/pdf/36aac57b60c8cde28b9ed16a6827988a46031925.pdf
DAFT: Distilling Adversarially Fine-tuned teachers for OOD Robustness,2022,ICML,"['Anshul Nasery', 'Sravanti Addepalli', 'Praneeth Netrapalli', 'Prateek Jain']",poster,[],"We consider the problem of OOD generalization,where the goal is to train a model that performs well on test distributions that are different from the training distribution. Deep learning models are known to be fragile to such shifts and can suffer large accuracy drops even for slightly different test distributions (Hendrycks & Dietterich, 2019).We propose a new method –DAFT– based on the intuition that adversarially robust combination of a large number of rich features should provide OOD robustness. Our method carefully distills the model from a powerful teacher that learns several discriminative features using standard training while combining them using adversarial training. The standard adversarial training procedure is modified to produce teachers which can guide the student better. We evaluate DAFT on standard benchmarks in the DomainBed framework, and find that DAFT consistently out-performs well-tuned ERM and distillation baselines by up to 6%, with more pronounced gains for smaller networks",https://api.openreview.net/pdf/c6cfbd876dcc099f7662d3ccfe9462f143cd50da.pdf
On the nonlinear correlation of ML performance across data subpopulations ,2022,ICML,"['Weixin Liang', 'Yining Mao', 'Yongchan Kwon', 'Xinyu Yang', 'James Zou']",poster,[],"Understanding the performance of machine learning models across diverse data distributions is critically important for reliable applications. Recent empirically works find that there is a strong linear relationship between in-distribution (ID) and out-of-distribution (OOD) performance, but we show that this is not necessarily true if there are subpopulation shifts. In this paper, we empirically show that out-of-distribution performance often has nonlinear correlation with in-distribution performance under subpopulation shifts. To understand this phenomenon, we decompose the model's performance into performance on each subpopulation. We show that there is a ""moon shape"" correlation (parabolic uptrend curve) between the test performance on the majority subpopulation and the minority subpopulation. This nonlinear correlations hold across model architectures, training durations and hyperparameters, and the imbalance between subpopulations. Moreover, we show that the nonlinearity increases in the presence of spurious correlations in the training data. We provide complementary theoretical and experimental analyses for this interesting phenomenon of nonlinear performance correlation across subpopulations. Finally, we discuss the implications of our findings for ML reliability and fairness.   ",https://api.openreview.net/pdf/e707b3dd4fea5799e2a50512f67eb133a1a866f4.pdf
Lazy vs hasty: linearization in deep networks impacts learning schedule based on example difficulty,2022,ICML,"['Thomas George', 'Guillaume Lajoie', 'Aristide Baratin']",poster,[],"A recent line of work has identified a so-called ‘lazy regime’ where a deep network can be well approximated by its linearization around initialization throughout training. Here we investigate the comparative effect of the lazy (linear) and feature
learning (non-linear) regimes on subgroups of examples based on their difficulty. Specifically, we show that easier examples are given more weight in feature learning mode, resulting in faster training compared to more difficult ones. We illustrate this phenomenon across different ways to quantify example difficulty, including c-score, label noise, and in the presence of spurious correlations.",https://api.openreview.net/pdf/bb24c5348a497a318885a57deeb923f15b7b5d3c.pdf
OOD-Probe: A Neural Interpretation of Out-of-Domain Generalization,2022,ICML,"['Zining Zhu', 'Soroosh Shahtalebi', 'Frank Rudzicz']",poster,"['OOD generalization', 'probing', 'interpretability']","The ability to generalize out-of-domain (OOD) is an important goal for deep neural network development, and researchers have proposed many high-performing OOD generalization methods from various foundations. While many OOD algorithms perform well in various scenarios, these systems are evaluated as ``black-boxes''. Instead, we propose a flexible framework that evaluates OOD systems with finer granularity using a probing module that predicts the originating domain from intermediate representations. We find that representations always encode some information about the domain. While the layerwise encoding patterns remain largely stable across different OOD algorithms, they vary across the datasets. For example, the information about rotation (on RotatedMNIST) is the most visible on the lower layers, while the information about style (on VLCS and PACS) is the most visible on the middle layers. In addition, the high probing results correlate to the domain generalization performances, leading to further directions in developing OOD generalization systems.",https://api.openreview.net/pdf/76d754f421a6e3f105fbf8d96bc6feaa86c43f3b.pdf
Linear Connectivity Reveals Generalization Strategies,2022,ICML,"['Jeevesh Juneja', 'Rachit Bansal', 'Kyunghyun Cho', 'João Sedoc', 'Naomi Saphra']",poster,"['loss landscapes', 'OOD generalization', 'NLI', 'text classification', 'loss surfaces', 'transfer learning', 'challenge sets', 'NLP']","It is widely accepted in the mode connectivity literature that when two neural networks are trained similarly on the same data, they are connected by a path through parameter space over which test set accuracy is maintained. Under some circumstances, including transfer learning from pretrained models, these paths are presumed to be linear. In contrast to existing results, we find that among text classifiers (trained on MNLI, QQP, and CoLA), some pairs of finetuned models have large barriers of increasing loss on the linear paths between them. On each task, we find distinct clusters of models which are linearly connected on the test loss surface, but are disconnected from models outside the cluster---models that occupy separate basins on the surface. By measuring performance on existing diagnostic datasets, we find that these clusters correspond to different generalization strategies: one cluster behaves like a bag of words model under domain shift, while another cluster uses syntactic heuristics. Our work demonstrates how the geometry of the loss surface can guide models towards different heuristic functions.",https://api.openreview.net/pdf/410119f42a0169f646a38e2e72f1415e840804b1.pdf
SelecMix: Debiased Learning by Mixing up Contradicting Pairs,2022,ICML,"['Inwoo Hwang', 'Sangjun Lee', 'Yunhyeok Kwak', 'Seong Joon Oh', 'Damien Teney', 'Jin-Hwa Kim', 'Byoung-Tak Zhang']",poster,"['debias', 'spurious correlation', 'mixup']","Neural networks trained with ERM (empirical risk minimization) sometimes learn unintended decision rules, in particular when their training data is biased, i.e., when training labels are correlated with undesirable features. Techniques have been proposed to prevent a network from learning such features, using the heuristic that spurious correlations are ``simple'' and learned preferentially during training by SGD. Recent methods resample or augment training data such that examples displaying spurious correlations (a.k.a. bias-aligned examples) become a minority, whereas the other, bias-conflicting examples become prevalent. These approaches are difficult to train and scale to real-world data, e.g., because they rely on disentangled representations. We propose an alternative based on mixup that augments the bias-conflicting training data with convex combinations of existing examples and their labels. Our method, named SelecMix, applies mixup to selected pairs of examples, which show either (i)~the same label but dissimilar biased features, or (ii)~a different label but similar biased features. To compare examples with respect to the biased features, we use an auxiliary model relying on the heuristic that biased features are learned preferentially during training by SGD.
On semi-synthetic benchmarks where this heuristic is valid, we obtain results superior to existing methods, in particular in the presence of label noise that makes the identification of bias-conflicting examples challenging.",https://api.openreview.net/pdf/de00d08540430654378b06fd1a43dcf279b1e336.pdf
Optimizing maintenance by learning individual treatment effects,2022,ICML,"['Toon Vanderschueren', 'Robert Boute', 'Tim Verdonck', 'Bart Baesens', 'Wouter Verbeke']",poster,"['Maintenance', 'Imperfect maintenance', 'Causal inference', 'Individual treatment effects', 'Machine learning']","The goal in maintenance is to avoid machine failures and overhauls, while simultaneously minimizing the cost of preventive maintenance. Maintenance policies aim to optimally schedule maintenance by modeling the effect of preventive maintenance on machine failures and overhauls. Existing work assumes the effect of preventive maintenance is (1) deterministic or governed by a known probability distribution, and (2) machine-independent. Conversely, this work proposes to relax both assumptions by learning the effect of maintenance conditional on a machine's characteristics from observational data on similar machines using existing methodologies for causal inference. This way, we can estimate the number of overhauls and failures for different levels of maintenance and, consequently, optimize the preventive maintenance frequency. We validate our proposed approach using real-life data on more than 4,000 maintenance contracts from an industrial partner. Empirical results show that our novel, causal approach accurately predicts the maintenance effect and results in individualized maintenance schedules that are more accurate and cost-effective than supervised or non-individualized approaches.",https://api.openreview.net/pdf/5057521023059d5f972ff2916a6bf9a11b2a9975.pdf
Adaptive Interest for Emphatic Reinforcement Learning,2022,ICML,"['Martin Klissarov', 'Rasool Fakoor', 'Jonas Mueller', 'Kavosh Asadi', 'Taesup Kim', 'Alex Smola']",spotlight,[],"Emphatic algorithms have shown great promise in stabilizing and improving reinforcement learning by selectively emphasizing the update rule. Although the emphasis fundamentally depends on an interest function which defines the intrinsic importance of each state, most approaches simply adopt a uniform interest over all states (except where a hand-designed interest is possible based on domain knowledge). In this paper, we investigate adaptive methods that allow the interest function to dynamically vary over states and iterations. In particular, we leverage meta-gradients to automatically discover online an interest function that would accelerate the agent’s learning process. Empirical evaluations on a wide range of environments show that adapting the interest is key to provide significant gains. Qualitative analysis indicates that the learned interest function emphasizes states of particular importance, such as bottlenecks, which can be especially useful in a transfer learning setting.",https://api.openreview.net/pdf/c3703a5974720270685bf08dee5e16e276d3cad9.pdf
Discovered Policy Optimisation,2022,ICML,"['Chris Lu', 'Jakub Grudzien Kuba', 'Alistair Letcher', 'Luke Metz', 'Christian Schroeder de Witt', 'Jakob Nicolaus Foerster']",spotlight,[],"The last decade has been revolutionary for reinforcement learning (RL) — it can now solve complex decision and control problems. Successful RL methods were handcrafted using mathematical derivations, intuition, and experimentation. This approach has a major shortcoming—it results in specific solutions to the RL problem, rather than a protocol for discovering efficient and robust methods. In contrast, the emerging field of meta-learning provides a toolkit for automatic machine learning method optimisation, potentially addressing this flaw. However, black-box approaches which attempt to discover RL algorithms with minimal prior structure have thus far not been successful. Mirror Learning, which includes RL algorithms, such as PPO, offers a potential framework. In this paper we explore the Mirror Learning space by meta-learning a “drift” function. We refer to the result as Learnt Policy Optimisation (LPO). By analysing LPO we gain original insights into policy optimisation which we use to formulate a novel, closed-form RL algorithm, Discovered Policy Optimisation (DPO). Our experiments in Brax environments confirm state-of-the-art performance of LPO and DPO, as well as their transfer to unseen settings.
",https://api.openreview.net/pdf/7a34be8d8547534ec3534822fd74ec3f417f8031.pdf
Live in the Moment: Learning Dynamics Model Adapted to Evolving Policy,2022,ICML,"['Xiyao Wang', 'Wichayaporn Wongkamjan', 'Furong Huang']",spotlight,"['Reinforcement Learning', 'Model-based Reinforcement Learning', 'State-action Visitation Distribution', 'Distribution Shift', 'Policy-adapted Dynamics Model Learning']","Model-based reinforcement learning (RL) achieves higher sample efficiency in practice than model-free RL by learning a dynamics model to generate samples for policy learning. Previous works learn a ``global'' dynamics model to fit the state-action visitation distribution for all historical policies. However, in this paper, we find that learning a global dynamics model does not necessarily benefit model prediction for the current policy since the policy in use is constantly evolving. The evolving policy during training will cause state-action visitation distribution shifts. We theoretically analyze how the distribution of historical policies affects the model learning and model rollouts. We then propose a novel model-based RL method, named \textit{Policy-adaptation Model-based Actor-Critic (PMAC)}, which learns a policy-adapted dynamics model based on a policy-adaptation mechanism. This mechanism dynamically adjusts the historical policy mixture distribution to ensure the learned model can continually adapt to the state-action visitation distribution of the evolving policy. Experiments on a range of continuous control environments in MuJoCo show that PMAC achieves state-of-the-art asymptotic performance  and almost two times higher sample efficiency than prior model-based methods.",https://api.openreview.net/pdf/0f79f10058a03146aac196799897fd304a3dcac4.pdf
Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization,2022,ICML,"['Jivat Neet Kaur', 'Emre Kiciman', 'Amit Sharma']",oral,[],"Real-world data collected from multiple domains can have multiple, distinct distribution shifts over multiple attributes. However, state-of-the art advances in domain generalization (DG) algorithms focus only on specific shifts over a single attribute. We introduce datasets with multi-attribute distribution shifts and find that existing DG algorithms fail to generalize. Using causal graphs to characterize the different types of shifts, we show that each multi-attribute causal graph entails different constraints over observed variables, and therefore any algorithm based on a single, fixed independence constraint cannot work well across all shifts. We present Causally Adaptive Constraint Minimization (CACM), an algorithm for identifying the correct independence constraints for regularization. Experiments confirm our theoretical claim: correct independence constraints lead to the highest accuracy on unseen domains. Our results demonstrate the importance of modeling the causal relationships inherent in a data-generating process, without which it can be impossible to know the correct regularization constraints for a dataset.",https://api.openreview.net/pdf/883ce28b3cbcb513a24e5e848120b18168de5fc5.pdf
Doubly Right Object Recognition,2022,ICML,"['Revant Teotia', 'Chengzhi Mao', 'Carl Vondrick']",oral,"['Interpretability', 'Spurious Correlations', 'Robustness']","Existing deep neural networks are optimized to predict the right thing, yet they may rely on the wrong evidence. Using the wrong evidence for prediction undermines out-of-distribution generalization, underscoring the gap between machine perception and human perception. In this paper, we introduce an overlooked but important problem: ``doubly right object recognition,'' which requires the model not only to predict the right outcome, but also to use the right reasons that are aligned with human perception. The existing benchmarks fail to learn or evaluate the doubly right object recognition task, because both the right reason and spurious correlations are predictive of the final outcome. Without additional supervision and annotation for what is the right reason for recognition, doubly right object recognition is impossible. To address this, we collect a dataset, which contains annotated right reasons that are aligned with human perception and train a fully interpretable model that only uses the attributes from our collected dataset for object prediction. Through empirical experiments, we demonstrate that our method can train models that are more likely to predict the right thing with the right reason, providing additional generalization ability on ObjectNet, and demonstrating zero-shot learning ability.",https://api.openreview.net/pdf/321cefc0b6961f224a872588ff78ade2d99f75aa.pdf
Characterizing Datapoints via Second-Split Forgetting,2022,ICML,"['Pratyush Maini', 'Saurabh Garg', 'Zachary Chase Lipton', 'J Zico Kolter']",oral,"['example hardness', 'memorization', 'generalization', 'forgetting', 'unlearning']","The dynamics by which neural networks learn and forget examples throughout training has emerged as an object of interest along several threads of research. In particular, researchers have proposed metrics of example hardness based on these dynamics, including (i) the epoch at which examples are first correctly classified; (ii) the number of times their predictions flip during training; and (iii) whether their prediction flips if they are held out. However, an example might be considered hard for several distinct reasons, such as being a member of a rare subpopulation, being mislabeled, or being fundamentally ambiguous in their class. In this paper, we focus on the second-split forgetting time (SSFT): the epoch (if any) after which an original training example is forgotten as the network is fine-tuned on a randomly held out partition of the data. Across multiple benchmark datasets and modalities, we demonstrate that mislabeled examples are forgotten quickly, and seemingly rare examples are forgotten comparatively slowly. By contrast, metrics only considering the first split learning dynamics struggle to differentiate the two. Additionally, the SSFT tends to be robust to the choice of architecture, optimizer, and random seed. From a practical standpoint, the SSFT (i) can help to identify mislabeled samples, the removal of which improves generalization; and (ii) can provide insights about failure modes. ",https://api.openreview.net/pdf/4e3bb598ca199212473a7389946dde4baf3d97b1.pdf
Self-Supervision on Images and Text Reduces Reliance on Visual Shortcut Features,2022,ICML,"['Anil Palepu', 'Andrew Beam']",oral,"['Machine Learning', 'Self-supervised learning', 'CLIP', 'Chest x-rays', 'Chest radiographs', 'Medical Imaging', 'Shortcut Learning', 'Synthetic Shortcuts', 'Integrated Gradients', 'Zero-shot classification', 'ICML']","Deep learning models trained in a fully supervised manner have been shown to rely on so-called ""shortcut"" features. Shortcut features are inputs that are associated with the outcome of interest in the training data, but are either no longer associated or not present in testing or deployment settings. Here we provide experiments that show recent self-supervised models trained on images and text provide more robust image representations and reduce the model's reliance on visual shortcut features on a realistic medical imaging example. Additionally, we find that these self-supervised models ""forget"" shortcut features more quickly than fully supervised ones when fine-tuned on labeled data. Though not a complete solution, our experiments provide compelling evidence that self-supervised models trained on images and text provide some resilience to visual shortcut features.",https://api.openreview.net/pdf/93497dbb4a1ecf8f4ce1847b9ace6c8641acf3a4.pdf
Last Layer Re-Training is Sufficient for Robustness to Spurious Correlations,2022,ICML,"['Polina Kirichenko', 'Pavel Izmailov', 'Andrew Gordon Wilson']",oral,"['spurious correlations', 'robustness', 'representation learning']","Neural network classifiers can largely rely on simple spurious features, such as backgrounds, to make predictions. However, even in these cases, we show that they still often learn core features associated with the desired attributes of the data, contrary to recent findings. Inspired by this insight, we demonstrate that simple last layer retraining can match or outperform state-of-the-art approaches on spurious correlation benchmarks, but with profoundly lower complexity and computational expenses. Moreover, we show that last layer retraining on large ImageNet-trained models can also significantly reduce reliance on background and texture information, improving robustness to covariate shift, after only minutes of training on a single GPU.",https://api.openreview.net/pdf/711d78638f5b5867e3cfe4383a98ee5dece0900e.pdf
Efficient Continuous Spatio-Temporal Simulation with Graph Spline Networks,2022,ICML,"['Chuanbo Hua', 'Federico Berto', 'Michael Poli', 'Stefano Massaroli', 'Jinkyoo Park']",oral,"['Graph', 'Spline Collocation Method', 'Graph Neural Networks', 'Simulation', 'Partial Differential Equations', 'PDEs', 'Physics', 'Scientific Computing']","Complex simulation of physical systems is an invaluable tool for a large number of fields, including engineering and scientific computing. To overcome the computational requirements of high-accuracy solvers, learned graph neural network simulators have recently been introduced. However, these methods often require a large number of nodes and edges, which can hinder their performance. Moreover, they cannot evaluate continuous solutions in space and time due to their inherently discretized structure. In this paper, we propose GraphSplineNets, a method based on graph neural networks and orthogonal spline collocation (OSC) to accelerate learned simulations of physical systems by interpolating solutions of graph neural networks. First, we employ an encoder-decoder message passing graph neural network to map the location and value of nodes from the physical domain to hidden space and learn to predict future values. Then, to realize fully continuous simulations over the domain without dense sampling of nodes, we post-process predictions with OSC. This strategy allows us to produce a solution at any location in space and time without explicit prior knowledge of underlying differential equations and with a lower computational burden compared to learned graph simulators evaluating more space-time locations. We evaluate the performance of our approach in heat equation, dam breaking, and flag simulations with different graph neural network baselines. Our method shows is consistently Pareto efficient in terms of simulation accuracy and inference time, i.e. 3x speedup with 10%  less error on flag simulation.",https://api.openreview.net/pdf/c01351455f7e94812931d21bc40c5cb7d7405bd2.pdf
Understanding the evolution of tumours using hybrid deep generative models,2022,ICML,"['Tom William Ouellette', 'Philip Awadalla']",oral,"['tumour evolution', 'deep generative models', 'simulation-based inference', 'subclonal clustering', 'cancer', 'subclonal dynamics']","Understanding both the evolutionary dynamics and subpopulation or subclonal structure that impacts tumour progression has important clinical implications for patients. However, deconvoluting subclonal structure and performing evolutionary parameter inference have largely been treated as two independent or step-wise tasks. Here, we show that combining stochastic simulations with hybrid deep generative models enables joint inference of subclonal structure and evolutionary parameters. Ultimately, by jointly learning these two problems, we show that our proposed approach leads to improved performance across a multitude of cancer evolution tasks including, but not limited to, detecting subclones, quantifying subclone frequency, and estimating mutation rate. As an additional benefit, we also show that hybrid deep generative models also provide substantial reductions in inference time relative to existing methods.",https://api.openreview.net/pdf/a24e2817b741a8311f77f4a238680d492dff9883.pdf
Learning to Solve PDE-constrained Inverse Problems with Graph Networks,2022,ICML,"['Qingqing Zhao', 'David B. Lindell', 'Gordon Wetzstein']",oral,[],"Learned graph neural networks (GNNs) have recently been established as fast and accurate alternatives for principled solvers in simulating the dynamics of physical systems. In many application domains across science and engineering, however, we are not only interested in a forward simulation but also in solving inverse problems with constraints defined by a partial differential equation (PDE). Here we explore GNNs to solve such PDE-constrained inverse problems. Given a sparse set of measurements, we are interested in recovering the initial condition or parameters of the PDE. We demonstrate that GNNs combined with autodecoder-style priors are well-suited for these tasks, achieving more accurate estimates of initial conditions or physical parameters than other learned approaches when applied to the wave equation or Navier Stokes equations. We also demonstrate computational speedups of up to 90x using GNNs compared to principled solvers.
",https://api.openreview.net/pdf/2944cc5881c0152a5cb3416efede59b524d09b79.pdf
A Density Functional Recommendation Approach for Accurate Predictions of Vertical Spin Splitting of Transition Metal Complexes,2022,ICML,"['Chenru Duan', 'Aditya Nandy', 'Heather Kulik']",oral,"['density functional theory', 'transition metal chemistry', 'recommender', 'high throughput computation']","Both conventional and machine learning-based density functional approximations (DFAs) have emerged as versatile approaches for virtual high-throughput screening and chemical discovery. To date, however, no single DFA is universally accurate for different chemical spaces. This DFA sensitivity is particularly high for open-shell transition-metal-containing systems, where strong static correlation may dominate. With electron density fitting and transfer learning, we build a DFA recommender that selects the DFA with the lowest expected error in a system-dependent manner. We demonstrate this recommender approach on the prediction of vertical spin-splitting energies (i.e., the electronic energy difference between the high-spin and low-spin state) of challenging transition metal complexes. This recommender yields relatively small errors (i.e., 2.1 kcal/mol) for transition metal chemistry and captures the distributions of the DFAs that are most likely to be accurate.",https://api.openreview.net/pdf/ac008f1ab6d19ff401199133fb59f952e56a841b.pdf
The StarCraft Multi-Agent Challenges+ : Learning of Sub-tasks and Environmental Benefits without Precise Reward Functions,2022,ICML,"['Mingyu Kim', 'Jihwan Oh', 'Yongsik Lee', 'Joonkee Kim', 'SeongHwan Kim', 'Song Chong', 'Se-Young Yun']",spotlight,"['Benchmark', 'Multi-agent reinforcement learning']"," In this paper, we propose a novel benchmark called SMAC$^{+}$, where agents are supposed to implicitly learn a way to complete sub-tasks or to use environmental benefits without precise reward functions. The StarCraft Multi-Agent Challenges (SMAC) recognized as a standard benchmark of Multi-Agent Reinforcement Learning (MARL) is mainly concerned with ensuring that all agents cooperatively eliminate approaching adversaries only through fine manipulation with obvious reward functions. SMAC$^{+}$, on the other hand, is interested in the ability of MARL algorithms to effectively discover sub-tasks. In the offensive scenarios, agents must learn to find opponents first and then eliminate them, and the defensive scenarios need agents to use topographic features such as placing behind structures to lower the possibility of being attacked by enemies. In these scenarios, MARL algorithms must learn indirectly how they accomplish sub-tasks without direct incentives. We investigate MARL algorithms under SMAC$^{+}$ and observe that recent approaches work well in similar settings to the previous challenges but misbehave in offensive scenarios, even when training time is significantly extended. We also discover that risk-based extra exploration approach has a positive effect on performance through the completion of sub-tasks.",https://api.openreview.net/pdf/c3ccf69b5122ac21a1c4481f8810b7d6d904e55e.pdf
High Performance Simulation for Scalable Multi-Agent Reinforcement Learning,2022,ICML,"['Jordan Langham-Lopez', 'Sebastian M Schmon', 'Patrick Cannon']",spotlight,"['Multi-Agent Reinforcement Learning', 'Reinforcement Learning', 'Agent Based Modelling', 'High Performance', 'GPU']","Multi-agent reinforcement learning experiments and open-source training environments are typically limited in scale, supporting tens or sometimes up to hundreds of interacting agents. In this paper we demonstrate the use of Vogue, a high performance agent based modelling framework. Vogue serves as a multi-agent training environment, supporting thousands to tens of thousands of interacting agents while maintaining high training throughput by running both the environment and reinforcement learning agents on the GPU. 
High performance multi-agent environments at this scale have the potential to enable the learning of robust and flexible policies for use in agent based models and simulations of complex systems. We demonstrate training performance with two newly developed, large scale multi-agent training environments. Moreover, we show that these environments can train shared reinforcement learning policies on time-scales of minutes and hours.",https://api.openreview.net/pdf/04d6c32d4ebe9683f4b0be0f2884651b43e08945.pdf
Calibrating Agent-based Models to Microdata with Graph Neural Networks,2022,ICML,"['Joel Dyer', 'Patrick Cannon', 'J. Doyne Farmer', 'Sebastian M Schmon']",spotlight,"['simulation-based inference', 'graph neural networks', 'microdata', 'agent-based models']","Calibrating agent-based models to data is among the most fundamental requirements to ensure the model fulfils its desired purpose. In recent years, simulation-based inference methods have emerged as powerful tools for performing this task when the model likelihood function is intractable, as is often the case for agent-based models. In some real-world use cases of agent-based models, both the observed data and the agent-based model output consist of the agents' states and their interactions over time. In such cases, there is a tension between the desire to make full use of the rich information content of such granular data on the one hand, and the need to reduce the dimensionality of the data to prevent difficulties associated with high-dimensional learning tasks on the other. A possible resolution is to construct lower-dimensional time-series through the use of summary statistics describing the macrostate of the system at each time point. However, a poor choice of summary statistics can result in an unacceptable loss of information from the original dataset, dramatically reducing the quality of the resulting calibration. In this work, we instead propose to learn parameter posteriors associated with granular microdata directly using temporal graph neural networks. We will demonstrate that such an approach offers highly compelling inductive biases for Bayesian inference using the raw agent-based model microstates as output.",https://api.openreview.net/pdf/e05894b81f11d7e2b8dbec65165da1f64d98674e.pdf
Generating Diverse Cooperative Agents by Learning Incompatible Policies,2022,ICML,"['Rujikorn Charakorn', 'Poramate Manoonpong', 'Nat Dilokthanakul']",spotlight,"['multi-agent systems', 'cooperative', 'reinforcement learning', 'diversity', 'paper']","Effectively training a robust agent that can cooperate with unseen agents requires diverse training partner agents. Nonetheless, obtaining cooperative agents with diverse behaviors is a challenging task. Previous work proposes learning a diverse set of agents by diversifying the state-action distribution of the agents. However, without information about the task's goal, the diversified behaviors are not motivated to find other important, albeit non-optimal, solutions, resulting in only local variations of a solution. In this work, we propose to learn diverse behaviors by looking at policy compatibility while using state-action information to induce local variations of behaviors. Conceptually, policy compatibility measures whether policies of interest can collectively solve a task. We posit that incompatible policies can be behaviorally different. Based on this idea, we propose a novel objective to learn diverse behaviors. We theoretically show that our novel objective can generate a dissimilar policy, which we incorporate into a population-based training scheme. Empirically, the proposed method outperforms the baselines in terms of the number of discovered solutions given the same number of agents.",https://api.openreview.net/pdf/9f46274b1b3d09a092eabe34cb6a41868444ed94.pdf
Effective Offline RL Needs Going Beyond Pessimism: Representations and Distributional Shift,2022,ICML,"['Xinyang Geng', 'Kevin Li', 'Abhishek Gupta', 'Aviral Kumar', 'Sergey Levine']",poster,"['Offline reinforcement learning', 'representation leanring']","Standard off-policy reinforcement learning (RL) methods based on temporal difference (TD) learning generally fail to learn good policies when applied to static offline datasets. Conventionally, this is attributed to distribution shift, where the Bellman backup queries high-value out-of-distribution (OOD) actions for the next time step, which then leads to systematic overestimation. However, this explanation is incomplete, as conservative offline RL methods that directly address overestimation still suffer from stability problems in practice. This suggests that although OOD actions may account for part of the challenge, the difficulties with TD learning in the offline setting are also deeply connected to other aspects such as the quality of representations of learned function approximators. In this work, we demonstrate that merely imposing pessimism is not sufficient for good performance, and demonstrate empirically that regularizing representations actually accounts for a large part of the improvement observed in modern offline RL methods. Building on this insight, we identify concrete metrics that enable effective diagnosis of the quality of the learned representation, and are able to adequately predict performance of the underlying method. Finally, we show that a simple approach for handling representations, without any changing any other aspect of conservative offline RL algorithms can lead to better performance in several offline RL problems. ",https://api.openreview.net/pdf/4bc4d77a267a0d91ad228f4b44f8a788dd7e6cf3.pdf
Hyperbolically Discounted Advantage Estimation for Generalization in Reinforcement Learning,2022,ICML,"['Nasik Muhammad Nafi', 'Raja Farrukh Ali', 'William Hsu']",poster,"['Reinforcement Learning', 'Generalization', 'Hyperbolic Discounting', 'Procgen']","In reinforcement learning (RL), agents typically discount future rewards using an exponential scheme. However, studies have shown that humans and animals instead exhibit hyperbolic time-preferences and thus discount future rewards hyperbolically. In the quest for RL agents that generalize well to previously unseen scenarios, we study the effects of hyperbolic discounting on generalization tasks and present Hyperbolic Discounting for Generalization in Reinforcement Learning (HDGenRL). We propose a hyperbolic discounting-based advantage estimation method that makes the agent aware of and robust to the underlying uncertainty of survival and episode duration. On the challenging RL generalization benchmark Procgen, our proposed approach achieves up to 200\% performance improvement over the PPO baseline that uses classical exponential discounting. We also incorporate hyperbolic discounting into another generalization-specific approach (APDAC), and the results indicate further improvement in APDAC's generalization ability. This denotes the effectiveness of our approach as a plug-in to any existing methods in aiding generalization.",https://api.openreview.net/pdf/d48aaa0c56bba3742aad61633a3e7a414407d145.pdf
Goal-Conditioned Generators of Deep Policies,2022,ICML,"['Francesco Faccio', 'Vincent Herrmann', 'Aditya Ramesh', 'Louis Kirsch', 'Jürgen Schmidhuber']",poster,"['Reinforcement Learning', 'Hypernetworks']","Goal-conditioned Reinforcement Learning (RL) aims at learning optimal policies, given goals encoded in special command inputs. Here we study goal-conditioned neural nets (NNs) that learn to generate deep NN policies in form of context-specific weight matrices, similar to Fast Weight Programmers and other methods from the 1990s. Using context commands of the form ""generate a policy that achieves a desired expected return,"" our NN generators combine powerful exploration of parameter space with generalization across commands to iteratively find better and better policies. A form of weight-sharing HyperNetworks and policy embeddings scales our method to generate deep NNs. Experiments show how a single learned policy generator can produce policies that achieve any return seen during training. Finally, we evaluate our algorithm on a set of continuous control tasks where it exhibits competitive performance.",https://api.openreview.net/pdf/1f1f4c54c6a478be66ed2177de47ccfc4e1ddbc2.pdf
CoMBiNED: Multi-Constrained Model Based Planning for Navigation in Dynamic Environments,2022,ICML,"['Harit Pandya', 'Rudra Poudel', 'Stephan Liwicki']",poster,[],"Recent model based planning approaches have attained a huge success on Atari games. However, learning accurate models for complex robotics scenarios such as navigation directly from high dimensional sensory measurements requires a large amount of data and training. Furthermore, even a small change on robot configuration such as kino-dynamics or sensor in the inference time requires re-training of the policy. In this paper, we address these issues in a principled fashion through a multi-constraint model based online planning (CoMBiNED) framework that does not require any retraining or modifications on the existing policy. We disentangle the given task into sub-tasks and learn dynamical models for them. Treating these dynamical models as soft-constraints, we employ stochastic optimisation to jointly optimize these sub-tasks on-the-fly at the inference time. We consider navigation as central application in this work and evaluate our approach on publicly available benchmark with complex dynamic scenarios and achieved significant improvement over recent approaches both in the cases of with-and-without given map of the environment.",https://api.openreview.net/pdf/8d0feb961cb7eb59e1709b3ca2daa46e0343bafe.pdf
A Regret Bound for Greedy Partially Observed Stochastic Contextual Bandits,2022,ICML,"['Hongju Park', 'Mohamad Kazem Shirani Faradonbeh']",poster,"['Contextual bandits', 'Reinforcement learning', 'Adaptive control', 'Iterative learning', 'Statistical learning']","Contextual bandits are widely-used models in reinforcement learning for incorporating both generic and idiosyncratic factors in reward functions. The existing approaches rely on full observation of the context vectors, while the problem of learning optimal arms from partially observed contexts remains immature. We show that in the latter setting, decisions can be made more guarded to minimize the risk of pulling sub-optimal arms. More precisely, efficiency is established for Greedy policies that treat the estimates of the unknown parameter and of the unobserved contexts as their true values. That includes non-asymptotic high probability regret bounds that grow logarithmically with the time horizon and linearly with the number of arms. Numerical results that showcase the efficacy of avoiding exploration are provided as well.",https://api.openreview.net/pdf/49b0625476940429b72f91309f03cde870de3347.pdf
Exploration in Reward Machines with Low Regret,2022,ICML,"['Hippolyte Bourel', 'Anders Jonsson', 'Odalric-Ambrym Maillard', 'Mohammad Sadegh Talebi']",poster,"['reward machine', 'regret minimization', 'non-markovian', 'temporal abstraction']","We study reinforcement learning (RL) for decision processes with non-Markovian reward, in which high-level knowledge in the form of reward machines is available to the learner. Specifically, we investigate the efficiency of RL under the average-reward criterion, in the regret minimization setting. We propose two model-based RL algorithms that each exploits the structure of the reward machines, and show that our algorithms achieve regret bounds that improve over those of baselines by a multiplicative factor proportional to the number of states in the underlying reward machine. To the best of our knowledge, the proposed algorithms and associated regret bounds are the first to tailor the analysis specifically to reward machines, either in the episodic or average-reward settings. We also present a regret lower bound for the studied setting, which indicates that the proposed algorithms achieve a near-optimal regret. Finally, we report numerical experiments that demonstrate the superiority of the proposed  algorithms over existing baselines in practice. ",https://api.openreview.net/pdf/f3e83a070affdfbb53ecae42c34845896c9a9e46.pdf
Exploring Long-Horizon Reasoning with Deep RL in Combinatorially Hard Tasks,2022,ICML,"['Andrew C Li', 'Pashootan Vaezipoor', 'Rodrigo Toro Icarte', 'Sheila A. McIlraith']",poster,"['Reinforcement Learning', 'HRL', 'Combinatorial', 'Reasoning', 'Discount Factors', 'Long Horizon', 'Deep RL']","Deep reinforcement learning has shown promise in discrete domains requiring complex reasoning, including games such as Chess, Go, and Hanabi. However, this type of reasoning is less often observed in long-horizon, continuous domains with high-dimensional observations, where instead RL research has predominantly focused on problems with simple high-level structure (e.g. opening a drawer or moving a robot as fast as possible). Inspired by combinatorially hard optimization problems, we propose a set of robotics tasks which admit many distinct solutions at the high-level, but require reasoning about states and rewards thousands of steps into the future for the best performance. Critically, while RL has traditionally suffered on complex, long-horizon tasks due to sparse rewards, our tasks are carefully designed to be solvable without specialized exploration. Nevertheless, our investigation finds that standard RL methods often neglect long-term effects due to discounting, while general-purpose hierarchical RL approaches struggle unless additional abstract domain knowledge can be exploited.",https://api.openreview.net/pdf/cdf6306889445b53ed490ae149c5ba61d59568e0.pdf
VIPer: Iterative Value-Aware Model Learning on the Value Improvement Path,2022,ICML,"['Romina Abachi', 'Claas A Voelcker', 'Animesh Garg', 'Amir-massoud Farahmand']",poster,"['decision aware model learning', 'representation learning', 'model based reinforcement learning', 'mbrl', 'value improvement path', 'value equivalent model']","We propose a practical and generalizable Decision-Aware Model-Based Reinforcement Learning algorithm. We extend the frameworks of VAML (Farahmand et al., 2017) and IterVAML (Farahmand, 2018), which have been shown to be difficult to scale to high-dimensional and continuous environments (Lovatto et al., 2020a; Modhe et al., 2021; Voelcker et al., 2022). We propose to use the notion of the Value Improvement Path (Dabney et al., 2020) to improve the generalization of VAML-like model learning. We show theoretically for linear and tabular spaces that our proposed algorithm is sensible, justifying extension to non-linear and continuous spaces. We also present a detailed implementation proposal based on these ideas.",https://api.openreview.net/pdf/fd1209e3a3d3ba656b42b9909e33f08446946803.pdf
Model-Based Meta Automatic Curriculum Learning,2022,ICML,"['Zifan Xu', 'Yulin Zhang', 'Shahaf S. Shperberg', 'Reuth Mirsky', 'Yuqian Jiang', 'Bo Liu', 'Peter Stone']",poster,"['Curriculum learning', 'meta learning', 'reinforcement learning']","When an agent trains for one target task, its experience is expected to be useful for training on another target task. This paper formulates the meta curriculum learning problem that builds a sequence of intermediate training tasks, called a curriculum, which will assist the learner to train toward any given target task in general. We propose a model-based meta automatic curriculum learning algorithm (MM-ACL) that learns to predict the performance on one task when trained on another, given contextual information such as the history of training tasks, loss functions, rollout state-action trajectories from the policy, etc. This predictor facilitates the generation of a curriculum that optimizes the performance of the learner on different target tasks. Our empirical results demonstrate that MM-ACL outperforms a random curriculum, a manually created curriculum, and a commonly used non-stationary bandit algorithm in a GridWorld domain.",https://api.openreview.net/pdf/8679667c021494019d746389debbf59fb99457e3.pdf
General Policy Evaluation and Improvement by Learning to Identify Few But Crucial States,2022,ICML,"['Francesco Faccio', 'Aditya Ramesh', 'Vincent Herrmann', 'Jean Harb', 'Jürgen Schmidhuber']",poster,"['Reinforcement Learning', 'Off-Policy Reinforcement Learning']","Learning to evaluate and improve policies is a core problem of Reinforcement Learning (RL). Traditional RL algorithms learn a value function defined for a single policy. A recently explored competitive alternative is to learn a single value function for many policies. Here we combine the actor-critic architecture of Parameter-Based Value Functions and the policy embedding of Policy Evaluation Networks to learn a single value function for evaluating (and thus helping to improve) any policy represented by a deep neural network (NN). The method yields competitive experimental results. In continuous control problems with infinitely many states, our value function minimizes its prediction error by simultaneously learning a small set of  `probing states' and a mapping from actions produced in probing states to the policy's return. The method extracts crucial abstract knowledge about the environment in form of very few states sufficient to fully specify the behavior of many policies. A policy improves solely by changing actions in probing states, following the gradient of the value function's predictions. Surprisingly, it is possible to clone the behavior of a near-optimal policy in Swimmer-v3 and Hopper-v3 environments only by knowing how to act in 3 and 5 such learned states, respectively. Remarkably, our value function trained to evaluate NN policies is also invariant to changes of the policy architecture: we show that it allows for zero-shot learning of linear policies competitive with the best policy seen during training.",https://api.openreview.net/pdf/ff664abd75ad3bbf4a9d51b9bc4ce4f04e94ad10.pdf
An Investigation into the Open World Survival Game Crafter,2022,ICML,"['Aleksandar Stanić', 'Yujin Tang', 'David Ha', 'Jürgen Schmidhuber']",poster,"['Crafter benchmark', 'baselines', 'OOD generalizaiton', 'attention-based agents']","We share our experience with the recently released Crafter benchmark, a 2D open world survival game. Crafter allows tractable investigation of novel agents and their generalization, exploration and long-term reasoning capabilities. We evaluate agents on the original Crafter environment, as well as on a newly introduced set of generalization environments, suitable for evaluating agents' robustness to unseen objects and fast-adaptation (meta-learning) capabilities. Through several experiments we provide a couple of critical insights that are of general interest for future work on Crafter. We find that: (1) Simple agents with tuned hyper-parameters outperform all previous agents. (2) Feedforward agents can unlock almost all achievements by relying on the inventory display. (3) Recurrent agents improve on feedforward ones, also without the inventory information. (4) Baseline agents fail to generalize to OOD objects, object-centric agents improve over them. We will open-source our code.
",https://api.openreview.net/pdf/709e1f3b2e06c9ff29566983781c6f3781c654ef.pdf
Unsupervised Model-based Pre-training for Data-efficient Reinforcement Learning from Pixels,2022,ICML,"['Sai Rajeswar', 'Pietro Mazzaglia', 'Tim Verbelen', 'Alexandre Piché', 'Bart Dhoedt', 'Aaron Courville', 'Alexandre Lacoste']",poster,"['Unsupervised Learning', 'Model-based Reinforcement Learning', 'Sample-Efficiency']","Reinforcement learning (RL) aims at autonomously performing complex tasks. To this end, a reward signal is used to steer the learning process. While successful in many circumstances, the approach is typically data-hungry, requiring large amounts of task-specific interaction between agent and environment to learn efficient behaviors. To alleviate this, unsupervised RL proposes to collect data through self-supervised interaction to accelerate task-specific adaptation. However, whether current unsupervised strategies lead to improved generalization capabilities is still unclear, more so when the input observations are high-dimensional. In this work, we advance the field by closing the performance gap in the Unsupervised RL Benchmark, a collection of tasks to be solved in a data-efficient manner, after interacting with the environment in a self-supervised way. Our approach uses unsupervised exploration for collecting experience to pre-train a world model. Then, when fine-tuning for downstream tasks, the agent leverages the learned model and a hybrid planner to efficiently adapt for the given tasks, achieving comparable results to task-specific baselines, while using 20x less data. We extensively evaluate our work, comparing several exploration methods and improving the fine-tuning process by studying the interactions between the learned components. Furthermore, we investigate the limitations of the pre-trained agent, gaining insights into how these influence the decision process and shedding light on new research directions.",https://api.openreview.net/pdf/ec142f729ad8de4c3a7af56a6e064989710f2c71.pdf
Model-Based Reinforcement Learning with SINDy,2022,ICML,"['Rushiv Arora', 'Eliot Moss', 'Bruno Castro da Silva']",poster,"['model-based Reinforcement Learning', 'model learning', 'non-linear dynamical systems']","We draw on the latest advancements in the physics community to propose a novel
method for discovering the governing non-linear dynamics of physical systems
in reinforcement learning (RL).  We establish that this method is capable of
discovering the underlying dynamics using significantly fewer trajectories (as
little as one rollout with $\leq 30$ time steps) than state of the art model
learning algorithms.  Further, the technique learns a model that is accurate
enough to induce near-optimal policies given significantly fewer trajectories
than those required by model-free algorithms.  It brings the benefits of
model-based RL without requiring a model to be developed in advance, for
systems that have physics-based dynamics.

To establish the validity and applicability of this algorithm, we conduct
experiments on four classic control tasks.  We found that an optimal policy
trained on the discovered dynamics of the underlying system can generalize
well.  Further, the learned policy performs well when deployed on the actual
physical system, thus bridging the model to real system gap.  We further
compare our method to state-of-the-art model-based and model-free approaches,
and show that our method requires fewer trajectories sampled on the true
physical system compared other methods.  Additionally, we explored approximate
dynamics models and found that they also can perform well.",https://api.openreview.net/pdf/a8a85a8844119bc715d1aff1b9eb2e40bcb6bdc4.pdf
Toward Human Cognition-inspired High-Level Decision Making For Hierarchical Reinforcement Learning Agents,2022,ICML,"['Rousslan Fernand Julien Dossa', 'Takashi Matsubara']",poster,"['Reinforcement learning', 'hierarchical reinforcement learning', 'world models', 'temporal abstraction', 'hierarchically organized behavior']","The ability of humans to efficiently understand and learn to solve complex tasks with relatively limited data is attributed to our hierarchically organized decision-making process.
Meanwhile, sample efficiency is a long-standing challenge for reinforcement learning (RL) agents, especially in long-horizon, sequential decision-making tasks with sparse and delayed rewards.
Hierarchical reinforcement learning (HRL) augments RL agents with temporal abstraction to improve their efficiency in such complex tasks.
However, the decision-making process of most HRL methods is often based directly on dense low-level information, while also using fixed temporal abstraction.
We propose the hierarchical world model (HWM), which is geared toward capturing more flexible high-level, temporally abstract dynamics, as well as low-level dynamics of the task.
Preliminary experiments on using the HWM with model-based RL resulted in improved sample efficiency and final performance.
An investigation of the state representations learned by the HWM also shows their alignment with human intuition and understanding.
Finally, we provide a theoretical foundation for integrating the proposed HWM with the HRL framework, thus building toward RL agents with hierarchically structured decision-making which aligns with the theorized principles of human cognition and decision process.",https://api.openreview.net/pdf/c7cb2195e952403362033def24f3743695345a5d.pdf
MoCoDA: Model-based Counterfactual Data Augmentation,2022,ICML,"['Silviu Pitis', 'Elliot Creager', 'Ajay Mandlekar', 'Animesh Garg']",poster,"['reinforcement learning', 'off-policy reinforcement learning', 'model-based reinforcement learning', 'offline reinforcement learning', 'data augmentation']","The number of states in a dynamic process is exponential in the number of objects, making  reinforcement learning (RL) difficult in complex, multi-object domains. For agents to scale to the real world, they will need to react to and reason about unseen combinations of objects. We argue that the ability to recognize and use local factorization in transition dynamics is a key element in unlocking the power of multi-object reasoning. To this end, we show that (1) known local structure in the environment transitions is sufficient for an exponential reduction in the sample complexity of training a dynamics model, and (2) a locally factored dynamics model provably generalizes out-of-distribution to unseen states and actions. Knowing the local structure also allows us to predict which unseen states and actions this dynamics model will generalize to. We propose to leverage these observations in a novel Model-based Counterfactual Data Augmentation (MoCoDA) framework. MoCoDA applies a learned locally factored dynamics model to an augmented distribution of states and actions to generate counterfactual transitions for RL. MoCoDA works with a broader set of local structures than prior work and allows for direct control over the augmented training distribution. We show that MoCoDA enables RL agents to learn policies that generalize to unseen states and actions. We use MoCoDA to train an offline RL agent to solve an out-of-distribution robotics manipulation task on which standard offline RL algorithms fail. ",https://api.openreview.net/pdf/15718f431eef7ee142fd33ecdfc167e0393cbfac.pdf
An Adaptive Entropy-Regularization Framework for Multi-Agent Reinforcement Learning,2022,ICML,"['Woojun Kim', 'Youngchul Sung']",poster,"['Multi-Agent Reinforcement Learning', 'Entropy regularization', 'Exploration']","In this paper, we propose an adaptive entropy-regularization framework (ADER) for multi-agent reinforcement learning (RL) to learn the adequate amount of exploration for each agent based on the degree of required exploration. In order to handle instability arising from updating multiple entropy temperature parameters for multiple agents, we disentangle the soft value function into two types: one for pure reward and the other for entropy. By applying multi-agent value factorization to the disentangled value function of pure reward, we obtain a relevant metric to assess the necessary degree of exploration for each agent. Based on this metric, we propose the ADER algorithm based on maximum entropy RL, which controls the necessary level of exploration across agents over time by learning the proper target entropy for each agent. Experimental results show that the proposed scheme significantly outperforms current state-of-the-art multi-agent RL algorithms. ",https://api.openreview.net/pdf/f438194519b94a26bc6624c0b8bfc0cf57a493b1.pdf
Leader-based Decision Learning for Cooperative Multi-Agent Reinforcement Learning,2022,ICML,"['Wenqi Chen', 'Xin Zeng', 'Amber Li']",poster,"['multi-agent reinforcement learning', 'leader-based decision learning']","A leader in the team enables efficient learning for other novices in the social learning setting for both humans and animals. This paper constructs the leader-based decision learning framework for Multi-Agent Reinforcement Learning and investigates whether the leader enables the learning of novices as well. We compare three different approaches to distilling a leader's experiences: Linear Layer Dimension Reduction, Attentive Graph Pooling, and Attention-based Graph Neural Network. We successfully show that a leader-based decision learning can 1) enable agents to learn faster, cooperate more effectively, and escape local optimum, and 2) promote the generalizability of agents in more challenging and unseen environments. The key to effective distillation is to maintain and aggregate important information.",https://api.openreview.net/pdf/b3d8043ecb5c9ed3fc679bebdf76cce528d06280.pdf
Non-Markovian Policies for Unsupervised Reinforcement Learning in Multiple Environments,2022,ICML,"['Pietro Maldini', 'Mirco Mutti', 'Riccardo De Santi', 'Marcello Restelli']",poster,[],"In recent years, the area of Unsupervised Reinforcement Learning (URL) has gained particular relevance as a way to foster generalization of reinforcement learning agents. In this setting, the agent's policy is first pre-trained in an unknown environment via reward-free interactions, often through a pure exploration objective that drives the agent towards a uniform coverage of the state space. It has been shown that this pre-training leads to improved efficiency in downstream supervised tasks later given to the agent to solve. When dealing with the unsupervised pre-training in multiple environments one should also account for potential trade-offs in the exploration performance within the set of environments, which leads to the following question: Can we pre-train a policy that is simultaneously optimal in all the environments? In this work, we address this question by proposing a novel non-Markovian policy architecture to be pre-trained with the common maximum state entropy objective. This architecture showcases significant empirical advantages when compared to state-of-the-art Markovian agents for URL.",https://api.openreview.net/pdf/4907bf869a05affb75c3af00556cd6f37048c0b5.pdf
Building a Subspace of Policies for Scalable Continual Learning,2022,ICML,"['Jean-Baptiste Gaya', 'Thang Doan', 'Lucas Caccia', 'Laure Soulier', 'Ludovic Denoyer', 'Roberta Raileanu']",poster,"['continual learning', 'deep reinforcement learning']","The ability to continuously acquire new knowledge and skills is crucial for autonomous agents. However, existing methods are typically based on either fixed-size models that cannot capture many diverse behaviors, or growing-size models that scale poorly with the number of tasks. In this paper, we introduce Continual Subspace of Policies (CSP), a method that iteratively learns a subspace of policies in the continual reinforcement learning setting where tasks are presented sequentially. The subspace's high expressivity allows our method to strike a good balance between stability (i.e. not forgetting prior tasks) and plasticity (i.e. learning new tasks), while the number of parameters grows sublinearly with the number of tasks. In addition, CSP displays good transfer, being able to quickly adapt to new tasks including combinations of previously seen ones without additional training. Finally, CSP outperforms state-of-the-art methods on a wide range of scenarios in two different domains. An interactive visualization of the subspace can be found at https://continual-subspace-policies-streamlit-app-gofujp.streamlitapp.com/.",https://api.openreview.net/pdf/42a4f44d4c6e176218bfede6407fdccffde87f01.pdf
DASCO: Dual-Generator Adversarial Support Constrained Offline Reinforcement Learning,2022,ICML,"['quan vuong', 'Aviral Kumar', 'Sergey Levine', 'Yevgen Chebotar']",poster,"['Offline Reinforcement Learning', 'Generative Adversarial Networks']","In offline RL, constraining the learned policy to remain close to the data is essential to prevent the policy from outputting out-of-distribution (OOD) actions with erroneously overestimated values. In principle, generative adversarial networks (GAN) can provide an elegant solution to do so, with the discriminator directly providing a probability that quantifies distributional shift. However, in practice, GAN-based offline RL methods have not outperformed alternative approaches, perhaps because the generator is trained to both fool the discriminator and maximize return - two objectives that are often at odds with each other. In this paper, we show that the issue of conflicting objectives can be resolved by training two generators: one that maximizes return, with the other capturing the ""remainder"" of the data distribution in the offline dataset, such that the mixture of the two is close to the behavior policy. We show that not only does having two generators enable an effective GAN-based offline RL method, but also approximates a support constraint, where the policy does not need to match the entire data distribution, but only the slice of the data that leads to high long term performance. We name our method DASCO, for Dual-Generator Adversarial Support Constrained Offline RL. On benchmark tasks that require learning from sub-optimal data, DASCO significantly outperforms prior methods that enforce distribution constraint.
",https://api.openreview.net/pdf/72aef7c615742e2b1c60e724d870a27f804d17ec.pdf
Representation Gap in Deep Reinforcement Learning,2022,ICML,"['Qiang He', 'Huangyuan Su', 'Jieyu Zhang', 'Xinwen Hou']",poster,"['deep reinforcement learning', 'representation learning', 'policy evaluation']","Deep reinforcement learning gives the promise that an agent learns good policy from high-dimensional information. Whereas representation learning removes irrelevant and redundant information and retains pertinent information. We consider the representation capacity of action value function and theoretically reveal its inherent property, representation gap with its target action value function. This representation gap is favorable. However, through illustrative experiments, we show that the representation of action value function grows similarly compared with its target value function, i.e. the undesirable inactivity of the representation gap (representation overlap). Representation overlap results in a loss of representation capacity, which further leads to sub-optimal learning performance. To activate the representation gap, we propose a simple but effective framework Policy Optimization from Preventing Representation Overlaps (POPRO), which regularizes the policy evaluation phase through differing the representation of action value function from its target. We also provide the convergence rate guarantee of POPRO. We evaluate POPRO on gym continuous control suites. The empirical results show that POPRO using pixel inputs outperforms or parallels the sample-efficiency of methods that use state-based features. ",https://api.openreview.net/pdf/1121ce32c14cc428e23407d74c0e13524533488a.pdf
Challenges and Opportunities in Offline Reinforcement Learning from Visual Observations,2022,ICML,"['Cong Lu', 'Philip J. Ball', 'Tim G. J. Rudner', 'Jack Parker-Holder', 'Michael A Osborne', 'Yee Whye Teh']",poster,[],"Offline reinforcement learning has shown great promise in leveraging large pre-collected datasets for policy learning, allowing agents to forgo often-expensive online data collection. However, to date, offline reinforcement learning from visual observations with continuous action spaces has been relatively under-explored, and there is a lack of understanding of where the remaining challenges lie. In this paper, we seek to establish simple baselines for continuous control in the visual domain. We show that simple modifications to two state-of-the-art vision-based online reinforcement learning algorithms, DreamerV2 and DrQ-v2, suffice to outperform prior work and establish a competitive baseline. We rigorously evaluate these algorithms on both existing offline datasets and a new testbed for offline reinforcement learning from visual observations that better represents the data distributions present in real-world offline RL problems, and open-source our code and data to facilitate progress in this important domain. Finally, we present and analyze several key desiderata unique to offline RL from visual observations, including visual distractions and visually identifiable changes in dynamics.",https://api.openreview.net/pdf/aab0ae0a6991577f528972988e6aa828dc45370f.pdf
Giving Feedback on Interactive Student Programs with Meta-Exploration,2022,ICML,"['Evan Zheran Liu', 'Moritz Pascal Stephan', 'Allen Nie', 'Christopher J Piech', 'Emma Brunskill', 'Chelsea Finn']",poster,"['meta-reinforcement learning', 'education']","Creating interactive software, such as websites or games, is a particularly engaging way to learn computer science. However, teaching and giving feedback on such software is hard — standard approaches require instructors to hand grade student-implemented interactive programs. As a result, online platforms that serve millions, like Code.org, are unable to provide any feedback on assignments for implementing interactive programs, which critically hinders students’ ability to learn. Recent work proposes to train reinforcement learning agents to interact with a student’s program, aiming to explore states indicative of errors. However, this approach only provides binary feedback of whether a program is correct or not, while students require finer-grained feedback on the specific errors in their programs to understand their mistakes. In this work, we show that exploring to discover errors can be cast as a meta-exploration problem. This enables us to construct a principled objective for discovering errors and an algorithm for optimizing this objective, which provides fine-grained feedback. We evaluate our approach on a set of 700K real anonymized student programs from a Code.org interactive assignment. Our approach provides feedback with 94.3% accuracy, improving over existing approaches by over 17.7% and coming within 1.5% of human-level accuracy.",https://api.openreview.net/pdf/c242a27498828ea312b3b1091c1959462189ac91.pdf
When to Ask for Help: Proactive Interventions in Autonomous Reinforcement Learning,2022,ICML,"['Annie Xie', 'Fahim Tajwar', 'Archit Sharma', 'Chelsea Finn']",poster,[],"A long-term goal of reinforcement learning is to design agents that can autonomously interact and learn in the world. A critical challenge to such autonomy is the presence of irreversible states which require external assistance to recover from, such as when a robot arm has pushed an object off of a table. While standard agents require constant monitoring to decide when to intervene, we aim to design proactive agents that can request human intervention only when needed. To this end, we propose an algorithm that can efficiently learns to detect and avoid states that are irreversible, and proactively ask for help in case the agent does enter them. On a suite of continuous control environments with unknown irreversible states, we find that our algorithm exhibits both better sample- and intervention-efficiency compared to existing methods.",https://api.openreview.net/pdf/18f30a723ebdae5ce6bd1f1875d087cb898fb7ed.pdf
Beyond the Return: Off-policy Function Estimation under User-specified Error-measuring Distributions,2022,ICML,"['Audrey Huang', 'Nan Jiang']",poster,[],"Off-policy evaluation often refers to two related tasks: estimating the expected return of a policy and estimating its value function (or other functions of interest, such as density ratios). While recent works on marginalized importance sampling (MIS) show that the former can enjoy provable guarantees under realizable function approximation, the latter is only known to be feasible under much stronger assumptions such as prohibitively expressive discriminators. In this work, we provide guarantees for off-policy function estimation under only realizability, by imposing proper regularization on the MIS objectives. Compared to commonly used regularization in MIS, our regularizer is much more flexible and can account for an arbitrary user-specified distribution, under which the learned function will be close to the ground truth. We provide exact characterization of the optimal dual solution that needs to be realized by the discriminator class, which determines the data-coverage assumption in the case of value-function learning. As another surprising observation, the regularizer can be altered to relax the data-coverage requirement, and completely eliminate it in the ideal case with strong side information.",https://api.openreview.net/pdf/7079e872905e216376177217fc2e75efe9c1cdc7.pdf
Maximum-Likelihood Inverse Reinforcement Learning with Finite-Time Guarantees,2022,ICML,"['Siliang Zeng', 'Chenliang Li', 'Alfredo Garcia', 'Mingyi Hong']",poster,"['Inverse Reinforcement Learning', 'Reward Identification']","Inverse reinforcement learning (IRL) aims to recover the reward function and the associated optimal policy that best fits observed sequences of states and actions implemented by an expert. Many algorithms for IRL have an inherent nested structure: the inner loop finds the optimal policy given parametrized rewards while the outer loop updates the estimates towards optimizing a measure of fit. For high dimensional environments such nested-loop structure entails a significant computational burden. To reduce the computational burden of a nested loop, novel methods such as SQIL [1] and IQ-Learn [2] emphasize policy estimation at the expense of reward estimation accuracy. However, without accurate estimated rewards, it is not possible to do counterfactual analysis such as predicting the optimal policy under different environment dynamics and/or learning new tasks. In this paper we develop a novel single-loop algorithm for IRL that does not compromise reward estimation accuracy. In the proposed algorithm, each policy improvement step is followed by a stochastic gradient step for likelihood maximization. We show that the proposed algorithm provably converges to a stationary solution with a finite-time guarantee. If the reward is parameterized linearly, we show the identified solution corresponds to the solution of the maximum entropy IRL problem. Finally, by using robotics control problems in Mujoco and their transfer settings, we show that the proposed algorithm achieves superior performance compared with other IRL and imitation learning benchmarks.",https://api.openreview.net/pdf/c5cb90fc7c9f18a8117466bebea2be7bc671dfc0.pdf
You Can’t Count on Luck: Why Decision Transformers Fail in Stochastic Environments,2022,ICML,"['Keiran Paster', 'Sheila A. McIlraith', 'Jimmy Ba']",poster,"['representation learning', 'reinforcement learning', 'model-based reinforcement learning', 'decision transformer']","Recently, methods such as Decision Transformer that reduce reinforcement learning to a prediction task and solve it via supervised learning (RvS) have become popular due to their simplicity, robustness to hyperparameters, and strong overall performance on offline RL tasks. However, simply conditioning a probabilistic model on a desired return and taking the predicted action can fail dramatically in stochastic environments since trajectories that result in a return may have only achieved that return due to luck. In this work, we describe the limitations of RvS approaches in stochastic environments and propose a solution. Rather than simply conditioning on returns, as is standard practice, our proposed method, ESPER, conditions on learned average returns which are independent from environment stochasticity. Doing so allows ESPER to achieve strong alignment between target return and expected performance in real environments. We demonstrate this in several challenging stochastic offline-RL tasks including the challenging puzzle game 2048, and Connect Four playing against a stochastic opponent. In all tested domains, ESPER achieves significantly better alignment between the target return and achieved return than simply conditioning on returns. ESPER also achieves higher maximum performance than even the value-based baselines.",https://api.openreview.net/pdf/7f10fee9201a02dc66ec3d1ff4d9de611114717d.pdf
Convergence and Price of Anarchy Guarantees of the Softmax Policy Gradient in Markov Potential Games,2022,ICML,"['Dingyang Chen', 'Qi Zhang', 'Thinh T. Doan']",poster,[],"We study the performance of policy gradient methods for the subclass of Markov games known as Markov potential games (MPGs), which extends the notion of normal-form potential games to the stateful setting and includes the important special case of the fully cooperative setting where the agents share an identical reward function. Our focus in this paper is to study the convergence of the policy gradient method for solving MPGs under softmax policy parameterization, both tabular and parameterized with general function approximators such as neural networks. We first show the asymptotic convergence of this method to a Nash equilibrium of MPGs for tabular softmax policies. Second, we derive the finite-time performance of the policy gradient in two settings: 1)  using the log-barrier regularization, and 2) using the natural policy gradient under the best-response dynamics (NPG-BR). Finally, extending the notion of price of anarchy (POA) and smoothness in normal-form games, we introduce the POA for MPGs and provide a POA bound for NPG-BR. To our knowledge, this is the first POA bound for solving MPGs. To support our theoretical results, we empirically compare the convergence rates and POA of policy gradient variants for both tabular and neural softmax policies.",https://api.openreview.net/pdf/f0813fc4818d218dc16949f7cc71f0a991d636a6.pdf
 Fast Convergence for Unstable Reinforcement Learning Problems by Logarithmic Mapping,2022,ICML,"['Wang Zhang', 'Lam M. Nguyen', 'Subhro Das', 'Alexandre Megretski', 'Luca Daniel', 'Tsui-Wei Weng']",poster,"['policy gradient method', 'unstable dynamical system', 'reinforcement learning']","For many of the reinforcement learning applications, the system is assumed to be inherently stable and with bounded reward, state and action space. These are key requirements for the optimization convergence of classical reinforcement learning reward function with discount factors. Unfortunately, these assumptions do not hold true for many real world problems such as an unstable linear–quadratic regulator (LQR). In this work, we propose new methods to stabilize and speed up the convergence of unstable reinforcement learning problems with the policy gradient methods. We provide theoretical insights on the efficiency of our methods. In practice, we achieve good experimental results over multiple examples where the vanilla methods mostly fail to converge due to system instability.",https://api.openreview.net/pdf/63dac04525538f575f0c5d77e62040ca53e8c5e5.pdf
Self-Referential Meta Learning,2022,ICML,"['Louis Kirsch', 'Jürgen Schmidhuber']",poster,"['meta-learning', 'self-referential', 'self-modification', 'meta-optimization', 'reinforcement-learning']","Meta Learning automates the search for learning algorithms. At the same time, it creates a dependency on human engineering on the meta-level, where meta learning algorithms need to be designed. In this paper, we investigate self-referential meta learning systems that modify themselves without the need for explicit meta optimization. We discuss the relationship of such systems to memory-based meta learning and show that self-referential neural networks require functionality to be reused in the form of parameter sharing. Finally, we propose Fitness Monotonic Execution (FME), a simple approach to avoid explicit meta optimization. A neural network self-modifies to solve bandit and classic control tasks, improves its self-modifications, and learns how to learn, purely by assigning more computational resources to better performing solutions.",https://api.openreview.net/pdf/a84652171a688c08a55e2c3e7e18ad41cf19f8bb.pdf
Distributionally Adaptive Meta Reinforcement Learning,2022,ICML,"['Anurag Ajay', 'Dibya Ghosh', 'Sergey Levine', 'Pulkit Agrawal', 'Abhishek Gupta']",poster,"['Meta reinforcement learning', 'Distributional robustness']","Meta-reinforcement learning algorithms provide a data-driven way to acquire learning algorithms that quickly adapt to many tasks with varying rewards or dynamics functions. However, learned meta-policies are often effective only on the exact task distribution on which the policy was trained, and struggle in the presence of distribution shift of test-time rewards or transition dynamics. In this work, we develop a framework for meta-RL algorithms that are able to behave appropriately under test-time distribution shifts in the space of tasks. Our framework centers on an adaptive approach to distributional robustness, in which we train a population of meta-agents to be robust to varying levels of distribution shift, so that when evaluated on a (potentially shifted) test-time distribution of tasks, we can adaptively choose the most appropriate meta-agent to follow. We formally show how this framework allows for improved regret under distribution shift, and empirically show its efficacy on simulated robotics problems under a wide range of distribution shifts.",https://api.openreview.net/pdf/a9cafbc6a674c6868c5ec4766e4c8d855b88653f.pdf
You Only Live Once: Single-Life Reinforcement Learning via Learned Reward Shaping ,2022,ICML,"['Annie S Chen', 'Archit Sharma', 'Sergey Levine', 'Chelsea Finn']",poster,"['reinforcement learning', 'autonomous reinforcement learning', 'adversarial imitation learning']","Reinforcement learning algorithms are typically designed to learn a performant policy that can repeatedly and autonomously complete a task, typically starting from scratch. However, many real-world situations operate under a different set of assumptions: the goal might not be to learn a policy that can do the task repeatedly, but simply to perform a new task successfully once, ideally as quickly as possible, and while leveraging some prior knowledge or experience. For example, imagine a robot that is exploring another planet, where it cannot get help or supervision from humans. If it needs to navigate to a crater that it has never seen before in search of water, it does not really need to acquire a policy for reaching craters reliably, it only needs to reach this particular crater once. It must do so without the benefit of episodic resets and tackle a new, unknown terrain, but it can leverage prior experience it acquired on Earth. We formalize this problem setting, which we call single-life reinforcement learning (SLRL), where an agent must complete a task once while contending with some form of novelty in a single trial without interventions, given some prior data. In this setting, we find that algorithms designed for standard episodic reinforcement learning can struggle, as they have trouble recovering from novel states especially when informative rewards are not provided. Motivated by this observation, we also propose an algorithm, $Q$-weighted adversarial learning (QWALE), that addresses the dearth of supervision by employing a distribution matching strategy that leverages the agent's prior experience as guidance in novel situations. Our experiments on several single-life continuous control problems indicate that methods based on our distribution matching formulation are 20-60% more successful because they can more quickly recover from novel, out-of-distribution states.",https://api.openreview.net/pdf/b8d0ed94a74803868a10b79aeb1b756c7a7651da.pdf
Directed Exploration via Uncertainty-Aware Critics,2022,ICML,"['Amarildo Likmeta', 'Matteo Sacco', 'Alberto Maria Metelli', 'Marcello Restelli']",poster,"['Reinforcement Learning', 'Continuous-Actions Control', 'Uncertainty-Aware Critic', 'Optimistic Exploration']","The exploration-exploitation dilemma is still an open problem in Reinforcement Learning (RL), especially when coped with deep architectures and in the context of continuous action spaces. Uncertainty quantification has been extensively used as a means to achieve efficient directed exploration. However, state-of-the-art methods for continuous actions still suffer from high sample complexity requirements. Indeed, they either completely lack strategies for propagating the epistemic uncertainty throughout the updates, or they mix it with aleatory uncertainty while learning the full return distribution (e.g., distributional RL). In this paper, we propose Wasserstein Actor-Critic (WAC), an actor-critic architecture inspired by the recent Wasserstein Q-Learning (WQL) (Metelli et al., 2019), that employs approximate Q-posteriors to represent the epistemic uncertainty and Wasserstein barycenters for uncertainty propagation across the state-action space. WAC enforces exploration in a principled way by guiding the policy learning process with the optimization of an upper bound of the Q-value estimates. Furthermore, we study some peculiar issues that arise when using function approximation, coupled with the uncertainty estimation, and propose a regularized loss for the uncertainty estimation. Finally, we evaluate our algorithm
on a suite of continuous-actions domains, where exploration is crucial, in comparison with state-of-the-art baselines. Our experiments show a clear benefit of using uncertainty-aware critics for continuous-actions control.",https://api.openreview.net/pdf/6bec9ec9605177099aebb7c18a22d9163129836d.pdf
Adversarial Cheap Talk,2022,ICML,"['Chris Lu', 'Timon Willi', 'Alistair Letcher', 'Jakob Nicolaus Foerster']",poster,[],"Adversarial attacks in reinforcement learning (RL) often assume highly-privileged access to the learning agent’s parameters, environment or data. Instead, this paper proposes a novel adversarial setting called a Cheap Talk MDP in which an Adversary has a minimal range of influence over the Victim. Parameterised as a deterministic policy that only conditions on the current state, an Adversary can merely append information to a Victim’s observation. To motivate the minimum-viability, we prove that in this setting the Adversary cannot occlude the ground truth, influence the underlying dynamics of the environment, introduce non-stationarity, add stochasticity, see the Victim’s actions, or access their parameters. Additionally, we present a novel meta-learning algorithm to train the Adversary, called adversarial cheap talk (ACT). Using ACT, we demonstrate that the resulting Adversary still manages to influence the Victim’s training and test performance despite these restrictive assumptions. Affecting train-time performance reveals a new attack vector and provides insight into the success and failure modes of existing RL algorithms. More specifically, we show that an ACT Adversary is capable of harming performance by interfering with the learner’s function approximation and helping the Victim’s performance by appending useful features. Finally, we demonstrate that an ACT Adversary can append information during train-time to directly and arbitrarily control the Victim at test-time in a zero-shot manner.",https://api.openreview.net/pdf/24a273f9eadb0f4a43a715dae08ad935acbf4bdb.pdf
Adaptive Intrinsic Motivation with Decision Awareness,2022,ICML,"['Suyoung Lee', 'Sae-Young Chung']",poster,"['Reinforcement learning', 'Exploration', 'Intrinsic motivation']","Intrinsic motivation is a simple but powerful method to encourage exploration, which is one of the fundamental challenges of reinforcement learning. However, we demonstrate that widely used intrinsic motivation methods are highly dependent on the ratio between the extrinsic and intrinsic rewards through extensive experiments on sparse reward MiniGrid tasks. To overcome the problem, we propose an intrinsic reward coefficient adaptation scheme that is equipped with intrinsic motivation awareness and adjusts the intrinsic reward coefficient online to maximize the extrinsic return. We demonstrate that our method, named Adaptive Intrinsic Motivation with Decision Awareness (AIMDA), operates stably in various challenging MiniGrid environments without algorithm-task-specific hyperparameter tuning.",https://api.openreview.net/pdf/bdf2b2ac906f2529d15209df15d44a37f1bb0e80.pdf
Leveraging Factored Action Spaces for Efficient Offline Reinforcement Learning in Healthcare,2022,ICML,"['Shengpu Tang', 'Maggie Makar', 'Michael Sjoding', 'Finale Doshi-Velez', 'Jenna Wiens']",poster,"['reinforcement learning', 'offline rl', 'action space factorization', 'bias-variance trade-off', 'domain knowledge', 'healthcare', 'sepsis']","Many reinforcement learning (RL) applications have combinatorial action spaces, where each action is a composition of sub-actions. A standard RL approach ignores this inherent factorization structure, resulting in a potential failure to make meaningful inferences about rarely observed sub-action combinations; this is particularly problematic for offline settings, where data may be limited. In this work, we propose a form of linear Q-function decomposition induced by factored action spaces. We study the theoretical properties of our approach, identifying scenarios where it is guaranteed to lead to zero bias when used to approximate the Q-function. Outside the regimes with theoretical guarantees, we show that our approach can still be useful because it leads to better sample efficiency without necessarily sacrificing policy optimality, allowing us to achieve a better bias-variance trade-off. Across several offline RL problems using simulators and real-world datasets motivated by healthcare problems, we demonstrate that incorporating factored action spaces into value-based RL can result in better-performing policies. Our approach can help an agent make more accurate inferences within under-explored regions of the state-action space when applying RL to observational datasets. ",https://api.openreview.net/pdf/d3c944a50c9f03e8d267d828841a93149e9faed6.pdf
Dynamic Update-to-Data Ratio: Minimizing World Model Overfitting,2022,ICML,"['Nicolai Dorka', 'Tim Welschehold', 'Wolfram Burgard']",poster,[],"Early stopping based on the validation set performance is a popular approach to find the right balance between under- and overfitting in the context of supervised learning. However, in reinforcement learning, even for supervised sub-problems such as world model learning, early stopping is not applicable as the dataset is continually evolving. As a solution, we propose a new general method that dynamically adjusts the update to data (UTD) ratio during training based on under- and overfitting detection on a small subset of the continuously collected experience not used for training. We apply our method to DreamerV2, a state-of-the-art model-based reinforcement learning algorithm, and evaluate it on the DeepMind Control Suite and the Atari k benchmark. The results demonstrate that one can better balance under- and overestimation by adjusting the UTD ratio with our approach compared to the default setting in DreamerV2 and that it is competitive with an extensive hyperparameter search which is not feasible for many applications. Our method eliminates the need to set the UTD hyperparameter by hand and even leads to a higher robustness with regard to other learning-related hyperparameters further reducing the amount of necessary tuning.",https://api.openreview.net/pdf/c163fedde853faa1db78ac749693e0a6d990735c.pdf
Task Factorization in Curriculum Learning,2022,ICML,"['Reuth Mirsky', 'Shahaf S. Shperberg', 'Yulin Zhang', 'Zifan Xu', 'Yuqian Jiang', 'Jiaxun Cui', 'Peter Stone']",poster,['Curriculum learning'],"A common challenge for learning when applied to a complex ``target'' task is that learning that task all at once can be too difficult due to inefficient exploration given a sparse reward signal.  Curriculum Learning addresses this challenge by sequencing training tasks for a learner to facilitate gradual learning. One of the crucial steps in finding a suitable curriculum learning approach is to understand the dimensions along which the domain can be factorized. In this paper, we identify different types of factorizations common in the literature of curriculum learning for reinforcement learning tasks: factorizations that involve the agent, the environment, or the mission. For each factorization category, we identify the relevant algorithms and techniques that leverage that factorization and present several case studies to showcase how leveraging an appropriate factorization can boost learning using a simple curriculum.",https://api.openreview.net/pdf/4078670e2f3c7865dd0fab124d699d3f345b7504.pdf
SAFER: Data-Efficient and Safe Reinforcement Learning via Skill Acquisition,2022,ICML,"['Dylan Z Slack', 'Yinlam Chow', 'Bo Dai', 'Nevan Wichers']",poster,"['primitive learning', 'safety', 'offline reinforcement learning']","Methods that extract policy primitives from offline demonstrations using deep generative models have shown promise at accelerating reinforcement learning (RL) for new tasks. Intuitively, these methods should also help to train safe RL agents because they enforce useful skills. However, we identify these techniques are not well equipped for safe policy learning because they ignore negative experiences (e.g., unsafe or unsuccessful), focusing only on positive experiences, which harms their ability to generalize to new tasks safely. Rather, we model the latent safety context using principled contrastive training on an offline dataset of demonstrations from many tasks, including both negative and positive experiences. Using this latent variable, our RL framework, SAFEty skill pRiors (SAFER) extracts task specific safe primitive skills to safely and successfully generalize to new tasks. In the inference stage, policies trained with SAFER learn to compose safe skills into successful policies. We theoretically characterize why SAFER can enforce safe policy learning and demonstrate its effectiveness on several complex safety- critical robotic grasping tasks inspired by the game Operation, in which SAFER outperforms state-of-the-art primitive learning methods in success and safety.
",https://api.openreview.net/pdf/92abdd1a677b3e703ba1d670b906a78f9afaba25.pdf
Guided Exploration in Reinforcement Learning via Monte Carlo Critic Optimization,2022,ICML,['Igor Kuznetsov'],poster,"['reinforcement learning', 'exploration', 'Monte Carlo methods']","The class of deep deterministic off-policy algorithms is effectively applied to solve challenging continuous control problems. However, current approaches use random noise as a common exploration method that has several weaknesses, such as a need for manual adjusting on a given task and the absence of exploratory calibration during the training process. We address these challenges by proposing a novel guided exploration method that uses a differential directional controller to incorporate scalable exploratory action correction. An ensemble of Monte Carlo Critics that provides exploratory direction is presented as a controller. The proposed method improves the traditional exploration scheme by changing exploration dynamically. We then present a novel algorithm exploiting the proposed directional controller for both policy and critic modification. The presented algorithm outperforms modern algorithms across a variety of problems from DMControl suite.",https://api.openreview.net/pdf/9759274a06f1ff7dc0327e2d7655860076144f4b.pdf
Deciding What to Model: Value-Equivalent Sampling for Reinforcement Learning,2022,ICML,"['Dilip Arumugam', 'Benjamin Van Roy']",poster,"['Reinforcement learning', 'Efficient exploration', 'Information theory', 'Bayesian reinforcement learning', 'Value equivalence']","The quintessential model-based reinforcement-learning agent iteratively refines its estimates or prior beliefs about the true underlying model of the environment. Recent empirical successes in model-based reinforcement learning with function approximation, however, eschew the true model in favor of a surrogate that, while ignoring various facets of the environment, still facilitates effective planning over behaviors. Recently formalized as the value equivalence principle, this algorithmic technique is perhaps unavoidable as real-world reinforcement learning demands consideration of a simple, computationally-bounded agent interacting with an overwhelmingly complex environment, whose underlying dynamics likely exceed the agent's capacity for representation. In this work, we consider the scenario where agent limitations may entirely preclude identifying an exactly value-equivalent model, immediately giving rise to a trade-off between identifying a model that is simple enough to learn while only incurring bounded sub-optimality. To address this problem, we introduce an algorithm that, using rate-distortion theory, iteratively computes an approximately-value-equivalent, lossy compression of the environment which an agent may feasibly target in lieu of the true model. We prove an information-theoretic, Bayesian regret bound for our algorithm that holds for any finite-horizon, episodic sequential decision-making problem. Crucially, our regret bound can be expressed in one of two possible forms, providing a performance guarantee for finding either the simplest model that achieves a desired sub-optimality gap or, alternatively, the best model given a limit on agent capacity.",https://api.openreview.net/pdf/4796d8e2a521daafaa5ba31813492f687b240cb1.pdf
Generalization of Reinforcement Learning with Policy-Aware Adversarial Data Augmentation,2022,ICML,"['Hanping Zhang', 'Yuhong Guo']",poster,"['Reinforcement Learning', 'Generalization', 'Policy-Aware Adversarial Data Augmentation']","The generalization gap in reinforcement learning (RL) has been a significant obstacle that prevents the RL agent from learning general skills and adapting to varying environments. Increasing the generalization capacity of the RL systems can significantly improve their performance on real-world working environments. In this work, we propose a novel policy-aware adversarial data augmentation method to augment the standard policy learning method with automatically generated trajectory data. Different from the observation transformation based data augmentations, our proposed method adversarially generates new trajectory data based on the policy gradient objective and aims to more effectively increase the RL agent’s generalization ability with the policy-aware data augmentation. Moreover, we further deploy a mixup step to integrate the original and generated data to enhance the generalization capacity while mitigating the over-deviation of the adversarial data. We conduct experiments on a number of RL tasks to investigate the generalization performance of the proposed method by comparing it with the standard baselines and the state-of-the-art mixreg approach. The results show our method can generalize well with limited training diversity, and achieve the state-of-the-art generalization test performance.",https://api.openreview.net/pdf/540b9bf209a916d5a586dd5ef07c7fbf8364ef4d.pdf
MEPG: A Minimalist Ensemble Policy Gradient Framework for Deep Reinforcement Learning,2022,ICML,"['Qiang He', 'Huangyuan Su', 'Chen GONG', 'Xinwen Hou']",poster,"['Reinforcement Learning', 'Ensemble Learning']","During the training of a reinforcement learning (RL) agent, the distribution of training data is non-stationary as the agent's behavior changes over time. Therefore, there is a risk that the agent is overspecialized to a particular distribution and its performance suffers in the larger picture. Ensemble RL can mitigate this issue by learning a robust policy. However, it suffers from heavy computational resource consumption due to the newly introduced value and policy functions. In this paper, to avoid the notorious resources consumption issue, we design a novel and simple ensemble deep RL framework that integrates multiple models into a single model. Specifically, we propose the Minimalist Ensemble Policy Gradient framework (MEPG), which introduces minimalist ensemble consistent Bellman update by utilizing a modified dropout operator. MEPG holds ensemble property by keeping the dropout consistency of both sides of the Bellman equation. Additionally, the dropout operator also increases MEPG's generalization capability. Moreover, we theoretically show that the policy evaluation phase in the MEPG maintains two synchronized deep Gaussian Processes. To verify the MEPG framework's ability to generalize, we perform experiments on the gym simulator, which presents that the MEPG framework outperforms or achieves a similar level of performance as the current state-of-the-art ensemble methods and model-free methods without increasing additional computational resource costs.",https://api.openreview.net/pdf/43b5ae54a83dd7d3ee3be9acac30edc37321fbf8.pdf
Neuro-Symbolic Language Modeling with Automaton-augmented Retrieval,2022,ICML,"['Uri Alon', 'Frank F. Xu', 'Junxian He', 'Sudipta Sengupta', 'Dan Roth', 'Graham Neubig']",poster,"['nearest', 'neighbors', 'k-nearest neighbors', 'language', 'models', 'automata', 'automaton', 'retomaton']","Retrieval-based language models (R-LM) model the probability of natural language text by combining a standard language model (LM) with examples retrieved from an external datastore at test time. While effective, a major bottleneck of using these models in practice is the computationally costly datastore search, which can be performed as frequently as every time step. In this paper, we present RetoMaton – retrieval automaton – which approximates the datastore search, based on (1) clustering of entries into “states”, and (2) state transitions from previous entries. This effectively results in a weighted finite automaton built on top of the datastore, instead of representing the datastore as a flat list. The creation of the automaton is unsupervised, and a RetoMaton can be constructed from any text collection: either the original training corpus or from another domain. Traversing this automaton at inference time, in parallel to the LM inference, reduces its perplexity, or alternatively saves up to 83% of the nearest neighbor searches over kNN-LM (Khandelwal et al., 2020), without hurting perplexity. 
Our code and trained models are available at https://github.com/neulab/retomaton . 
This is a workshop version of the longer paper that appeared in ICML'2022 (Alon et al., 2022).",https://api.openreview.net/pdf/f6ccfcaf9b61b3c51a030dc8b12a68347cf38fd6.pdf
Matching pre-training and Fine-tuning Methods for Knowledge Retrieval from pretrained Language Models,2022,ICML,['Ahmad Pouramini'],poster,"['Pretrained Language Models', 'Commonsense Knowledge', 'KB Completion']","In this paper we study different methods for pre-training and fine-tuning a transformer-based language model for generating commonsense knowledge or the KB completion task in few-shot settings. The model can be trained in unsupervised and supervised methods with different pre-training objectives. We investigate the effect of each type of these training objectives on the performance of the model in knowledge generationand retrieval. We analyze the results from both plausibility and variety and novelty aspects. The results show that mixing both objectives in pre-training and fine-tuning stages can provide more novel and accurate results in few shot settings.
These considerations can be taken into account for selecting and fine-tuning a model for a specific
task.
",https://api.openreview.net/pdf/b125e202b4c367cce998a69b7cbfef48ff4ee76f.pdf
Knowledge-Consistent Dialogue Generation with Knowledge Graphs,2022,ICML,"['Minki Kang', 'Jin Myung Kwak', 'Jinheon Baek', 'Sung Ju Hwang']",poster,[],"We propose a framework for generating knowledge consistent and context-relevant dialogues with a knowledge graph (KG), named SUbgraph Retrieval-augmented GEneration (SURGE).
First, our method retrieves the context-relevant subgraph from the KG, and then enforces consistency across the facts by perturbing their word embeddings conditioned on the retrieved subgraph. 
Then, it learns the latent representation space using graph-text multi-modal contrastive learning which ensures that the generated texts have high similarity to the retrieved subgraphs. We validate the performance of our SURGE framework on the OpendialKG dataset and show that our method generates high-quality dialogues that faithfully reflect the knowledge from the KG. ",https://api.openreview.net/pdf/3cbcbc47f030dbfa9e2df4a54399f272b4b2a086.pdf
Bridging the Training-Inference Gap for Dense Phrase Retrieval,2022,ICML,"['Gyuwan Kim', 'Jinhyuk Lee', 'Barlas Oguz', 'Wenhan Xiong', 'Yizhe Zhang', 'Yashar Mehdad', 'William Yang Wang']",poster,"['Machine Learning', 'Information Retrieval', 'Question Answering', 'Dense Retrieval', 'Efficiency', 'Validation']","Building dense retrievers requires a series of standard procedures, including training and validating neural models and creating indexes for efficient search. However, these procedures are often misaligned in that training objectives do not exactly reflect the retrieval scenario at inference time. In this paper, we explore how the gap between training and inference in dense retrieval can be reduced, focusing on dense phrase retrieval (Lee et al., 2021) where billions of representations are indexed at inference. Since validating every dense retriever with a large-scale index is practically infeasible, we propose an efficient way of validating dense retrievers using a small subset of the entire corpus. This allows us to validate various training strategies including unifying contrastive loss terms and using hard negatives for phrase retrieval, which largely reduces the training-inference discrepancy. As a result, we improve phrase retrieval by 2-3% in top-1 accuracy and passage retrieval by 2-4% in top-20 accuracy for open-domain question answering. Our work urges modeling dense retrievers with careful consideration of training and inference via efficient validation while advancing phrase retrieval as a general solution for dense retrieval.",https://api.openreview.net/pdf/5c8cdbbb0ccd089bc0699bcc247ff02cf80aad32.pdf
Multi-Task Retrieval-Augmented Text Generation with Relevance Sampling,2022,ICML,"['Sebastian Hofstätter', 'Jiecao Chen', 'Karthik Raman', 'Hamed Zamani']",poster,"['retrieval augmented generation', 'KILT', 'Fusion-in-Decoder']","This paper studies multi-task training of retrieval-augmented generation models for knowledge-intensive tasks.  
We propose to clean the training set by utilizing a distinct property of knowledge-intensive generation: The connection of query-answer pairs to items in the knowledge base. We filter training examples via a threshold of confidence on the relevance labels, whether a pair is answerable by the knowledge base or not.We train a single Fusion-in-Decoder (FiD) generator on seven combined tasks of the KILT benchmark. The experimental results suggest that our simple yet effective approach substantially improves competitive baselines on two strongly imbalanced tasks; and shows either smaller improvements or no significant regression on the remaining tasks. Furthermore, we demonstrate our multi-task training with relevance label sampling scales well with increased model capacity and achieves state-of-the-art results in five out of seven KILT tasks.",https://api.openreview.net/pdf/c4348a9b9d8a1f46b3fdada1cb702d56630e0d43.pdf
SCONER: Scoring Negative Candidates\\Before Training Neural Re-Ranker For Question Answering,2022,ICML,"['Man Luo', 'Mihir Parmar', 'Jayasurya Sevalur Mahendran', 'Sahit Jain', 'Samarth Rawal', 'Chitta Baral']",poster,"['Neural re-ranker', 'question answering']","A neural re-ranker aims to re-scores a set of candidates given by a search engine. 
It is crucial to obtain good performance on many down-stream tasks such as retrieval-based question answering (ReQA). 
In this work, we introduce a scoring function for negative candidates to train a neural re-ranker and compare models trained by our approach with three baselines on a range of ReQA tasks.
We term our approach as SCONER---scoring negative candidates before training neural re-ranker, which includes 1) a scoring function based on the concept of Semantic Textual Similarity (STS) and data augmentation; and 2) a neural re-ranker trained on data using generated negativeness scores as labels. 
Experimental results show that SCONER outperforms three baselines by up to 13\% absolute improvement on the SearchQA dataset and 5.5\% on average across all datasets in terms of P@1. SCONER demonstrates that using different negativeness scores to train a neural-ranker is better than a single score, and we present a simple yet efficient way to generate the scores.",https://api.openreview.net/pdf/b784994ca8c7e1d8178f5331e78fdaf9d1dedf01.pdf
PGT: a prompt based generative transformer for the patent domain,2022,ICML,"['Dimitrios Christofidellis', 'Antonio Berrios Torres', 'Ashish Dave', 'Manuel Roveri', 'Kristin Schmidt', 'Sarath Swaminathan', 'Hans Vandierendonck', 'Dmitry Zubarev', 'Matteo Manica']",poster,"['patent generation', 'nlp', 'transformers']","Patents are a valuable source of knowledge, but drafting them is a time-consuming and expensive task.
Methods that assist patent generation can provide a two-fold improvement as they can speed up the generation process and
suggest to the inventor ideas and claims.
Herein, influenced by recent advances in language modeling via multitask learning and prompt engineering, we present Patent Generative Transformer (PGT), a transformer-based language model trained to facilitate patent drafting.
Specifically, the model supports three tasks: part-of-patent generation, text infilling, and patent coherence evaluation.
PGT complements inventors and assures the fast and successful transition from their input to a coherent patent disclosure taking advantage of its multitasking nature.
We show how the model outperforms a collection of task-specific baselines on relevant metrics. We further test the quality of the generated text via blind testing by subject matter experts.
Finally, we explore a zero-shot extension of the model showing how to use PGT for generating domain-specific abstracts.",https://api.openreview.net/pdf/1e3e4b672739f588e5e22fdf72b3bf4929b4ac20.pdf
Repository-Level Prompt Generation for Large Language Models of Code,2022,ICML,"['Disha Shrivastava', 'Hugo Larochelle', 'Daniel Tarlow']",poster,"['codex', 'large langauge models for source code', 'code-autocompletion', 'information retrieval', 'domain-knowledge']","With the success of large language models (LLMs) of code and their use as code assistants (e.g. Codex (Chen et al., 2021) used in GitHub Copilot), development of techniques where we can have the capability to introduce domain-specific knowledge in the prompt design process becomes important. In this work, we propose a framework called Repo-Level Prompt Generator that learns to generate example-specific prompts using a set of rules. These rules allow us to take context from the entire repository, thereby incorporating both the structure of the repository and the context from other relevant files (e.g. imports, parent class files). Our technique doesn’t require any access to the weights of the LLM, making it applicable in cases where we only have a black- box access to the LLM. We conduct experiments on the task of single line code-autocompletion using code repositories taken from Google Code archives. We demonstrate that an oracle constructed from our proposed rules gives up to 36% relative improvement over Codex, showing the quality of our proposed rules. Further, we show that when we train a model to select the best rule, we can achieve significant performance gains over Codex.",https://api.openreview.net/pdf/f9ebaebc24b79746fdc96a4c15cf9629ef68a352.pdf
Are Large Pre-Trained Language Models Leaking Your Personal Information?,2022,ICML,"['Jie Huang', 'Hanyin Shao', 'Kevin Chang']",poster,"['Analysis of Language Models', 'Privacy', 'Memorization', 'Association']","Are Large Pre-Trained Language Models Leaking Your Personal Information? In this paper, we analyze whether Pre-Trained Language Models (PLMs) are prone to leaking personal information. Specifically, we query PLMs for email addresses with contexts of the email address or prompts containing the owner’s name. We find that PLMs do leak personal information due to memorization. However, since the models are weak at association, the risk of specific personal information being extracted by attackers is low. We hope this work could help the community to better understand the privacy risk of PLMs and bring new insights to make PLMs safe.",https://api.openreview.net/pdf/8a2aa6b979f1db6dbaee023550573a28275d8535.pdf
Huge Frozen Language Models as Readers for Open-Domain Question Answering,2022,ICML,"['Yoav Levine', 'Ori Ram', 'Daniel Jannai', 'Barak Lenz', 'Shai Shalev-Shwartz', 'Amnon Shashua', 'Kevin Leyton-Brown', 'Yoav Shoham']",poster,"['Language models', 'Open domain question answering', 'Retrieval.']","In the open-book variant of the open domain question answering setting, an answer generator typically attends to 100+ retrieved documents when answering, and is thus often called a ""reader"". Current readers are fine tuned for this long-context functionality. Because it is prohibitively expensive to fine tune huge models to attend to 100+ retrieved documents, readers tend to be relatively small, typically having fewer than 1B parameters. We introduce huge LMs into this pipeline as frozen readers. To do so, we use a re-ranking stage to condense relevant information from 100+ retrieved documents into the input sequence length of the frozen LM reader. We show that frozen LMs can reach and surpass leading fine tuning approaches on Natural Questions, a prominent open-domain question answering benchmark.",https://api.openreview.net/pdf/8f87ddcdd5366116ef4b81c673013a59271aeac9.pdf
Dialog Inpainting: Turning Documents into Dialogs,2022,ICML,"['Zhuyun Dai', 'Arun Tejasvi Chaganty', 'Vincent Y Zhao', 'Aida Amini', 'Mike Green', 'Qazi Mamunur Rashid', 'Kelvin Guu']",poster,"['dialog', 'conversational ai', 'synthetic data', 'large language model', 'generation', 'question answering', 'retrieval']","Many important questions (e.g. ""How to eat healthier?"") require conversation to establish context and explore in depth. However, conversational question answering (ConvQA) systems have long been stymied by scarce training data that is expensive to collect. To address this problem, we propose a new technique for synthetically generating diverse and high-quality dialog data: dialog inpainting. Our approach takes the text of any document and transforms it into a two-person dialog between the writer and an imagined reader: we treat sentences from the article as utterances spoken by the writer, and then use a dialog inpainter to predict what the imagined reader asked or said in between each of the writer's utterances. By applying this approach to passages from Wikipedia and the web, we produce WikiDialog and WebDialog, two datasets totalling 19 million diverse information-seeking dialogs---1,000x larger than the largest existing ConvQA dataset. Furthermore, human raters judge the answer adequacy and conversationality of WikiDialog to be as good or better than existing manually-collected datasets. Using our inpainted data to pre-train ConvQA retrieval systems, we significantly advance state-of-the-art across three benchmarks, yielding up to 40% relative gains on standard evaluation metrics.",https://api.openreview.net/pdf/0c36dbb0635d1d3620938784ad897a95adf0fd0e.pdf
Large Language Models are Zero-Shot Reasoners,2022,ICML,"['Takeshi Kojima', 'Shixiang Shane Gu', 'Machel Reid', 'Yutaka Matsuo', 'Yusuke Iwasawa']",poster,"['chain of thought (CoT)', 'zero-shot learning', 'multi-step reasoning', 'arithmetic', 'commonsense reasoning', 'prompting', 'large language models (LLMs)']","Chain of thought (CoT) prompting, a recent technique for eliciting multi-step reasoning through step-by-step answer examples, achieved the state-of-the-art performances in arithmetics and symbolic reasoning.While these successes are often attributed to LLMs' ability for few-shot learning, we show that LLMs are decent zero-shot reasoners by simply adding ``Let's think step by step'' before each answer. Experimental results demonstrate that our Zero-shot-CoT, using the same single prompt template, significantly outperforms zero-shot LLM performances on diverse benchmark reasoning tasks including arithmetics (MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin Flip), and other logical reasoning tasks(Date Understanding, Tracking Shuffled Objects), without any hand-crafted few-shot examples, e.g. increasing the accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with an 175B parameter Instruct-GPT, as well as similar magnitudes of improvements with  540B parameter PaLM. The versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task broad cognitive capabilities may be extracted through simple prompting. We hope our work not only serves as the minimal strongest zero-shot baseline for the challenging reasoning benchmarks, but also highlights the importance of carefully exploring and analyzing the enormous zero-shot knowledge hidden inside LLMs.",https://api.openreview.net/pdf/e177eb6b1efa56359e6fa462481bb6a7a36c0642.pdf
LinkBERT: Pretraining Language Models with Document Links,2022,ICML,"['Michihiro Yasunaga', 'Jure Leskovec', 'Percy Liang']",poster,"['language model', 'pretraining', 'knowledge', 'hyperlink']","Language model (LM) pretraining can learn various knowledge from text corpora, helping downstream tasks. 
However, existing methods such as BERT model a single document, and do not capture dependencies or knowledge that span across documents.
In this work, we propose LinkBERT, an LM pretraining method that leverages links between documents, e.g., hyperlinks. Given a text corpus, we view it as a graph of documents and create LM inputs by placing linked documents in the same context. We then pretrain the LM with two joint self-supervised objectives: masked language modeling and our new proposal, document relation prediction. 
We show that LinkBERT outperforms BERT on diverse downstream tasks across two domains: a general domain (pretrained on Wikipedia with hyperlinks) and biomedical domain (pretrained on PubMed with citation links). 
LinkBERT is especially effective for multi-hop reasoning and few-shot QA (+5\% absolute improvement on HotpotQA and TriviaQA), and the biomedical LinkBERT also sets new states of the art on various BioNLP tasks (+7\% on BioASQ and USMLE). 
We release our pretrained models, LinkBERT and BioLinkBERT, as well as code and data.",https://api.openreview.net/pdf/52e3167ee4a015c89b7e22bb65be6acbecd9c423.pdf
Efficient Task Adaptation by Mixing Discovered Skills,2022,ICML,"['JUNGSUB RHIM', 'Eunseok Yang', 'Taesup Kim']",poster,"['unsupervised learning', 'reinforcement learning', 'skill discovery', 'pretraining', 'finetuning', 'sample efficiency']","Unsupervised skill discovery is one of the approaches by which the agent learns potentially useful and distinct behaviors without any explicit reward. The agent is then expected to quickly solve downstream tasks by properly using a set of discovered skills rather than learning everything from scratch. However, it is non-trivial to optimally utilize the discovered skills for each task, which can be viewed as a fine-tuning method, and this has been less considered in the literature in spite of its importance. In this paper, we compare some fine-tuning methods showing how they inefficiently utilize the discovered skills and also propose new methods, which are sample-efficient and effective by interpreting the skills as a perspective of how an agent transforms the input state. Our code is available at https://github.com/jsrimr/unsupervisedRL",https://api.openreview.net/pdf/2f615da02275ae573709fea6b28830ad1aef501f.pdf
Non-Markovian Policies for Unsupervised Reinforcement Learning in Multiple Environments,2022,ICML,"['Pietro Maldini', 'Mirco Mutti', 'Riccardo De Santi', 'Marcello Restelli']",poster,['Unsupervised pre-training for reinforcement learning'],"In recent years, the area of Unsupervised Reinforcement Learning (URL) has gained particular relevance as a way to foster generalization of reinforcement learning agents. In this setting, the agent's policy is first pre-trained in an unknown environment via reward-free interactions, often through a pure exploration objective that drives the agent towards a uniform coverage of the state space. It has been shown that this pre-training leads to improved efficiency in downstream supervised tasks later given to the agent to solve. When dealing with the unsupervised pre-training in multiple environments one should also account for potential trade-offs in the exploration performance within the set of environments, which leads to the following question: Can we pre-train a policy that is simultaneously optimal in all the environments? In this work, we address this question by proposing a novel non-Markovian policy architecture to be pre-trained with the common maximum state entropy objective. This architecture showcases significant empirical advantages when compared to state-of-the-art Markovian agents for URL.",https://api.openreview.net/pdf/16de6aac9c1b23e159ae38d28f246e2bfeeb2898.pdf
On the Importance of Hyperparameters and Data Augmentation for Self-Supervised Learning,2022,ICML,"['Diane Wagner', 'Fabio Ferreira', 'Danny Stoll', 'Robin Tibor Schirrmeister', 'Samuel Müller', 'Frank Hutter']",poster,"['Self-Supervised Learning', 'Data Augmentation', 'Hyperparameters']","Self-Supervised Learning (SSL) has become a very active area of Deep Learning research where it is heavily used as a pre-training method for classification and other tasks. However, the rapid pace of advancements in this area comes at a price: training pipelines vary significantly across papers, which presents a potentially crucial confounding factor. Here, we show that, indeed, the choice of hyperparameters and data augmentation strategies can have a dramatic impact on performance. To shed light on these neglected factors and help maximize the power of SSL, we hyperparameterize these components and optimize them with Bayesian optimization, showing improvements across multiple datasets for the SimSiam SSL approach. Realizing the importance of data augmentations for SSL, we also introduce a new automated data augmentation algorithm, GroupAugment, which considers groups of augmentations and optimizes the sampling across groups. In contrast to algorithms designed for supervised learning, GroupAugment achieved consistently high linear evaluation accuracy across all datasets we considered. Overall, our results indicate the underestimated role of data augmentation for SSL.",https://api.openreview.net/pdf/4e362eba2314c097997bea36e6f19321e4801111.pdf
Learning Large-scale Universal User Representation with Sparse Mixture of Experts,2022,ICML,"['Caigao JIANG', 'Siqiao Xue', 'James Y. Zhang', 'Lingyue Liu', 'Zhibo Zhu', 'Hongyan Hao']",poster,"['user representation', 'mixture of expert', 'transformer']","Learning user sequence behaviour embedding is very sophisticated and challenging due to the complicate feature interaction over time and high dimension of user features. Recent emerging foundation models \textit{e}.\textit{g}. BERT and its variants, encourage a large body of researchers to investigate in this field. However, unlike natural language processing(NLP) tasks, the parameters of user behaviour model comes mostly from user embedding layer which makes most existing works fail to train an universal user embedding at large scale. Furthermore, user representations are learned from multiple downstream tasks, the past research did not address the seesaw phenomenon.In this paper, we propose SUPERMOE, a generic framework for obtain high quality user representation from multiple tasks. Specifically, the user behaviour sequences are encoded by MoE transformer, thus we can improve the model capacity to billions of parameters even trillions. In order to deal with seesaw phenomenon when learning across multiple tasks, we design a new loss function with task indicators. We perform extensive offline experiments on public datasets and online experiments on private real world business scenarios. Our approach achieves best performance over state-of-art models, the results demonstrate the effectiveness of our user behaviour representation framework using MOE transformer.",https://api.openreview.net/pdf/a13e8f8a73b91a53092e957a115ea7920082dec3.pdf
Pushing the limits of self-supervised ResNets: Can we outperform supervised learning without labels on ImageNet?,2022,ICML,"['Nenad Tomasev', 'Ioana Bica', 'Brian McWilliams', 'Lars Holger Buesing', 'Razvan Pascanu', 'Charles Blundell', 'Jovana Mitrovic']",poster,"['pretraining', 'representation learning', 'unsupervised learning', 'self-supervised learning', 'contrastive learning', 'invariance', 'ImageNet']","Despite recent progress made by self-supervised methods in representation learning with residual networks, they still underperform supervised learning on the ImageNet classification benchmark. To address this, we propose a novel self-supervised representation learning method Representation Learning via Invariant Causal Mechanisms v2 (ReLICv2) (based on ReLIC (Mitrovic et al., 2021)) which explicitly enforces invariance over spurious features such as background and object style. We conduct an extensive experimental evaluation across a varied set of datasets, learning settings and tasks. ReLICv2 achieves 77.1% top-1 accuracy on ImageNet using linear evaluation with a ResNet50 architecture and 80.6% with larger ResNet models, outperforming previous state-of-the-art self-supervised approaches by a wide margin. Moreover, we show a relative overall improvement exceeding +5% over the supervised baseline in the transfer setting and the ability to learn more robust representations than self-supervised and supervised models. Most notably, ReLICv2 is the first unsupervised representation learning method to consistently outperform a standard supervised baseline in a like-for-like comparison across a wide range of ResNet architectures. Finally, we show that despite using ResNet encoders, ReLICv2 is comparable to state-of-the-art self-supervised vision transformers.",https://api.openreview.net/pdf/ee2f11a71e0158737465b69bd719c85de21827f3.pdf
How robust are pre-trained models to distribution shift?,2022,ICML,"['Yuge Shi', 'Imant Daunhawer', 'Julia E Vogt', 'Philip Torr', 'Amartya Sanyal']",poster,"['pre-trained models', 'spurious correlation', 'distribution shift', 'unsupervised learning', 'self-supervised learning', 'auto-encoder', 'variational auto-encoder']","The vulnerability of machine learning models to spurious correlations has mostly been discussed in the context of supervised learning (SL). However, there is a lack of insight on how spurious correlations affect the performance of popular self-supervised learning (SSL) and auto-encoder based models (AE). In this work, we shed light on this by evaluating the performance of these models on both real world and synthetic distribution shift datasets. Following observations that the linear head itself can be susceptible to spurious correlations, we develop a new evaluation scheme with the linear head trained on out-of-distribution (OOD) data, to isolate the performance of the pre-trained models from a potential bias of the linear head used for evaluation. With this new methodology, we show that SSL models are consistently more robust to distribution shifts and thus better at OOD generalisation than AE and SL models.",https://api.openreview.net/pdf/18031564739953d8b96e81ca769f12a63620e757.pdf
Is Self-Supervised Contrastive Learning More Robust Than Supervised Learning?,2022,ICML,"['Yuanyi Zhong', 'Haoran Tang', 'Junkun Chen', 'Jian Peng', 'Yu-Xiong Wang']",poster,"['contrastive learning', 'pre-training', 'robustness']","Self-supervised contrastive learning is a powerful tool to learn visual representation without labels. Prior work has primarily focused on the recognition accuracy of contrastive pre-training algorithms, but has overlooked other behavioral aspects. In addition to accuracy, distributional robustness plays a critical role in the reliability of machine learning models. We design and conduct a series of robustness tests to quantify the behavioral differences between contrastive learning and supervised learning. These tests leverage data corruptions at multiple levels, ranging from pixel-level gamma distortion to patch-level shuffling and to dataset-level distribution shift. Our tests unveil intriguing robustness behaviors of contrastive and supervised learning. On the one hand, under downstream corruptions, we generally observe that contrastive learning is surprisingly more robust than supervised learning. On the other hand, under pre-training corruptions, we find contrastive learning vulnerable to patch shuffling and pixel intensity change, yet less sensitive to dataset-level distribution change. We attempt to explain these results through the role of data augmentation and feature space properties. Our insight has implications in improving the downstream robustness of supervised learning.",https://api.openreview.net/pdf/e35486f8601db0eb24ba976e92b26c26dcad7048.pdf
Leader-based Pre-training Framework for Cooperative Multi-Agent Reinforcement Learning,2022,ICML,"['Wenqi Chen', 'Xin Zeng', 'Amber Li']",poster,"['multi-agent reinforcement learning', 'pre-training', 'leader-based learning']","A leader in the team enables efficient learning for other novices in the social learning setting for both humans and animals. This paper constructs the leader-based pre-training framework for Multi-Agent Reinforcement Learning and investigates whether the leader enables the learning of novices as well. We compare three different approaches to distilling a leader's experiences from the pre-training model: Linear Layer Dimension Reduction, Attentive Graph Pooling, and Attention-based Graph Neural Network. We successfully show that a leader-based pre-training framework can 1) enable agents to learn faster, cooperate more effectively, and escape local optimum, and 2) promote the generalizability of agents in more challenging and unseen environments. The key to effective distillation is to maintain and aggregate important information.",https://api.openreview.net/pdf/a3205cdd9c5233121b8c397fdc01aca0f0820983.pdf
Pixel-level Correspondence for Self-Supervised Learning from Video,2022,ICML,"['Yash Sharma', 'Yi Zhu', 'Chris Russell', 'Thomas Brox']",poster,"['self-supervised', 'unsupervised', 'representation', 'video', 'optical flow', 'dense prediction', 'contrastive learning']","While self-supervised learning has enabled effective representation learning in the absence of labels, for vision, video remains a relatively untapped source of supervision. To address this, we propose Pixel-level Correspondence (PiCo), a method for dense contrastive learning from video. By tracking points with optical flow, we obtain a correspondence map which can be used to match local features at different points in time. We validate PiCo on standard benchmarks, outperforming self-supervised baselines on multiple dense prediction tasks, without compromising performance on image classification. ",https://api.openreview.net/pdf/173841e98ae2288e354138a867434612088c1fe2.pdf
Pre-Training on a Data Diet: Identifying Sufficient Examples for Early Training,2022,ICML,"['Mansheej Paul', 'Brett W Larsen', 'Surya Ganguli', 'Jonathan Frankle', 'Gintare Karolina Dziugaite']",poster,"['data pruning', 'iterative magnitude pruning', 'lottery ticket hypothesis', 'sparsity']","A striking observation about iterative magnitude pruning (IMP; Frankle et al. 2020) is that—after just a few hundred steps of dense training—the method can find a sparse sub-network that can be trained to the same accuracy as the dense network. However, the same does not hold at step 0, i.e., random initialization. In this work, we seek to understand how this early phase of pre-training leads to a good initialization for IMP through the lens of the data distribution. Empirically we observe that, holding the number of pre-training iterations constant, training on a small fraction of (randomly chosen)  data suffices to obtain an equally good initialization for IMP. We additionally observe that by pre-training only on ""easy"" training data we can decrease the number of steps necessary to find a good initialization for IMP compared to training on the full dataset or a randomly chosen subset. Combined, these results provide new insight into the role played by data in the early phase of training.",https://api.openreview.net/pdf/1adf3e61782f6a70538442e4f2558f61b1db1455.pdf
Enhancing Multi-hop Connectivity for Graph Convolutional Networks,2022,ICML,"['Songtao Liu', 'Shixiong Jing', 'Tong Zhao', 'Zengfeng Huang', 'Dinghao Wu']",poster,"['Homophily', 'High-order Neihgbors']","Graph Convolutional Network and many of its variants are known to suffer from the dilemma between model depth and over-smoothing issues. Stacking layers of GCN usually lead to the exponential expansion of the receptive field (i.e., high-order neighbors). In order to incorporate the information from high-order neighbors to learn node representations without drastically increasing the number of graph convolution layers, we propose a simple and effective pre-processing technique to increase graph connectivity. Our approach selectively inserts connections between center nodes and informative high-order neighbors, with learnable weights to control the information flow through the connection. Experiments show that our approach improves the performance of GCN, and reduce the depth of GCNII without sacrificing its performance. Besides, our proposed homophily-based weight assignment can mitigate the effect of graph structural attacks.",https://api.openreview.net/pdf/8ef942ec850d38218f012e0f4da3d7ae7353d595.pdf
Investigating Why Contrastive Learning Benefits Robustness against Label Noise,2022,ICML,"['Yihao Xue', 'Kyle Whitecross', 'Baharan Mirzasoleiman']",poster,"['robustness', 'contrastive learning', 'pretraining']","Self-supervised contrastive learning has recently been shown to be very effective in preventing deep networks from overfitting noisy labels. Despite its empirical success, the theoretical understanding of the effect of contrastive learning on boosting robustness is very limited. In this work, we rigorously prove that learned the representation matrix has certain desirable properties in terms its SVD that benefit robustness against label noise. We further show that the low-rank structure of the Jacobian of deep networks pre-trained with contrastive learning allows them to achieve a superior performance initially, when fine-tuned on noisy labels. Finally, we demonstrate that the initial robustness provided by contrastive learning enables robust training methods to achieve state-of-the-art performance under extreme noise levels.",https://api.openreview.net/pdf/e1d75c8a6eaf47d462bfc10f8c0c927438285027.pdf
Pretraining a Neural Network before Knowing Its Architecture,2022,ICML,['Boris Knyazev'],poster,"['hypernetworks', 'efficient pretraining', 'few-shot transfer learning', 'fine-tuning', 'orthogonal parameters']","Training large neural networks is possible by training a smaller hypernetwork that predicts parameters for the large ones. A recently released Graph HyperNetwork (GHN) trained this way on one million of smaller ImageNet architectures is able to predict parameters for large unseen networks such as ResNet-50. While networks with predicted parameters lose performance on the source task, the predicted parameters have been found useful for fine-tuning on other tasks. We study if fine-tuning based on the same GHN is still useful on novel strong architectures that were published after the GHN had been trained. We found that for recent architectures such as ConvNeXt, GHN initialization becomes less useful than for ResNet-50. One potential reason is the increased distribution shift of novel architectures from those used to train the GHN. We also found that the predicted parameters lack the diversity necessary to successfully fine-tune parameters with gradient descent. We alleviate this limitation by applying simple post-processing techniques to predicted parameters before fine-tuning them on a target task and improve fine-tuning of ResNet-50 and ConvNeXt.",https://api.openreview.net/pdf/677b3dd7063395f4242dc2e2200a4a27b013e36b.pdf
Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming,2022,ICML,"['Hanlin Zhang', 'Ziyang Li', 'Jiani Huang', 'Mayur Naik', 'Eric Xing']",poster,[],"Pre-trained large language models (LMs) struggle to perform logical reasoning reliably despite advances in scale and compositionality. In this work, we tackle this challenge through the lens of symbolic programming. We propose DSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained LMs govern the perception of factual knowledge, and a symbolic module equipped with provenance generates top-k proofs by deductive reasoning. In contrast to works that rely on hand-crafted logic rules, our differentiable symbolic reasoning architecture efficiently learns weighted rules to further improve LMs. DSR-LM is scalable, interpretable, and allows easy integration of prior knowledge, thereby supporting extensive symbolic programming to robustly derive a logical conclusion. Our experiments show that DSR-LM leads to improved logical reasoning of pre-trained LMs and outperforms a spectrum of competitive baselines even under systematic distribution shifts on sequence lengths.",https://api.openreview.net/pdf/9c6e266e2035d92d8759f6a972c766894aabe781.pdf
How well do contrastively trained models transfer?,2022,ICML,"['M. Moein Shariatnia', 'Rahim Entezari', 'Mitchell Wortsman', 'Olga Saukh', 'Ludwig Schmidt']",poster,"['supervised training', 'constrastive learning', 'clip', 'simclr']","There are two prevailing methods for pre-training on large datasets to learn transferable representations: 1) supervised pre-training on large but weakly-labeled datasets; 2) contrastively training on image only and image, text pairs. While supervised pre-training learns good representations that can be transferred to a wide range of tasks, contrastively models such as CLIP have demonstrated unprecedented zero-shot transfer. In this work, we compare the transferability of the two aforementioned methods to multiple downstream tasks. The pre-training distributions we consider include YFCC, Conceptual Captions, and ImageNet-21K while pre-training objectives range from supervised to SimCLR, CLIP, and SLIP. We observe that different pre-training methods with the same training source transfer similarly given their ImageNet accuracy.",https://api.openreview.net/pdf/9fe62b49b25f3530782e620e5da9b288e4e262d9.pdf
Vote for Nearest Neighbors Meta-Pruning of Self-Supervised Networks,2022,ICML,"['Haiyan Zhao', 'Tianyi Zhou', 'Guodong Long', 'Jing Jiang', 'Chengqi Zhang']",poster,[],"Pruning plays an essential role in deploying deep neural nets (DNNs) to the hardware of limited memory or computation. However, current high-quality iterative pruning can create a terrible carbon footprint when compressing a large DNN for a wide variety of devices and tasks. Can we reuse the pruning results on previous tasks to accelerate the pruning for a new task? Can we find a better initialization for a new task? We study this ``nearest neighbors meta-pruning'' problem by first investigating different choices of pre-trained models for pruning under limited iterations. Our empirical study reveals several advantages of the self-supervision pre-trained model when pruned for multiple tasks. We further study the overlap of pruned models for similar tasks and how the overlap changes for different layers. Inspired by these discoveries, we develop a simple but strong baseline ``Meta-Vote Pruning (MVP)'' that significantly reduces the pruning iterations for a new task by initializing a sub-network from the pruned models of tasks similar to it. In experiments, we demonstrate the advantages of MVP through extensive empirical studies and comparisons with popular pruning methods.",https://api.openreview.net/pdf/a4fe539a177a373dc257e1260b68a3f35b605914.pdf
On Combining Global and Localized Self-Supervised Models of Speech,2022,ICML,"['Sri Harsha Dumpala', 'Chandramouli Shama Sastry', 'Rudolf Uher', 'Sageev Oore']",poster,"['Simple Siamese (SimSiam)', 'self-supervised learning', 'emotion classification', 'sentiment classification', 'depression detection']","Self supervised learning involves learning general-purpose representations that can be useful in a variety of downstream tasks.
In this work, we study the application of speech-embeddings derived from popular self-supervised learning frameworks such as wav2vec-2.0 and HuBERT over four different speech-classification tasks such as sentiment classification, command detection, emotion classification and depression detection. We distinguish between and discuss self-supervised training tasks that induce localized and global features of speech based on their temporal granularity: noting that self-supervised representation learning frameworks based on the masked language-modeling objective -- such as wav2vec-2.0 and HuBERT -- induce localized embeddings, we define a self-supervised learning framework based on SimSiam for learning global features of speech. Through our evaluations, we find that these global representations are better suited for tasks such as depression detection and emotion classification while the localized embeddings of speech can be very useful in tasks such as speech-command detection; we also find that our proposed model outperforms TRILL -- a popular model for learning global representations. Finally, we also propose and confirm empirically that combining the global and localized representations of speech helps obtain better performance across a range of downstream tasks than each of the individual embedding methods. ",https://api.openreview.net/pdf/df3d4d251d4415bbcca148fa2e9ad49526c52c1b.pdf
Mind the Gap: Understanding the Modality Gap in Multi-modal Contrastive Representation Learning,2022,ICML,"['Weixin Liang', 'Yuhui Zhang', 'Yongchan Kwon', 'Serena Yeung', 'James Zou']",poster,"['Multi-modal Representation Learning', 'Contrastive Representation Learning', 'Cone Effect', 'Modality Gap', 'Geometry of Deep Multi-Model Learning']","We present modality gap, an intriguing geometric phenomenon of the representation space of multi-modal models. Specifically, we show that different data modalities (e.g. images and text) are embedded at arm's length in their shared representation in multi-modal models such as CLIP. Our systematic analysis demonstrates that this gap is caused by a combination of model initialization and contrastive learning optimization. In model initialization, we show empirically and theoretically that the representation of a common deep neural network is restricted to a narrow cone. As a consequence, in a multi-modal model with two encoders, the representations of the two modalities are clearly apart when the model is initialized. During optimization,  contrastive learning keeps the different modalities separate by a certain distance, which is influenced by the temperature parameter in the loss function. Our experiments further demonstrate that varying the modality gap distance has a significant impact in improving the model's downstream zero-shot classification performance and fairness. Our code and data are available at https://modalitygap.readthedocs.io/",https://api.openreview.net/pdf/9ba24e4ed894472ff991fcbdc0fc5413cc788e55.pdf
Robustness to Adversarial Gradients: A Glimpse Into the Loss Landscape of Contrastive Pre-training,2022,ICML,"['Philip Fradkin', 'Lazar Atanackovic', 'Michael R. Zhang']",poster,"['contrastive', 'flatness', 'loss-landscape', 'curvature', 'pre-training', 'sharpness', 'minima']","An in-depth understanding of deep neural network generalization can allow machine learning practitioners to design systems more robust to class balance shift, adversarial attacks, and data drift. However, the reasons for better generalization are not fully understood.  Recent works provide empirical arguments suggesting flat minima generalize better. While recently proposed contrastive pre-training methods have also been shown to improve generalization, there is an incomplete understanding of the loss landscape of these models and why they generalize well. In this work, we analyze the loss landscape of contrastive trained models on the CIFAR10 dataset by looking at three sharpness measures: (1) the approximate eigenspectrum of the Hessian, (2) (Cε, A)-sharpness, and (3) robustness to adversarial gradients (RAG), a new efficient measure of sharpness. Our findings suggest models fine-tuned after contrastive training favor flatter solutions relative to baseline classifiers trained with a supervised objective. In addition, our proposed metric yields findings consistent with existing works, demonstrating impacts of learning rate and batch size on minima sharpness.",https://api.openreview.net/pdf/b41045bee1ed234a5ed1d0b628f65abab08b8465.pdf
Self-Destructing Models: Increasing the Costs of Harmful Dual Uses in Foundation Models,2022,ICML,"['Eric Mitchell', 'Peter Henderson', 'Christopher D Manning', 'Dan Jurafsky', 'Chelsea Finn']",poster,"['pretraining', 'foundation models', 'ai safety', 'meta learning', 'dual use', 'responsible ai']","A growing ecosystem of large, open-source foundation models has reduced the labeled data and technical expertise necessary to apply machine learning to many new problems. Yet foundation models pose a clear dual-use risk, indiscriminately reducing the costs of building both harmful and benign machine learning systems. To mitigate this risk, we propose the task blocking paradigm, in which foundation models are trained with an additional mechanism to impede adaptation to harmful tasks while retaining good performance on desired tasks. We call the resulting models self-destructing models, inspired by mechanisms that prevent adversaries from using tools for harmful purposes. We present an algorithm for training self-destructing models leveraging techniques from meta-learning and adversarial learning, showing that it can largely prevent a BERT-based model from learning to perform gender identification without harming the model's ability to perform profession classification. We conclude with a discussion of future directions.",https://api.openreview.net/pdf/c0e2f8366f4d79eb363e38b71ea06f456b169cc0.pdf
Flaky Performances when Pre-Training on Relational Databases with a Plan for Future Characterization Efforts,2022,ICML,"['Shengchao Liu', 'David Vazquez', 'Jian Tang', 'Pierre-Andre Noel']",poster,"['self-supervised learning', 'graph neural networks', 'relational databases', 'tabular data']","We explore the downstream task performances for graph neural network (GNN) self-supervised learning (SSL) methods trained on subgraphs extracted from relational databases (RDBs). Intuitively, this joint use of SSL and GNNs allows us to leverage more of the available data, which could translate to better results. However, while we observe positive transfer in some cases, others showed systematic performance degradation, including some spectacular ones. We hypothesize a mechanism that could explain this behaviour and draft the plan for future work testing it by characterize how much relevant information different strategies can (theoretically and/or empirically) extract from (synthetic and/or real) RDBs.",https://api.openreview.net/pdf/7857018b59013b137b4237368ea185817b9d6bc8.pdf
Training strategies with unlabeled and few labeled examples under 1-pixel attack by combining supervised and self-supervised learning,2022,ICML,"['Gabriel Biscaro Cavallari', 'Moacir A Ponti']",poster,"['feature learning', 'self-supervised learning', 'semi-supervised learning']","Self-supervised learning pre-training exhibited excellent performance on feature learning by using only unlabeled examples. Still, it is not clear how different self-supervised tasks perform under distinct image domains and there are still training issues to be tackled under scenarios of limited labeled data. We investigate two self-supervised tasks: rotation and Barlow Twins, on three distinct image domains, exploring a combination of supervised and self-supervised learning. Our motivation is to work on scenarios where the proportion of labeled data with respect to unlabeled data is small, as well as investigate the model's robustness to 1-pixel attacks. The models that combine supervised with self-supervised tasks can take advantage of the unlabeled data to improve the learned representation in terms of the linear discrimination, as well as allowing learning even under attack.",https://api.openreview.net/pdf/5d34eb33f8df109c73dda32cb6eab810995c14cc.pdf
Contrastive Learning Can Find An Optimal Basis For Approximately Invariant Functions,2022,ICML,"['Daniel D. Johnson', 'Ayoub El Hanchi', 'Chris J. Maddison']",poster,"['contrastive learning', 'kernel methods', 'Markov chain', 'eigenfunction', 'spectral decomposition', 'representation learning']","Contrastive learning is a powerful framework for learning self-supervised representations that generalize well to downstream supervised tasks. We show that multiple existing contrastive learning methods can be reinterpeted as learning a positive-definite kernel that approximates a particular *contrastive kernel* defined by the positive pairs. The principal components of the data under this kernel exactly correspond to the eigenfunctions of a positive-pair Markov chain, and these eigenfunctions can be used to build a representation that
provably minimizes the worst-case approximation error of linear predictors under the assumption that positive pairs have similar labels. We give generalization bounds for downstream linear prediction using this optimal representation, and show how to approximate this representation using kernel PCA. We also explore kernel-based representations on a noisy MNIST task for which the positive pair distribution has a closed form, and compare the properties of the true eigenfunctions with their learned approximations.",https://api.openreview.net/pdf/be8f4382ca95d15544e741993af39fab77bd7615.pdf
Memorization in NLP Fine-tuning Methods,2022,ICML,"['Fatemehsadat Mireshghallah', 'Archit Uniyal', 'Tianhao Wang', 'David Evans', 'Taylor Berg-Kirkpatrick']",poster,"['Fine-tuning', 'Memorization', 'Privacy']","Large language models are shown to present privacy risks through memorization of training data, and several recent works have studied such risks for the pre-training phase. Little attention, however, has been given to the fine-tuning phase and it is not well understood how different fine-tuning  methods (such as fine-tuning the full model, the model head, and adapter) compare in terms of memorization risk. This presents increasing concern as the ``pre-train and fine-tune'' paradigm proliferates. In this paper, we empirically study memorization of fine-tuning methods using membership inference and extraction attacks, and show that their susceptibility to attacks is very different. We observe that fine-tuning the head of the model has the highest susceptibility to attacks, whereas fine-tuning smaller adapters appears to be less vulnerable to known extraction attacks.",https://api.openreview.net/pdf/3f59c6505c2ebecf7bd6231cada6707a0eff3f2a.pdf
Feed-Forward Source-Free Latent Domain Adaptation via Cross-Attention,2022,ICML,"['Ondrej Bohdal', 'Da Li', 'Shell Xu Hu', 'Timothy Hospedales']",poster,"['latent domain adaptation', 'source-free', 'cross-attention', 'meta-learning']","We study the highly practical but comparatively under-studied problem of latent-domain adaptation, where a source model should be adapted to a target dataset that contains a mixture of unlabelled domain-relevant and domain-irrelevant examples. Motivated by the requirements for data privacy and the need for embedded and resource-constrained devices of all kinds to adapt to local data distributions, we further focus on the setting of feed-forward source-free domain adaptation, where adaptation should not require access to the source dataset, and also be back propagation-free. Our solution is to meta-learn a network capable of embedding the mixed-relevance target dataset and dynamically adapting inference for target examples using cross-attention. The resulting framework leads to consistent strong improvements.",https://api.openreview.net/pdf/c2b26a43cba8fe1afda745e45bc670a737d21269.pdf
On the Subspace Structure of Gradient-Based Meta-Learning,2022,ICML,"['Gustaf Tegnér', 'Alfredo Reichlin', 'Hang Yin', 'Mårten Björkman', 'Danica Kragic Jensfelt']",poster,"['meta-learning', 'gradient-based meta-learning', 'parameter space', 'few-shot classification', 'dimensionality reduction']","In this work we provide an analysis of the distribution of the post-adaptation parameters of Gradient-Based Meta-Learning (GBML) methods. Previous work has noticed how, for the case of image-classification, this adaption only takes place on the last layers of the network. We propose the more general notion that parameters are updated over a low-dimensional subspace of the same dimensionality as the task-space and show that this holds for regression as well. Furthermore, the induced subspace structure provides a method to estimate the intrinsic dimension of the space of tasks of common few-shot learning datasets.",https://api.openreview.net/pdf/c51b22f9f51ead98bfdc8bc525af6da4323dfbb3.pdf
RL-Tune: A Deep Reinforcement Learning Assisted Layer-wise Fine-Tuning Approach for Transfer Learning,2022,ICML,"['Tanvir Mahmud', 'Natalia Frumkin', 'Diana Marculescu']",poster,"['novel fine-tuning', 'transfer-learning', 'deep reinforcement learning', 'learning-rate scheduling']","Data scarcity is one of the major challenges in many real-world applications. To handle low-data regimes, practitioners often take an existing pre-trained network and fine-tune it on a data-deficient target task. In this setup, a network is pre-trained on a source dataset and fine-tuned on a different, potentially smaller, target dataset. We address two critical challenges with transfer learning via fine-tuning: (1) The required amount of fine-tuning greatly depends on the distribution shift from source to target dataset. (2) This distribution shift greatly varies by layer, thereby requiring layer-wise adjustments in fine-tuning to adapt to this distribution shift while preserving the pre-trained network's feature representation. To overcome these challenges, we propose RL-Tune, a layer-wise fine-tuning framework for transfer learning which leverages reinforcement learning to adjust learning rates as a function of the target data shift. In our RL framework, the state is a collection of the intermediate feature activations generated from training samples. The agent generates layer-wise learning rates as actions for fine-tuning based on the current state and obtains sample accuracy as the reward. RL-Tune outperforms other state-of-the-art approaches on standard transfer learning benchmarks by a large margin, e.g., 6% mean accuracy improvement on CUB-200-2011 with 15% data.",https://api.openreview.net/pdf/c3dcc098a06010ba0f47a32a029f147e3a2d72d3.pdf
Improved Generalization Bounds for Transfer Learning via Neural Collapse,2022,ICML,"['Tomer Galanti', 'András György', 'Marcus Hutter']",poster,"['neural collapse', 'transfer learning', 'classification']","Using representations learned by large, pretrained models, also called foundation models, in new tasks with fewer data has been successful in a wide range of machine learning problems. Recently, Galanti et al. (2022) introduced a theoretical framework for studying this transfer learning setting for classification. Their analysis is based on the recently observed phenomenon that the features learned by overparameterized deep classification networks show an interesting clustering property, called neural collapse (Papyan et al. 2020). A cornerstone of their analysis demonstrates that neural collapse generalizes from the source classes to new target classes. However, this analysis is limited as it relies on several unrealistic assumptions. In this work, we provide an improved theoretical analysis significantly relaxing these modeling assumptions.",https://api.openreview.net/pdf/52dc64ba3d691753eeb9e8306a8bec08d893e760.pdf
Predicting Human Similarity Judgments Using Large Language Models,2022,ICML,"['Raja Marjieh', 'Ilia Sucholutsky', 'Theodore Sumers', 'Nori Jacoby', 'Thomas L. Griffiths']",poster,"['language', 'representational similarity', 'cognitive science', 'perception', 'computer vision', 'machine learning', 'NLP', 'pre-training']","Similarity judgments provide a well-established method for accessing mental representations, with applications in psychology, neuroscience and machine learning. However, collecting similarity judgments can be prohibitively expensive for naturalistic datasets as the number of comparisons grows quadratically in the number of stimuli. We leverage recent advances in language models and online recruitment, proposing an efficient domain-general procedure for predicting human similarity judgments based on text descriptions. Crucially, the number of descriptions required grows only linearly with the number of stimuli, drastically reducing the amount of data required. We test this procedure on six datasets of naturalistic images and show that our models outperform previous approaches based on visual information.",https://api.openreview.net/pdf/f4b3551c3ba8921e09968ae64a0f016a0896ae6b.pdf
Federated Learning from Pre-Trained Models: A Contrastive Learning Approach,2022,ICML,"['Yue Tan', 'Guodong Long', 'Jie Ma', 'Lu Liu', 'Tianyi Zhou', 'Jing Jiang']",poster,"['Federated Learning', 'Pre-Trained Model', 'Contrastive Learning']","Excessive computation and communication demands pose challenges to current FL frameworks, especially when training large-scale models. To prevent these issues from hindering the deployment of FL systems, we propose a lightweight framework where clients jointly learn to fuse the representations generated by multiple fixed pre-trained models rather than training a large-scale model from scratch. To capture more client-specific and class-relevant information from the pre-trained models and jointly improve each client's ability to exploit those off-the-shelf models, we design a Federated Prototype-wise Contrastive Learning (FedPCL) approach which shares knowledge across clients through their class prototypes and builds client-specific representations in a prototype-wise contrastive manner. We perform a thorough evaluation of the proposed FedPCL in the lightweight framework, measuring its ability to fuse various pre-trained models on popular FL datasets.",https://api.openreview.net/pdf/3b76c95b1ae77539fefff9bd6bec6966db26eaf5.pdf
Hyper-Representation for Pre-Training and Transfer Learning,2022,ICML,"['Konstantin Schürholt', 'Boris Knyazev', 'Xavier Giró-i-Nieto', 'Damian Borth']",poster,"['Hyper-Representations', 'Model Zoo', 'Representation Learning', 'Knowledge Transfer']","Learning representations of neural network weights given a model zoo is an emerging and challenging area with many potential applications from model inspection, to neural architecture search or knowledge distillation. Recently, an autoencoder trained on a model zoo was able to learn a hyper-representation, which captures intrinsic and extrinsic properties of the models in the zoo. In this work, we extend hyper-representations for generative use to sample new model weights as pre-training. We propose layer-wise loss normalization which we demonstrate is key to generate high-performing models and a sampling method based on the empirical density
of hyper-representations. The models generated using our methods are diverse, performant and capable to outperform conventional baselines for transfer learning. Our results indicate the potential of knowledge aggregation from model zoos to new models via hyper-representations thereby paving the avenue for novel research directions.",https://api.openreview.net/pdf/55d36e17ac62c1b12371b1c4e0968714b89e082a.pdf
What Do We Maximize In Self-Supervised Learning?,2022,ICML,"['Ravid Shwartz-Ziv', 'Randall Balestriero', 'Yann LeCun']",poster,"['Self supervised learning', 'Information theory']","In this paper, we examine self-supervised learning methods, particularly VICReg, to provide an information-theoretical understanding of their construction. As a first step, we demonstrate how information-theoretic quantities can be obtained for a deterministic network, offering a possible alternative to prior work that relies on stochastic models. This enables us to demonstrate how VICReg can be (re)discovered from first principles and its assumptions about data distribution. Furthermore, we empirically demonstrate the validity of our assumptions, confirming our novel understanding of VICReg. Finally, we believe that the derivation and insights we obtain can be generalized to many other SSL methods, opening new avenues for theoretical and practical understanding of SSL and transfer learning.",https://api.openreview.net/pdf/814d14836aa7c8023d369b69dc2433988813be15.pdf
ECLIP: Efficient Contrastive Language-Image Pretraining via Ensemble Confidence Learning and Masked Language Modeling,2022,ICML,"['Jue Wang', 'Haofan Wang', 'Weijia Wu', 'Jincan Deng', 'Yu Lu', 'Xiaofeng Guo', 'Debing Zhang']",poster,['Language-Image Pretraining'],"While large scale pre-training has achieved great achievements in bridging the gap between vision and language, it still faces three challenges. First, the cost for pre-training is expensive. Second, there is no efficient way to handle the data noise which degrades model performance. Third, previous methods only leverage limited image-text paired data, while ignoring richer single-modal data, which may result in poor generalization to single-modal downstream tasks. In this work, we propose \textbf{E}fficient \textbf{C}ontrastive \textbf{L}anguage-\textbf{I}mage \textbf{P}retraining (ECLIP) via Ensemble Confidence Learning and Masked Language Modeling. Specifically, We adaptively filter out noisy samples in the training process by means of Ensemble Confidence Learning strategy, and add a Masked Language Modeling objective to utilize extra non-paired text data. ECLIP achieves the state-of-the-art performance on Chinese cross-modal retrieval tasks with only 1/10 training resources compared with CLIP and WenLan, while showing excellent generalization to single-modal tasks including text retrieval and text classification.",https://api.openreview.net/pdf/7b6a3b98b01d423ebeb3b306cdd1aff085e0a536.pdf
Boosting Monolingual Sentence Representation with Large-scale Parallel Translation Datasets,2022,ICML,"['Jue Wang', 'Haofan Wang', 'Xing Wu', 'Chaochen Gao', 'Debing Zhang']",poster,"['pre-training', 'language model']","Although contrastive learning greatly improves sentence representation, its performance is still limited by the size of existing monolingual datasets. So can semantically highly correlated massively parallel translation pairs be used for pre-training of monolingual models? This paper proposes an exploration of this. We leverage parallel translated sentence pairs to learn single-sentence sentence embeddings and demonstrate superior performance in balancing alignment and consistency. We achieve new state-of-the-art performance on the mean score of Standard Semantic Text Similarity (STS), outperforming both SimCSE and Sentence-T5.",https://api.openreview.net/pdf/a325c981b8d54da9e5793d78d909bdb8a3a69875.pdf
Knowledge Distillation for Efficient Sequences of Training Runs,2022,ICML,"['Xingyu Liu', 'Alexander Leonardi', 'Lu Yu', 'Christopher Gilmer-Hill', 'Matthew L Leavitt', 'Jonathan Frankle']",poster,"['Knowledge distillation', 'efficient training', 'hyperparameter search', 'sequences of training runs']","In many practical scenarios - like hyperparameter search or continual retraining with new data - related training runs are performed many times in sequence. Current practice is to train each of these models independently from scratch. We study the problem of exploiting the computation invested in previous runs to reduce the cost of future runs using knowledge distillation (KD). We find that augmenting future runs with KD from previous runs dramatically reduces the time necessary to train these models, even taking into account the overhead of KD. We improve on these results with two strategies that reduce the overhead of KD by 80-90% with minimal effect on accuracy and vast pareto-improvements in overall cost. We conclude that KD is a promising avenue for reducing the cost of the expensive preparatory work that precedes training final models in practice.",https://api.openreview.net/pdf/d501addebb2f092d69cd3e13e87477fa3a151542.pdf
Energy-Inspired Self-Supervised Pretraining for Vision Models,2022,ICML,"['Ze Wang', 'Jiang Wang', 'Zicheng Liu', 'Qiang Qiu']",poster,[],"Motivated by the fact that forward and backward passes of a deep network naturally form symmetric mappings between input and output representations, we introduce a simple yet effective self-supervised vision model pretraining framework inspired by energy-based models (EBMs). In the proposed framework, we model energy estimation and data restoration as the forward and backward passes of a single network without any auxiliary components, e.g., an extra decoder. For the forward pass, we fit a network to an energy function that assigns low energy scores to samples that belong to an unlabeled dataset, and high energy otherwise. For the backward pass, we restore data from corrupted versions iteratively using gradient-based optimization along the direction of energy minimization in as few as one step. Our framework accepts a wide range of pretext tasks with different data corruption methods, and permits models to be pretrained from masked image modeling and image restoration. We support our findings with extensive experiments, and show the proposed method delivers comparable and even better performance with remarkably fewer epochs of training compared to the state-of-the-art self-supervised vision model pretraining methods. Our findings shed light on further exploring self-supervised vision model pretraining pretext tasks beyond masked image modeling.",https://api.openreview.net/pdf/9bfcdfad8509cde432106211e62ab1da0b5d5afd.pdf
On the Connection between Pre-training Data Diversity and Robustness,2022,ICML,"['Vivek Ramanujan', 'Thao Nguyen', 'Ludwig Schmidt', 'Ali Farhadi']",poster,"['pretraining', 'distribution shift', 'finetuning', 'robustness']","Our work studies the implications of transfer learning on model behavior beyond accuracy: how does the pre-training distribution affect the downstream robustness of a fine-tuned model? We analyze model effective robustness using the framework proposed by Taori et al. (2020), which demonstrates that in-distribution and out-of-distribution performances are highly correlated along a robustness linear trend. We explore various interventions that significantly alter the pre-training distribution, including label space, label semantics, and the pre-training dataset itself. In most cases, changes during pre-training have minimal impact on the original linear trend produced by pre-training models on the full ImageNet dataset. We demonstrate these findings on pre-training distributions constructed from ImageNet and iNaturalist, with the fine-tuning task being iWildCams-WILDS animal classification.",https://api.openreview.net/pdf/022e860c898c0c7d916943aea00afb27fb3045ec.pdf
Pre-Trained Image Encoder for Generalizable Visual Reinforcement Learning ,2022,ICML,"['Zhecheng Yuan', 'Zhengrong Xue', 'Bo Yuan', 'Xueqian Wang', 'Yi Wu', 'Yang Gao', 'Huazhe Xu']",poster,"['Visual RL', 'Generealization', 'Pre-trained Models']","Learning generalizable policies that can adapt to unseen environments remains challenging in visual Reinforcement Learning (RL). Existing approaches try to acquire a robust representation via diversifying the appearances of in-domain observations for better generalization. Limited by the specific observations of the environment, these methods ignore the possibility of exploring diverse real-world image datasets. In this paper, we investigate how a visual RL agent would benefit from the off-the-shelf visual representations. Surprisingly, we find that the early layers in an ImageNet pre-trained ResNet model could provide rather generalizable representations for visual RL. Hence, we propose Pre-trained Image Encoder for Generalizable visual reinforcement learning (PIE-G), a simple yet effective framework that can generalize to the unseen visual scenarios in a zero-shot manner. Extensive experiments are conducted on DMControl Generalization Benchmark, DMControl Manipulation Tasks, and Drawer World to verify the effectiveness of PIE-G. Empirical evidence suggests PIE-G can significantly outperforms previous state-of-the-art methods in terms of generalization performance. In particular, PIE-G boasts a 55% generalization performance gain on average in the challenging video background setting.",https://api.openreview.net/pdf/70e88e8cba3ab1714edce79cc97501d9214165d1.pdf
Self-Supervised Time Series Representation Learning with Temporal-Instance Similarity Distillation,2022,ICML,"['Ainaz Hajimoradlou', 'Leila Pishdad', 'Frederick Tung', 'Maryna Karpusha']",poster,"['self-supervised learning', 'time series', 'classification', 'anomaly detection', 'forecasting', 'similarity distillation', 'teacher-student architecture']","We propose a self-supervised method for pre-training universal time series representations in which we learn contrastive representations using similarity distillation along the temporal and instance dimensions. We analyze the effectiveness of both dimensions, and evaluate our pre-trained representations on three downstream tasks: time series classification, anomaly detection, and forecasting.",https://api.openreview.net/pdf/2a2f255aaa5759bc6e950b1ec0c8663a5dc914fa.pdf
Protein Representation Learning by Geometric Structure Pretraining,2022,ICML,"['Zuobai Zhang', 'Minghao Xu', 'Arian Rokkum Jamasb', 'Vijil Chenthamarakshan', 'Aurelie Lozano', 'Payel Das', 'Jian Tang']",poster,"['Protein representation learning', 'pretraining']","Learning effective protein representations is critical in a variety of tasks in biology such as predicting protein function or structure. Existing approaches usually pretrain protein language models on a large number of unlabeled amino acid sequences and then finetune the models with some labeled data in downstream tasks. Despite the effectiveness of sequence-based approaches, the power of pretraining on known protein structures, which are available in smaller numbers only, has not been explored for protein property prediction, though protein structures are known to be determinants of protein function. In this paper, we propose to pretrain protein representations according to their 3D structures. We first present a simple yet effective encoder to learn the  geometric features of a protein. We pretrain the protein graph encoder by leveraging multiview contrastive learning and different self-prediction tasks. Experimental results on both function prediction and fold classification tasks show that our proposed pretraining methods outperform or are on par with the state-of-the-art sequence-based methods, while using much less data. All codes and models will be published upon acceptance.",https://api.openreview.net/pdf/887f11aec47248ac743753e96ebb4470ded6d8c8.pdf
Manifold Characteristics That Predict Downstream Task Performance,2022,ICML,"['Ruan Henry Van der Merwe', 'Gregory Newman', 'Etienne Barnard']",poster,"['self-supervised learning', 'deep learning', 'manifold', 'generalization']","Pretraining methods are typically compared by evaluating the accuracy of linear classifiers, transfer learning performance, or visually inspecting the representation manifold's (RM) lower-dimensional projections. We show that the differences between methods can be understood more clearly by investigating the RM directly, which allows for a more detailed comparison. To this end, we propose a framework and new metric to measure and compare different RMs. We also investigate and report on the RM characteristics for various pretraining methods. These characteristics are measured by applying sequentially larger local alterations to the input data, using white noise injections and Projected Gradient Descent (PGD) adversarial attacks, and then tracking each datapoint. We calculate the total distance moved for each datapoint and the relative change in distance between successive alterations. We show that self-supervised methods learn an RM where alterations lead to large but constant size changes, indicating a smoother RM than fully supervised methods. We then combine these measurements into one metric, the Representation Manifold Quality Metric (RMQM), where larger values indicate larger and less variable step sizes, and show that RMQM correlates positively with performance on downstream tasks.",https://api.openreview.net/pdf/353b9b2b87c6784c20d23a4db94fc5f57dc6a1f3.pdf
"PARS-Push: Personalized, Asynchronous and Robust Decentralized Optimization",2022,ICML,"['M. Taha Toghani', 'Soomin Lee', 'Cesar A Uribe']",poster,"['Model-Agnostic Meta-Learning', 'Asynchronous Communication', 'Decentralized Optimization', 'Personalization']","We study the decentralized multi-step Model-Agnostic Meta-Learning (MAML) framework where a group of $n$ agents seeks to find a common point that enables ``few-shot'' learning (personalization) via local stochastic gradient steps on their local functions. We formulate the personalized optimization problem under the MAML framework and propose PARS-Push, a decentralized asynchronous algorithm robust to message failures, communication delays, and directed message sharing. We characterize the convergence rate of PARS-Push for smooth and strongly convex and smooth and non-convex functions under arbitrary multi-step personalization. Moreover, we provide numerical experiments showing its performance under heterogeneous data setups.",https://api.openreview.net/pdf/392293a6ffbfd8650a2875eef2d675e15b378a18.pdf
Evaluating Self-Supervised Learned Molecular Graphs ,2022,ICML,"['Hanchen Wang', 'Shengchao Liu', 'Jean Kaddour', 'Qi Liu', 'Jian Tang', 'Matt Kusner', 'Joan Lasenby']",poster,[],"Because of data scarcity in real-world scenarios, obtaining pre-trained representations via self-supervised learning (SSL) has attracted increasing interest. Although various methods have been proposed, it is still under-explored what knowledge the networks learn from the pre-training tasks and how it relates to downstream properties. In this work, with an emphasis on chemical molecular graphs, we fill in this gap by devising a range of node-level, pair-level, and graph-level probe tasks to analyse the representations from pre-trained graph neural networks (GNNs). We empirically show that: 1. Pre-trained models have better downstream performance compared to randomly-initialised models due to their improved the capability of capturing global topology and recognising substructures. 2. However, randomly initialised models outperform pre-trained models in terms of retaining local topology. Such information gradually disappears from the early layers to the last layers for pre-trained models.",https://api.openreview.net/pdf/3be09afb8ab6f15c9b9cc753474636e02f12a15c.pdf
PSP-HDRI$+$: A Synthetic Dataset Generator for Pre-Training of Human-Centric Computer Vision Models,2022,ICML,"['Salehe Erfanian Ebadi', 'Saurav Dhakad', 'Sanjay Vishwakarma', 'Chunpu Wang', 'You-Cyuan Jhang', 'Maciek Chociej', 'Adam Crespi', 'Alex Thaman', 'Sujoy Ganguly']",poster,"['Machine Learning', 'Synthetic Data', 'Computer Vision', 'Human-Centric Computer Vision', 'ImageNet', 'Pre-training']","We introduce a new synthetic data generator PSP-HDRI$+$ that proves to be a superior pre-training alternative to ImageNet and other large-scale synthetic data counterparts. We demonstrate that pre-training with our synthetic data will yield a more general model that performs better than alternatives even when tested on out-of-distribution (OOD) sets. Furthermore, using ablation studies guided by person keypoint estimation metrics with an off-the-shelf model architecture, we show how to manipulate our synthetic data generator to further improve model performance.",https://api.openreview.net/pdf/69b2004a816326ce43bfd5b36a5781418ee5ab3f.pdf
Generative Self-training Improves Pre-training for Visual Dialog,2022,ICML,"['Gi-Cheon Kang', 'Sungdong Kim', 'Jin-Hwa Kim', 'Donghyun Kwak', 'Byoung-Tak Zhang']",poster,"['Visual Dialog', 'Self-Training', 'Semi-Supervised Learning', 'Dialogue Generation', 'Vision-and-Language']","Visual dialog (VisDial) is a task of answering a series of questions grounded in an image, using the dialog history as context. Prior work has trained the dialog models solely on VisDial data via supervised learning or leveraged pre-training on related vision-and-language datasets. This paper presents a semi-supervised learning approach for VisDial, called Generative Self-Training (GST), to enhance the pre-training. Specifically, GST generates synthetic dialog data for unlabeled images via multimodal conditional text generation and trains the dialog model on the synthetic and the original VisDial data. Moreover, we also propose perplexity-based data selection and multimodal consistency regularization for robust training of the synthetic data. Evaluation on VisDial v1.0 dataset shows that GST improves the pre-training and achieves new state-of-the-art results.  ",https://api.openreview.net/pdf/cc21f9be527e95c8e256377ac20734f2d7c20935.pdf
The Trade-off between Label Efficiency and Universality of  Representations from Contrastive Learning,2022,ICML,"['Zhenmei Shi', 'Jiefeng Chen', 'Kunyang Li', 'Jayaram Raghuram', 'Xi Wu', 'Yingyu Liang', 'Somesh Jha']",poster,"['Contrastive Learning', 'Self-Supervised Learning', 'Foundation Model', 'Complexity']","The pre-train representation learning paradigm is a recent popular approach to address distribution shift and limitations in training data. This approach first pre-trains a representation function using large unlabeled datasets from multiple tasks by self-supervised (e.g., contrastive) learning, and then learns a simple classifier on the representation using small labeled datasets from the downstream target tasks. The representation should have two key properties: label efficiency (i.e., ability to learn an accurate classifier with a small amount of labeled data) and universality (i.e., usefulness across a wide range of downstream tasks). In this paper, we focus on contrastive learning and systematically study the trade-off between label efficiency and universality both theoretically and empirically. We empirically show that this trade-off exists in different models and datasets. Theoretically, we propose a data model with a hidden representation and provide analysis in a simplified linear setting. Our analysis shows that compared to pre-training on the target task, pre-training on diverse tasks leads to a larger sample complexity for learning the optimal classifier, and thus has worse prediction performance.",https://api.openreview.net/pdf/dd984eb49b33a497be5ddfd73e1786d218f8e83e.pdf
"Democratizing Contrastive Language-Image Pre-training: A CLIP Benchmark of Data, Model, and Supervision",2022,ICML,"['Yufeng Cui', 'Lichen Zhao', 'Feng Liang', 'Yangguang Li', 'Jing Shao']",poster,"['Contrastive Language-Image Pre-training', 'Benchmark', 'Zero-shot Learning']","Contrastive Language-Image Pretraining (CLIP) has emerged as a novel paradigm to learn visual models from language supervision.  While researchers continue to push the frontier of CLIP, reproducing these works remains challenging. This is because researchers do not choose consistent training recipes and even use different data, hampering the fair comparison between different methods. In this work, we propose CLIP-benchmark, a first attempt to evaluate, analyze, and benchmark CLIP and its variants.  We conduct a comprehensive analysis of three key factors: data, supervision, and model architecture. We find considerable intuitive or counter-intuitive insights:  (1). Data quality has a significant impact on performance.  (2). Certain supervision has different effects for Convolutional Networks (ConvNets) and Vision Transformers (ViT).  Applying more proper supervision can effectively improve the performance of CLIP. (3). Curtailing the text encoder reduces the training cost but not much affect the final performance. Moreover, we further combine DeCLIP with FILIP, bringing us the strongest variant DeFILIP. The CLIPbenchmark is released at: https://github.com/Sense-GVT/DeCLIP for future CLIP research.",https://api.openreview.net/pdf/9b5067a9cb479cc1c8459d2410d932abdb80e24e.pdf
LAVA: Language Audio Vision Alignment for Data-Efficient Video Pre-Training,2022,ICML,"['Sumanth Gurram', 'David Chan', 'Andy Fang', 'John Canny']",poster,"['Video', 'Self-Supervised', 'Pre-Training', 'Transformers', 'Multi-Modal', 'Action', 'Recognition']","Generating representations of video data is of key importance in advancing the field of machine perception. Most current techniques rely on hand-annotated data, which can be difficult to work with, expensive to generate, and hard to scale. In this work, we propose a novel learning approach based on contrastive learning, LAVA, which is capable of learning joint language, audio, and video representations in a self-supervised manner. We pre-train LAVA on the Kinetics 700 dataset using transformer encoders to learn representations for each modality. We then demonstrate that LAVA performs competitively with the current state-of-the-art self-supervised and weakly-supervised techniques on UCF-101 and HMDB-51 video action recognition while using a fraction of the unlabeled data.",https://api.openreview.net/pdf/af13907191e5edab04b45c297e0e83e6654f5f00.pdf
Robustness of Inverse Reinforcement Learning,2022,ICML,['Ezgi Korkmaz'],poster,"['reinforcement learning', 'inverse reinforcement learning', 'robust', 'imitation learning', 'deep inverse reinforcement learning']","Reinforcement learning research experienced substantial jumps in its progress after the first achievement on utilizing deep neural networks to approximate the state-action value function in high-dimensional states. While deep reinforcement learning algorithms are currently being employed in many different tasks from industrial control to biomedical applications, yet the fact that an MDP has to provide a clear reward function limits the tasks that can be achieved via reinforcement learning. In this line of research, some studies proposed to directly learn a policy from observing expert trajectories (i.e. imitation learning), and others proposed to learn a reward function from the expert demonstrations (i.e. inverse reinforcement learning). In this paper we will focus on robustness and vulnerabilities of deep imitation learning and deep inverse reinforcement learning policies. Furthermore, we will layout non-robust features learnt by the deep inverse reinforcement learning policies. We conduct experiments in the Arcade Learning Environment (ALE), and compare the non-robust features learnt by the deep inverse reinforcement learning algorithms to vanilla trained deep reinforcement learning policies. We hope that our study can provide a basis for the future discussions on the robustness of both deep inverse reinforcement learning and deep reinforcement learning.",https://api.openreview.net/pdf/c3d1bfc9ca6578a89991971da141304670895e05.pdf
Inferring Relationship using Theory of Mind in Press Diplomacy,2022,ICML,"['Hyeonchang Jeon', 'Songmi Oh', 'Wonsang You', 'Hoyoun Jung', 'Kyung-Joong Kim']",poster,"['Diplomacy', 'Theory of Mind(ToM)', 'Multi-agent learning']","Diplomacy is a turn-based, non-cooperative multiplayer game. In the Press version, the relationships among players change dynamically depending on both the public situation and private communications. To ensure optimal decision-making, an agent should infer the mental states of others to identify relationships that are not explicit. In this paper, we propose the relationship theory of mind (RToM) which focuses on understanding relationships using ToM. We combine graph neural networks (GNNs) that embed the relationships and a ToM neural network (ToMnet) that discovers whom agents trust. To evaluate the RToM, we use the RToM to predict agent responses. If successful, we expect the agents can understand relationships with others to predict the acceptance of the negotiation. Our work is also applicable to other multi-agent reinforcement learning (MARL) problems featuring complex relationships, such as sequential social dilemmas (SSDs).",https://api.openreview.net/pdf/fc66fbf9d6153948e40313ce9205c30a0920ed85.pdf
The AI Macroeconomy: A New Set of Benchmarks for Multiagent Reinforcement Learning Models,2022,ICML,['Brandon Gary Kaplowitz'],poster,"['benchmark', 'marl', 'macroeconomics', 'heterogeneous agents', 'mean-field game', 'markets']","We propose a new set of challenging benchmark gym environments for testing single- and multi-agent reinforcement learning environments. Single-agent environments are based on a simple consumption-saving decision problem. In each period, agents face an exogenous positive draw that represents how much income they will have in this period. In response, agents may choose what fraction of that income they would like to consume immediately for a reward, or save and get a return going forward on it.
In the full version of the problem, all agents' saving decisions generate a price via market clearing. Agents then must learn what their value will be conditioned on the current state. This environment will provide a challenging, potentially non-stationary environment where agents' actions have critical effects on other agents' actions, albeit via a common observation. This environment will be made publicly available via a Github repository and open-source.",https://api.openreview.net/pdf/9edbb5d11d2670b5e32d447af53c9e181f785595.pdf
Risk Perspective Exploration in Distributional Reinforcement Learning,2022,ICML,"['Jihwan Oh', 'Joonkee Kim', 'Se-Young Yun']",poster,"['proposal', 'distributional reinforcement learning', 'exploration', 'risk-based', 'distribution-based']","Distributional reinforcement learning demonstrates state-of-the-art performance in continuous and discrete control settings with the features of variance and risk, which can be used to explore. However, the exploration method employing the risk property is hard to find, although numerous exploration methods in Distributional RL employ the variance of return distribution per action. In this paper, we present risk scheduling approaches that explore risk levels and optimistic behaviors from a risk perspective. We demonstrate the performance enhancement of the DMIX algorithm using risk scheduling in a multi-agent setting with comprehensive experiments.",https://api.openreview.net/pdf/7e20dee3527585d06f3de62842baabd2bbcd3512.pdf
A Variational Approach to  Mutual Information-Based Coordination for Multi-Agent Reinforcement Learning,2022,ICML,"['Woojun Kim', 'Whiyoung Jung', 'Myungsik Cho', 'Youngchul Sung']",poster,"['Multi-Agent Reinforcement Learning', 'Variational Approach', 'Mutual Information', 'Coordination']","In this paper, we propose a new mutual information (MMI) framework for multi-agent reinforcement learning (MARL) to enable multiple agents to learn coordinated behaviors by regularizing the accumulated return with the mutual information between multi-agent actions. By introducing a latent variable to induce nonzero mutual information between multi-agent actions and applying a variational bound, we derive a tractable lower bound on the considered MMI-regularized objective function. Applying policy iteration to maximize the derived lower bound, we propose a practical algorithm named variational maximum mutual information multi-agent actor-critic (VM3-AC). We evaluated VM3-AC for several games requiring coordination, and numerical results show that VM3-AC outperforms other MARL algorithms in multi-agent tasks requiring coordination.",https://api.openreview.net/pdf/f71e2e50755d08506371753f1017ccf85c5b2bb8.pdf
Convergence and Price of Anarchy Guarantees of the Softmax Policy Gradient in Markov Potential Games,2022,ICML,"['Dingyang Chen', 'Qi Zhang', 'Thinh T. Doan']",poster,[],"We study the performance of policy gradient methods for the subclass of Markov games known as Markov potential games (MPGs), which extends the notion of normal-form potential games to the stateful setting and includes the important special case of the fully cooperative setting where the agents share an identical reward function. Our focus in this paper is to study the convergence of the policy gradient method for solving MPGs under softmax policy parameterization, both tabular and parameterized with general function approximators such as neural networks. We first show the asymptotic convergence of this method to a Nash equilibrium of MPGs for tabular softmax policies. Second, we derive the finite-time performance of the policy gradient in two settings: 1)  using the log-barrier regularization, and 2) using the natural policy gradient under the best-response dynamics (NPG-BR). Finally, extending the notion of price of anarchy (POA) and smoothness in normal-form games, we introduce the POA for MPGs and provide a POA bound for NPG-BR. To our knowledge, this is the first POA bound for solving MPGs. To support our theoretical results, we empirically compare the convergence rates and POA of exact and sample-based policy gradient variants for both tabular and neural softmax policies.",https://api.openreview.net/pdf/2e3fc7ec9b9b4c4ff7d0076074c55f2bc124459a.pdf
Deep Learning-based Spatially Explicit Emulation of an Agent-Based Simulator for Pandemic in a City,2022,ICML,"['Varun Madhavan', 'Adway Mitra', 'Partha Pratim Chakrabarti']",poster,"['agent-based simulation', 'surrogate modelling', 'spatio-temporal sequence prediction', 'Covid-19 modelling']","Agent-Based Models are very useful for simulation of physical or social processes, such as the spreading of a pandemic in a city. Such models proceed by specifying the behavior of individuals (agents) and their interactions, and parameterizing the process of infection based on such interactions based on the geography and demography of the city. However, such models are computationally very expensive, and the complexity is often linear in the total number of agents. This seriously limits the usage of such models for simulations, which often have to be run hundreds of times for policy planning and even model parameter estimation. An alternative is to develop an emulator, a surrogate model that can predict the Agent-Based Simulator's output based on its initial conditions and parameters. In this paper, we discuss a Deep Learning model based on Dilated Convolutional Neural Network that can emulate such an agent based model with high accuracy. We show that use of this model instead of the original Agent-Based Model provides us major gains in the speed of simulations, allowing much quicker calibration to observations, and more extensive scenario analysis. The models we consider are spatially explicit, as the locations of the infected individuals are simulated instead of the gross counts. Another aspect of our emulation framework is its divide-and-conquer approach that divides the city into several small overlapping blocks and carries out the emulation in them parallelly, after which these results are merged together. This ensures that the same emulator can work for a city of any size, and also provides significant improvement of time complexity of the emulator, compared to the original simulator. ",https://api.openreview.net/pdf/c0bae48f9a0a9acf4ea086c1ef2d8bfce3ee6bc2.pdf
Low-Loss Subspace Compression for Clean Gains against Multi-Agent Backdoor Attacks,2022,ICML,"['Siddhartha Datta', 'Nigel Shadbolt']",poster,[],"Recent exploration of the multi-agent backdoor attack demonstrated the backfiring effect, a natural defense against backdoor attacks where backdoored inputs are randomly classified. This yields a side-effect of low accuracy w.r.t. clean labels, which motivates this paper's work on the construction of multi-agent backdoor defenses that maximize accuracy w.r.t. clean labels and minimize that of poison labels. Founded upon agent dynamics and low-loss subspace construction, we contribute three defenses that yield improved multi-agent backdoor robustness.",https://api.openreview.net/pdf/42e9589283887cbde42b6fd01a65040c62297ca2.pdf
MetaShift: A Dataset of Datasets for Evaluating Contextual Distribution Shifts,2022,ICML,"['Weixin Liang', 'Xinyu Yang', 'James Y. Zou']",oral,[],"Understanding the performance of machine learning models across diverse data distributions is critically important for reliable applications. Motivated by this, there is a growing focus on curating benchmark datasets that capture distribution shifts. In this work, we present MetaShift—a collection of 12,868 sets of natural images across 410 classes—to address this challenge. We leverage the natural heterogeneity of Visual Genome and its annotations to construct MetaShift. The key construction idea is to cluster images using its metadata, which provides context for each image (e.g. cats with cars or cats in bathroom) that represent distinct data distributions. MetaShift has two important benefits: first, it contains orders of magnitude more natural data shifts than previously available. Second, it provides explicit explanations of what is unique about each of its data sets and a distance score that measures the amount of distribution shift between any two of its data sets. Importantly, MetaShift can be readily used to evaluate any ImageNet pre-trained vision model, as we have matched MetaShift with ImageNet hierarchy. The matched version covers 867 out of 1,000 classes in ImageNet-1k. Each class in the ImageNet-matched MetaShift contains 2301.6 images on average, and 19.3 subsets capturing images in different contexts. We also propose methods to construct either binary or multiclass classification tasks, providing access to evaluate the model’s robustness across diverse distribution shifts.",https://api.openreview.net/pdf/f3abf5c031f35559d99be5fe3b43e913fd47744a.pdf
When does dough become a bagel?Analyzing the remaining mistakes on ImageNet,2022,ICML,"['Vijay Vasudevan', 'Benjamin Caine', 'Raphael Gontijo-Lopes', 'Sara Fridovich-Keil', 'Rebecca Roelofs']",oral,"['mistake analysis', 'ImageNet', 'multi-label evaluation']","Image classification accuracy on the ImageNet dataset has been a barometer for progress in computer vision over the last decade. Several recent papers have questioned the degree to which the benchmark remains useful to the community, yet innovations continue to contribute gains to performance, with today's largest models achieving 90%+ top-1 accuracy. To help contextualize progress on ImageNet and provide a more meaningful evaluation for today's state-of-the-art models, we manually review and categorize every remaining mistake that a few top models make and provide insights into the long-tail of errors on one of the most benchmarked datasets in computer vision. We focus on the multi-label subset evaluation of ImageNet, where today's best models achieve upwards of 97% top-1 accuracy. Our analysis reveals that nearly half of the supposed mistakes are not mistakes at all, and we uncover new valid multi-labels, demonstrating that, without careful review, we are significantly underestimating the performance of these models. On the other hand, we also find that today's best models still make a significant number of mistakes (40%) that are obviously wrong to human reviewers. To calibrate future progress on ImageNet, we provide an updated multi-label evaluation set, and we curate ImageNet-Major: a 68-example ""major error"" slice of the obvious mistakes made by today's top models---a slice where models should achieve near perfection, but today are far from doing so.",https://api.openreview.net/pdf/cf12e00bbc94041110a92a58da90e2d7e1638cfe.pdf
ImageNet-Patch: A Dataset for Benchmarking Machine Learning Robustness against Adversarial Patches,2022,ICML,"['Maura Pintor', 'Daniele Angioni', 'Angelo Sotgiu', 'Luca Demetrio', 'Ambra Demontis', 'Battista Biggio', 'Fabio Roli']",oral,"['adversarial machine learning', 'machine learning', 'out of ditribution detection', 'computer vision']","Adversarial patches are optimized contiguous pixel blocks in an input image that cause a  machine-learning model to misclassify it.
However, their optimization is computationally demanding and requires careful hyperparameter tuning.
To overcome these issues, we propose ImageNet-Patch, a dataset to benchmark machine-learning models against adversarial patches.
It consists of a set of patches optimized to generalize across different models and applied to ImageNet data after preprocessing them with affine transformations.
This process enables an approximate yet faster robustness evaluation, leveraging the transferability of adversarial perturbations.",https://api.openreview.net/pdf/70697c9ceb38f532541cde6c98ee3f694da9c56a.pdf
LinkBERT: Pretraining Language Models with Document Links,2022,ICML,"['Michihiro Yasunaga', 'Jure Leskovec', 'Percy Liang']",poster,"['language model', 'pretraining', 'scientific text', 'citation link', 'citation network', 'biomedicine', 'bionlp', 'knowledge', 'reasoning', 'question answering']","Language model (LM) pretraining can learn various knowledge from text corpora, helping downstream tasks. 
However, existing methods such as BERT model a single document, and do not capture dependencies or knowledge that span across documents. In this work, we propose LinkBERT, an LM pretraining method that leverages links between documents, e.g., hyperlinks, citation links. Given a text corpus, we view it as a graph of documents and create LM inputs by placing linked documents in the same context. We then pretrain the LM with two joint self-supervised objectives: masked language modeling and our new proposal, document relation prediction. 
We show that LinkBERT outperforms BERT on diverse downstream tasks across both general domain (pretrained on Wikipedia with hyperlinks) and biomedical domain (pretrained on PubMed with citation links). In particular, LinkBERT is effective for knowledge- and reasoning-intensive tasks such as multi-hop reasoning and few-shot inference (+7\% absolute gain on BioASQ and MedQA), and achieves new state-of-the-art results on various biomedical NLP tasks including relation extraction and literature classification. Our results suggest the promise of LinkBERT for scientific applications.
We release our pretrained models, LinkBERT and BioLinkBERT, as well as code and data.",https://api.openreview.net/pdf/8c1c560bc9844884a614988eaf9dfd41372fd61c.pdf
Graphein - a Python Library for Geometric Deep Learning and Network Analysis on Biomolecular Structures and Interaction Networks,2022,ICML,"['Arian Rokkum Jamasb', 'Ramon Viñas Torné', 'Eric J Ma', 'Yuanqi Du', 'Charles Harris', 'Kexin Huang', 'Dominic Hall', 'Pietro Lio', 'Tom Leon Blundell']",poster,"['Protein', 'Drug Discovery', 'Geometric Deep Learning', 'Biomolecules']","Geometric deep learning has broad applications in biology, a domain where relational structure in data is often intrinsic to modelling the underlying phenomena. Currently, efforts in both geometric deep learning and, more broadly, deep learning applied to biomolecular tasks have been hampered by a scarcity of appropriate datasets accessible to domain specialists and machine learning researchers alike. To address this, we introduce Graphein as a turn-key tool for transforming raw data from widely-used bioinformatics databases into machine learning-ready datasets in a high-throughput and flexible manner. Graphein is a Python library for constructing graph and surface-mesh representations of biomolecular structures, such as proteins, nucleic acids and small molecules, and biological interaction networks for computational analysis and machine learning. Graphein provides utilities for data retrieval from widely-used bioinformatics databases for structural data, including the Protein Data Bank, the AlphaFold Structure Database, chemical data from ZINC and ChEMBL, and for biomolecular interaction networks from STRINGdb, BioGrid, TRRUST and RegNetwork. The library interfaces with popular geometric deep learning libraries: DGL, Jraph, PyTorch Geometric and PyTorch3D though remains framework agnostic as it is built on top of the PyData ecosystem to enable inter-operability with scientific computing tools and libraries.  Graphein is designed to be highly flexible, allowing the user to specify each step of the data preparation, scalable to facilitate working with large protein complexes and interaction graphs, and contains useful pre-processing tools for preparing experimental files. Graphein facilitates network-based, graph-theoretic and topological analyses of structural and interaction datasets in a high-throughput manner. We envision that Graphein will facilitate developments in computational biology, graph representation learning and drug discovery. \\

Availability and implementation: Graphein is written in Python. Source code, example usage and tutorials, datasets, and documentation are made freely available under the MIT License at the following URL: https://anonymous.4open.science/r/graphein-3472/README.md",https://api.openreview.net/pdf/45238d952fdf667d8992ff778b671560b214cbce.pdf
On the Relationships between Graph Neural Networks for the Simulation of Physical Systems and Classical Numerical Methods,2022,ICML,"['Artur Toshev', 'Ludger Paehler', 'Andrea Panizza', 'Nikolaus A. Adams']",poster,"['graph neural networks', 'numerical methods', 'numerical simulation', 'physical simulations']","Recent developments in Machine Learning approaches for modelling physical systems have begun to mirror the past development of numerical methods in the computational sciences. In this survey we begin by providing an example of this development with the parallels between graph neural network acceleration for physical simulations and the development of particle-based approaches. We then give an overview of simulation approaches, which have not yet found their way into state-of-the-art Machine Learning methods and hold the potential to make Machine Learning approaches more accurate and more efficient. We conclude by presenting an outlook on the potential of these approaches for making Machine Learning models for science more efficient.",https://api.openreview.net/pdf/8d11fb72a3324aacd4ba061ed0e41e1cb924f0f9.pdf
Intelligent Digital Twins can Accelerate Scientific Discovery and Control Complex Multi-Physics Processes,2022,ICML,"['Arden Phua', 'Gary W Delaney', 'Peter S. Cook', 'Chris H.J. Davies']",poster,"['Digital Twins', 'Additive Manufacturing', 'Gaussian Processes']","The emerging area of Intelligent Digital Twins (IDTs) offers great potential as a new paradigm for accelerating scientific discovery, while also offering state-of-the-art functionality in controlling complex physical processes. We investigate this concept for the case of an Intelligent Digital Twin of metal additive manufacturing (AM). Metal AM is an excellent choice for utilising an IDT due to the process being an inherently complex multi-physics one, with key elements including granular powder flow, laser melting and material solidification. This complexity means that computational simulations are extremely costly and obtaining high quality experimental data is extremely difficult, so optimal exploration of the parameter space using all available information on the current uncertainty in the region of interest is highly desirable. Our Intelligent Digital Twin for this process includes a complete description of the target geometry of the object being printed and a set of data-driven and computational models for the different physical processes occurring in the system. The data-driven models consist of a set of Gaussian Processes (GP) that can be trained using combinations of real world sensor data and outputs from computational simulations. We illustrate the utility of our IDT by determining optimal input print parameters and obtaining Pareto fronts between competing priorities such as surface roughness and print time. We also demonstrate the potential of the IDT as an intelligent control system to respond to errors during the print process and dynamically improve final print quality. ",https://api.openreview.net/pdf/2b722f7ca058f7a01d3cf12e257eecc3247e9cdb.pdf
Reinforced Genetic Algorithm for Structure-based Drug Design,2022,ICML,"['Tianfan Fu', 'Wenhao Gao', 'Connor W. Coley', 'Jimeng Sun']",poster,"['molecule generation', 'molecule optimization']","Structure-based drug design (SBDD) aims to discover drug candidates by finding molecules (ligands) that bind tightly to a disease-related protein (targets), which is the primary approach to computer-aided drug discovery.
Recently, applying deep generative models for three-dimensional (3D) molecular design conditioned on protein pockets to solve SBDD has attracted much attention, but their formulation as probabilistic modeling often leads to unsatisfactory optimization performance. 
On the other hand, traditional combinatorial optimization methods such as genetic algorithms (GA) have demonstrated state-of-the-art performance in various molecular optimization tasks. However, they do not utilize protein target structure to inform design steps but rely on a random-walk-like exploration, which leads to unstable performance and no knowledge transfer between different tasks despite the similar binding physics.
To achieve a more stable and efficient SBDD, we propose Reinforced Genetic Algorithm that uses neural models to prioritize the profitable design steps and suppress random-walk behavior. 
The neural models take the 3D structure of the targets and ligands as inputs and are pre-trained using native complex structures to utilize the knowledge of the shared binding physics from different targets and then fine-tuned during optimization. 
We conduct thorough empirical studies on optimizing binding affinity to various disease targets and show that Reinforced Genetic Algorithm outperforms the baselines in terms of docking scores and is more robust to random initializations. The ablation study also indicates that the training on different targets helps improve the performance by leveraging the shared underlying physics of the binding processes. ",https://api.openreview.net/pdf/8e067b82433a77fb8cadcc1cb1f54b80dc1cf3a3.pdf
Improving Subgraph Representation Learning via Multi-View Augmentation,2022,ICML,"['Yili Shen', 'Jiaxu Yan', 'Cheng-Wei Ju', 'Jun Yi', 'Zhou Lin', 'Hui Guan']",poster,"['Graph Learning', 'Subgraph Representation Learning', 'Graph Data Augmentation', 'Multi-view Augmentation']","Subgraph representation learning based on Graph Neural Network (GNN) has exhibited broad applications in scientific advancements, such as predictions of molecular structure-property relationships and collective cellular function. In particular, graph augmentation techniques have shown promising results in improving graph-based and node-based classification tasks. Still, they have rarely been explored in the existing GNN-based subgraph representation learning studies. In this study, we develop a novel multi-view augmentation mechanism to improve subgraph representation learning models and thus the accuracy of downstream prediction tasks. Our augmentation technique creates multiple variants of subgraphs and embeds these variants into the original graph to achieve highly improved training efficiency, scalability, and accuracy. Benchmark experiments on several real-world biological and physiological datasets demonstrate the superiority of our proposed multi-view augmentation techniques in subgraph representation learning.",https://api.openreview.net/pdf/2cc85fe846f91295b9fec3b2b5843546eed0ec30.pdf
Path Integral Stochastic Optimal Control for Sampling Transition Paths,2022,ICML,"['Lars Holdijk', 'Yuanqi Du', 'Priyank Jaini', 'Ferry Hooft', 'Bernd Ensing', 'Max Welling']",poster,"['Stochastic Optimal Control', 'Transition Path Sampling', 'Molecular Dynamics', 'Protein Folding', 'Equivariance']","We consider the problem of Sampling Transition Paths. Given two metastable conformational states of a molecular system, \eg\ a folded and unfolded protein, we aim to sample the most likely transition path between the two states. Sampling such a transition path is computationally expensive due to the existence of high free energy barriers between the two states. To circumvent this, previous work has focused on simplifying the trajectories to occur along specific molecular descriptors called Collective Variables (CVs). However, finding CVs is not trivial and requires chemical intuition. For larger molecules, where intuition is not sufficient, using these CV-based methods biases the transition along possibly irrelevant dimensions. Instead, this work proposes a method for sampling transition paths that consider the entire geometry of the molecules. To achieve this, we first relate the problem to recent work on the Schrodinger bridge problem and stochastic optimal control. Using this relation, we construct a method that takes into account important characteristics of molecular systems such as second-order dynamics and invariance to rotations and translations. We demonstrate our method on the commonly studied Alanine Dipeptide, but also consider larger proteins such as Polyproline and Chignolin. 
",https://api.openreview.net/pdf/61a5adfdc808b2549208eb36b00a3c595780ab16.pdf
Evaluating Self-Supervised Learned Molecular Graphs,2022,ICML,"['Hanchen Wang', 'Shengchao Liu', 'Jean Kaddour', 'Qi Liu', 'Jian Tang', 'Matt Kusner', 'Joan Lasenby']",poster,[],"Because of data scarcity in real-world scenarios, obtaining pre-trained representations via self-supervised learning (SSL) has attracted increasing interest. Although various methods have been proposed, it is still under-explored what knowledge the networks learn from the pre-training tasks and how it relates to downstream properties. In this work, with an emphasis on chemical molecular graphs, we fill in this gap by devising a range of node-level, pair-level, and graph-level probe tasks to analyse the representations from pre-trained graph neural networks (GNNs). We empirically show that: 1. Pre-trained models have better downstream performance compared to randomly-initialised models due to their improved the capability of capturing global topology and recognising substructures. 2. However, randomly initialised models outperform pre-trained models in terms of retaining local topology. Such information gradually disappears from the early layers to the last layers for pre-trained models.",https://api.openreview.net/pdf/57a3d1e5ef81bd1f1f59c0c34f9b7bf560323d88.pdf
Unifying physical systems’ inductive biases in neural ODE using dynamics constraints,2022,ICML,"['Yi Heng Lim', 'Muhammad Firmansyah Kasim']",poster,"['neural ode', 'physics', 'energy conservation', 'constraints']","Conservation of energy is at the core of many physical phenomena and dynamical systems. There have been a significant number of works in the past few years aimed at predicting the trajectory of motion of dynamical systems using neural networks while adhering to the law of conservation of energy. Most of these works are inspired by classical mechanics such as Hamiltonian and Lagrangian mechanics as well as Neural Ordinary Differential Equations. While these works have been shown to work well in specific domains respectively, there is a lack of a unifying method that is more generally applicable without requiring significant changes to the neural network architectures. In this work, we aim to address this issue by providing a simple method that could be applied to not just energy-conserving systems, but also dissipative systems, by including a different inductive bias in different cases in the form of a regularisation term in the loss function. The proposed method does not require changing the neural network architecture and could form the basis to validate a novel idea, therefore showing promises to accelerate research in this direction.",https://api.openreview.net/pdf/1c175d78650c2bf69354fe55bec27a5d2d1296ed.pdf
PowerGraph: Using neural networks and principal components to determine multivariate statistical power trade-offs,2022,ICML,"['Ajinkya K Mulay', 'Sean P Lane', 'Erin Hennes']",poster,"['statistical power', 'transfer learning']","Statistical power estimation for studies with multiple model parameters is inherently a multivariate problem. Power for individual parameters of interest cannot be reliably estimated univariately since correlation and variance explained relative to one parameter will impact the power for another parameter, all usual univariate considerations being equal. Explicit solutions in such cases, especially for models with many parameters, are either impractical or impossible to solve, leaving researchers to the prevailing method of simulating power. However, the point estimates for a vector of model parameters are uncertain, and the impact of inaccuracy is unknown. In such cases, sensitivity analysis is recommended such that multiple combinations of possible observable parameter vectors are simulated to understand power trade-offs. A limitation to this approach is that it is computationally expensive to generate sufficient sensitivity combinations to accurately map the power trade-off function in increasingly high-dimensional spaces for the models that social scientists estimate. This paper explores the efficient estimation and graphing of statistical power for a study over varying model parameter combinations. We propose a simple and generalizable machine learning inspired solution to cut the computational cost to less than 10% of the brute force method while providing F1 scores above 90%. We further motivate the impact of transfer learning in learning power manifolds across varying distributions.",https://api.openreview.net/pdf/984265a4cfafcfe5a5a2f97ccdb365e5e5eb5016.pdf
From Kepler to Newton: Explainable AI for Science Discovery,2022,ICML,"['Zelong Li', 'Jianchao Ji', 'Yongfeng Zhang']",poster,"['Explainable AI', 'Science Discovery', 'Scientific Method', 'Technological Singularity', 'Human and Nature']","The Observation --- Hypothesis --- Prediction --- Experimentation loop paradigm for scientific research has been practiced by researchers for years towards scientific discoveries. However, with data explosion in both mega-scale and milli-scale research, it has been sometimes very difficult to manually analyze the data and propose new hypotheses to drive the cycle for scientific discovery.
In this paper, we discuss the role of Explainable AI in scientific discovery process by demonstrating an Explainable AI-based paradigm for science discovery. The key is to use Explainable AI to help derive data or model interpretations, hypotheses, as well as scientific discoveries or insights. We show how computational and data-intensive methodology---together with experimental and theoretical methodology---can be seamlessly integrated for scientific research. To demonstrate the AI-based science discovery process, and to pay our respect to some of the greatest minds in human history, we show how Kepler's laws of planetary motion and Newton's law of universal gravitation can be rediscovered by (Explainable) AI based on Tycho Brahe's astronomical observation data, whose works were leading the scientific revolution in the 16-17th century. This work also highlights the important role of Explainable AI (as compared to Blackbox AI) in science discovery to help humans prevent or better prepare for the possible technological singularity that may happen in the future, since science is not only about the know how, but also the know why.",https://api.openreview.net/pdf/ab0ae14763754c5ae34a50a68f1303185d8ed8a9.pdf
LAST: Latent Space Assisted Adaptive Sampling for Protein Trajectories,2022,ICML,"['Hao Tian', 'Xi Jiang', 'Sian Xiao', 'Hunter La Force', 'Eric Larson', 'Peng Tao']",poster,"['Variational Autoencoder', 'Molecular Dynamics', 'Adaptive Sampling']","Molecular dynamics (MD) simulation is widely used to study protein conformations and dynamics. However, conventional simulation suffers from being trapped in some local energy minima that are hard to escape. Thus, most computational time is spent sampling in the already visited regions. This leads to an inefficient sampling process and further hinders the exploration of protein movements in affordable simulation time. The advancement of deep learning provides new opportunities for protein sampling. Variational autoencoders are a class of deep learning models to learn a low-dimensional representation (referred to as the latent space) that can capture the key features of the input data. Based on this characteristic, we proposed a new adaptive sampling method, latent space assisted adaptive sampling for protein trajectories (LAST), to accelerate the exploration of protein conformational space. This method comprises cycles of (i) variational autoencoders training, (ii) seed structure selection on the latent space and (iii) conformational sampling through additional MD simulations. The proposed approach is validated through the sampling of four structures of two protein systems: two metastable states of E. Coli adenosine kinase (ADK) and two native states of Vivid (VVD). In all four conformations, seed structures were shown to lie on the boundary of conformation distributions. Moreover, large conformational changes were observed in a shorter simulation time when compared with conventional MD (cMD) simulations in both systems. In metastable ADK simulations, LAST explored two transition paths toward two stable states while cMD became trapped in an energy basin. In VVD light state simulations, LAST was three times faster than cMD simulation with a similar conformational space.",https://api.openreview.net/pdf/2029465fd9e4d208f477b1e8e557fb27ef8614b5.pdf
One-Shot Transfer Learning of Physics-Informed Neural Networks,2022,ICML,"['Shaan Desai', 'Marios Mattheakis', 'Hayden Joy', 'Pavlos Protopapas', 'Stephen J. Roberts']",poster,"['physics', 'digital twins', 'surrogates', 'transfer learning']","Solving differential equations efficiently and accurately sits at the heart of progress in many areas of scientific research, from classical dynamical systems to quantum mechanics. There is a surge of interest in using Physics-Informed Neural Networks (PINNs) to tackle such problems as they provide numerous benefits over traditional numerical approaches. Despite their potential benefits for solving differential equations, transfer learning has been under explored. In this study, we present a general framework for transfer learning PINNs that results in one-shot inference for linear systems of both ordinary and partial differential equations. This means that highly accurate solutions to many unknown differential equations can be obtained instantaneously without retraining an entire network. We demonstrate the efficacy of the proposed deep learning approach by solving several real-world problems, such as first- and second-order linear ordinary equations, the Poisson equation, and the time-dependent Schr\""{o}dinger complex-value partial differential equation.
",https://api.openreview.net/pdf/bb326153cd495e3bfed33a2d138a119b69fc9ab5.pdf
Weakly Supervised Inversion of Multi-physics Data for Geophysical Properties,2022,ICML,"['Shihang Feng', 'Peng Jin', 'Yinpeng Chen', 'Xitong Zhang', 'Zicheng Liu', 'David Alumbaugh', 'Michael Commer', 'Youzuo Lin']",poster,"['Multi-physics Inversion', 'Weakly Supervised', 'Pseudo Labels']","Multi-physics inversion plays a critical role in geophysics. It has been widely used to simultaneously infer various geophysical properties~(such as velocity and conductivity). Among those inversion problems, some are explicitly governed by partial differential equations~(PDEs), while others are not. Without explicit governing equations, conventional physical-based inversion techniques are not feasible and data-driven inversion requires expensive full labels. To overcome this issue, we proposed a new data-driven multi-physics inversion technique with extremely weak supervision. Our key finding is that the pseudo labels can be constructed by learning the local relationship among geophysical properties at very sparse locations. We explore the multi-physics inversion problem from two distinct measurements~(seismic and electromagnetic data) to three geophysical properties~(velocity, conductivity, and $\mathrm{CO_2}$ saturation) with synthetic data based on the Kimberlina storage reservoir in California.  Our results show that we are able to invert for properties without explicit governing equations. Moreover, the labeled data on three geophysical properties can be significantly reduced by 50 times~(from 100 down to only 2 locations).",https://api.openreview.net/pdf/cda488a8bd7734adfe75d066f569b88ab1903f16.pdf
How Much of the Chemical Space Has Been Explored? Selecting the Right Exploration Measure for Drug Discovery,2022,ICML,"['Yutong Xie', 'Ziqiao Xu', 'Jiaqi Ma', 'Qiaozhu Mei']",poster,"['molecular generation', 'drug discovery', 'exploration measures']","Forming a molecular candidate set that contains a wide range of potentially effective compounds is crucial to the success of drug discovery. While many aim to optimize particular chemical properties, there is limited literature on how to properly measure and encourage the exploration of the chemical space when generating drug candidates. This problem is challenging due to the lack of formal criteria to select good exploration measures. We propose a novel framework to systematically evaluate exploration measures for drug candidate generation. The framework is built upon three formal analyses: an axiomatic analysis that validates the potential measures analytically, an empirical analysis that compares the correlations of the measures to a proxy gold standard, and a practical analysis that benchmarks the effectiveness of the measures in an optimization framework of molecular generation. We are able to evaluate a wide range of potential exploration measures under this framework and make recommendations on existing and novel exploration measures that are suitable for the task of drug discovery.",https://api.openreview.net/pdf/b641a6a2a88d066ef60b98db30087b0705bba42e.pdf
No Free Lunch from Deep Learning in Neuroscience: A Case Study through Models of the Entorhinal-Hippocampal Circuit,2022,ICML,"['Rylan Schaeffer', 'Mikail Khona', 'Ila R Fiete']",poster,"['neuroscience', 'deep learning']","Fundamental research in Neuroscience is currently undergoing a renaissance based on deep learning. The central promises of deep learning-based modeling of brain circuits are that the models shed light on evolutionary optimization problems, constraints and solutions, and generate novel predictions regarding neural phenomena. We show, through the case-study of grid cells in the entorhinal-hippocampal circuit, that one often gets neither. We begin by reviewing the principles of grid cell mechanism and function obtained from analytical and first-principles modeling efforts, then consider the claims of deep learning models of grid cells and rigorously examine their results under varied conditions. Using large-scale hyperparameter sweeps and hypothesis-driven experimentation, we demonstrate that the results of such models may reveal more about particular and non-fundamental implementation choices than fundamental truths about neural circuits or the loss function(s) they might optimize. Finally, we discuss why it is that these models of the brain cannot be expected to work without the addition of substantial amounts of inductive bias, an informal No Free Lunch theorem for Neuroscience. In conclusion, caution and consideration, together with biological knowledge, are warranted in building and interpreting deep learning models in Neuroscience.",https://api.openreview.net/pdf/c8ed8ccf35cd0e07feda1bf9e9f88c587c53f849.pdf
Predicting generalization with degrees of freedom in neural networks,2022,ICML,"['Erin Grant', 'Yan Wu']",poster,"['generalization', 'compression']","Model complexity is fundamentally tied to predictive power in the sciences as well as in applications. However, there is a divergence between naive measures of complexity such as parameter count and the generalization performance of over-parameterized machine learning models. Prior empirical approaches to capturing intrinsic complexity in a more sophisticated manner than parameter count are computationally intractable, do not capture the implicitly regularizing effects of the entire machine-learning pipeline, or do not provide a quantitative fit to the double descent behavior of overparameterized models. In this work, we introduce an empirical complexity measure inspired by the classical notion of generalized degrees of freedom in statistics. This measure can be approximated efficiently and is a function of the entire machine learning training pipeline. We demonstrate that this measure correlates with generalization performance in the double-descent regime.",https://api.openreview.net/pdf/74bd7f47b7b224b2cb5e896de832d5b93194ff86.pdf
Unsupervised Discovery of Inertial-Fusion Plasma Physics using Differentiable Kinetic Simulations and a Maximum Entropy Loss Function,2022,ICML,"['Archis Joglekar', 'Alexander Thomas']",poster,"['automatic differentiation', 'plasma physics', 'simulations', 'partial differential equations', 'differentiable programming', 'kinetic plasma physics', 'automated physics discovery']","Plasma supports collective modes and particle-wave interactions that leads to complex behavior in inertial fusion energy applications. While plasma can sometimes be modeled as a charged fluid, a kinetic description is useful towards the study of nonlinear effects in the higher dimensional momentum-position phase-space that describes the full complexity of plasma dynamics. We create a differentiable solver for the plasma kinetics 3D partial-differential-equation and introduce a domain-specific objective function based on the maximum entropy principle. Using this framework, we perform gradient-based optimization of neural networks that provide forcing function parameters to the differentiable solver given a set of initial conditions. We apply this to an inertial-fusion relevant configuration and find that the optimization process exploits a novel physical effect that has previously remained undiscovered.",https://api.openreview.net/pdf/2f742b58916220a89206b1305c9db7c6dfe3c52c.pdf
MultiScale MeshGraphNets,2022,ICML,"['Meire Fortunato', 'Tobias Pfaff', 'Peter Wirnsberger', 'Alexander Pritzel', 'Peter Battaglia']",poster,"['graph neural networks', 'simulations', 'multiscale', 'mesh']","In recent years, there has been a growing interest in using machine learning to overcome the high cost of numerical simulation, with some learned models achieving impressive speed-ups over classical solvers whilst maintaining accuracy. However, these methods are usually tested at low-resolution settings, and it remains to be seen whether they can scale to the costly high-resolution simulations that we ultimately want to tackle.
In this work, we propose two complementary approaches to improve the framework from MeshGraphNets, which demonstrated accurate predictions in a broad range of physical systems. MeshGraphNets relies on a message passing graph neural network to propagate information, and this structure becomes a limiting factor for high-resolution simulations, as equally distant points in space become further apart in graph space. First, we demonstrate that it is possible to learn accurate surrogate dynamics of a high-resolution system on a much coarser mesh, both removing the message passing bottleneck and improving performance; and second, we introduce a hierarchical approach (MultiScale MeshGraphNets) which passes messages on two different resolutions (fine and coarse), significantly improving the accuracy of MeshGraphNets while requiring less computational resources.
",https://api.openreview.net/pdf/a7bf090f67f8d2b4d254d94296645ac54ac81d6d.pdf
Curvature-informed multi-task learning for graph networks,2022,ICML,"['Alexander New', 'Michael J Pekala', 'Nam Q Le', 'Janna Domenico', 'Christine D. Piatko', 'Christopher D Stiles']",poster,"['graph neural networks', 'multi-task learning', 'chemical property prediction', 'materials property prediction', 'hessians']","Properties of interest for crystals and molecules, such as band gap, elasticity, and solubility, are generally related to each other: they are governed by the same underlying laws of physics. However, when state-of-the-art graph neural networks attempt to predict multiple properties simultaneously (the multi-task learning (MTL) setting), they frequently underperform a suite of single property predictors. This suggests graph networks may not be fully leveraging these underlying similarities.  Here we investigate a potential explanation for this phenomenon – the curvature of each property’s loss surface significantly varies, leading to inefficient learning. This difference incurvature can be assessed by looking at spectral properties of the Hessians of each property’s loss function, which is done in a matrix-free manner via randomized numerical linear algebra. We evaluate our hypothesis on two benchmark datasets (Materials Project (MP) and QM8) and consider how these findings can inform the training of novel multi-task learning models.",https://api.openreview.net/pdf/2a7fd4400c57368aeb6c173e7f3039ac14252954.pdf
Neural Basis Functions for Accelerating Solutions to high Mach Euler Equations,2022,ICML,"['David Witman', 'Alexander New', 'Hicham Alkandry', 'Honest Mrema']",poster,"['Machine Learning', 'Scientific Machine Learning', 'Neural Networks', 'Partial Differential Equations', 'Euler Equations']",We propose an approach to solving partial differential equations (PDEs) using a set of neural networks which we call Neural Basis Functions (NBF). This NBF framework is a novel variation of the POD DeepONet operator learning approach where we regress a set of neural networks onto a reduced order Proper Orthogonal Decomposition (POD) basis. These networks are then used in combination with a branch network that ingests the parameters of the prescribed PDE to compute a reduced order approximation to the PDE. This approach is applied to the steady state Euler equations for high speed flow conditions (mach 10-30) where we consider the 2D flow around a cylinder which develops a shock condition. We then use the NBF predictions as initial conditions to a high fidelity Computational Fluid Dynamics (CFD) solver (CFD++) to show faster convergence. Lessons learned for training and implementing this algorithm will be presented as well.,https://api.openreview.net/pdf/e6d7367a2026dfb54ab09cf5fca781960ef1e57a.pdf
MAgNet: Mesh Agnostic Neural PDE Solver,2022,ICML,"['Oussama Boussif', 'Dan Assouline', 'Loubna Benabbou', 'Yoshua Bengio']",poster,"['physical simulations', 'implicit neural representations', 'graph neural networks', 'learned simulators']","The computational complexity of classical numerical methods for solving Partial Differential Equations (PDE) scales significantly as the resolution increases. When it comes to climate predictions, fine spatio-temporal resolutions are required to resolve all turbulent scales in the fluid simulations. This makes the task of accurately resolving these scales computationally out of reach even with modern supercomputers. As a result, climate modelers solve these PDEs on grids that are too coarse (3km to 200km on each side), which hinders the accuracy and usefulness of the predictions. In this paper, we leverage the recent advances in Implicit Neural Representations (INR) to design a novel architecture that predicts the spatially continuous solution of a PDE given a spatial position query. By augmenting coordinate-based architectures with Graph Neural Networks (GNN), we enable zero-shot generalization to new non-uniform meshes and long-term predictions up to 250 frames ahead that are physically consistent. Our Mesh Agnostic Neural PDE Solver (MAgNet) is able to make accurate predictions across a variety of PDE simulation datasets and compares favorably with existing baselines. Moreover, our model generalizes well to different meshes and resolutions up to four times those trained on.",https://api.openreview.net/pdf/c9765f758cf28a7020b0ad60199b08e6383a1f0a.pdf
Multiscale Neural Operator: Learning Fast and Grid-independent PDE Solvers,2022,ICML,"['Björn Lütjens', 'Catherine H. Crawford', 'Campbell D Watson', 'Christopher Hill', 'Dava Newman']",poster,"['physics-informed machine learning', 'pinns', 'scientific machine learning', 'neural ODEs', 'neural operators', 'machine learning', 'neural networks', 'Matryoshka', 'multiphysics', 'multiscale', 'parametrizations', 'closure', 'subgrid', 'superstructures', 'partial differential equations', 'PDEs', 'differential equations', 'numerical solvers', 'physics', 'hpc', 'surrogate', 'reduced order modeling', 'model reduction', 'uncertainty quantification', 'climate', 'fluid dynamics', 'physics', 'computational physics']","Numerical simulations in climate, chemistry, or astrophysics are computationally too expensive for uncertainty quantification or parameter-exploration at high-resolution. Reduced-order or surrogate models are multiple orders of magnitude faster, but traditional surrogates are inflexible or inaccurate and pure machine learning (ML)-based surrogates too data-hungry. We propose a hybrid, flexible surrogate model that exploits known physics for simulating large-scale dynamics and limits learning to the hard-to-model term, which is called parametrization or closure and captures the effect of fine- onto large-scale dynamics. Leveraging neural operators, we are the first to learn grid-independent, non-local, and flexible parametrizations. Our $\textit{multiscale neural operator}$ is motivated by a rich literature in multiscale modeling, has quasilinear runtime complexity, is more accurate or flexible than state-of-the-art parametrizations and demonstrated on the chaotic equation multiscale Lorenz96.",https://api.openreview.net/pdf/4b1396cbed6835b656cce3b923b8bac782eed5e7.pdf
"Differentiable Physics Simulations with Contacts: Do They Have Correct Gradients w.r.t. Position, Velocity and Control?",2022,ICML,"['Yaofeng Desmond Zhong', 'Jiequn Han', 'Georgia Olympia Brikis']",poster,[],"In recent years, an increasing amount of work has focused on differentiable physics simulation and has produced a set of open source projects such as Tiny Differentiable Simulator, Nimble Physics, diffTaichi, Brax, Warp, Dojo and DiffCoSim. By making physics simulations end-to-end differentiable, we can perform gradient-based optimization and learning tasks. A majority of differentiable simulators consider collisions and contacts between objects, but they use different contact models for differentiability. In this paper, we overview four kinds of differentiable contact formulations - linear complementarity problems (LCP), convex optimization models, compliant models and position-based dynamics (PBD). We analyze and compare the gradients calculated by these models and show that the gradients are not always correct. We also demonstrate their ability to learn an optimal control strategy by comparing the learned strategies with the optimal strategy in an analytical form. The codebase to reproduce the experiment results is available at https://github.com/DesmondZhong/diff_sim_grads.",https://api.openreview.net/pdf/9a44a4cd5710a149b21a1ad58a66e4d6debb33f9.pdf
Transform Once: Efficient Operator Learning in Frequency Domain,2022,ICML,"['Michael Poli', 'Stefano Massaroli', 'Federico Berto', 'Jinkyoo Park', 'Tri Dao', 'Christopher Re', 'Stefano Ermon']",poster,"['neural operators', 'frequency', 'transform', 'differential equation', 'dynamics', 'turbulence', 'fluid flows', 'PDE', 'speedup', 'high-resolution']","Spectrum analysis provides one of the most effective paradigms for information-preserving dimensionality reduction in data: often, a simple description of naturally occurring signals can be obtained via few terms of periodic basis functions. Neural operators designed for frequency domain learning are based on complex-valued transforms i.e. Fourier Transforms (FT), and layers that perform computation on the spectrum and input data separately. This design introduces considerable computational overhead: for each layer, a forward and inverse FT. Instead, this work introduces a blueprint for frequency domain learning through a single transform: transform once (T1). Our results significantly streamline the design process of neural operators, pruning redundant transforms, and leading to speedups of 3 x to 30 that increase with data resolution and model size. We perform extensive experiments on learning to solve partial differential equations, including incompressible Navier-Stokes, turbulent flows around airfoils, and high-resolution video of smoke dynamics. T1 models improve on the test performance of SOTA neural operators while requiring significantly less computation, with over $30\%$ reduction in predictive error across tasks.",https://api.openreview.net/pdf/4dde92adb5dd04f927e9e935f915f83fb18b27ec.pdf
Provable Concept Learning for Interpretable Predictions Using Variational Autoencoders,2022,ICML,"['Armeen Taeb', 'Nicolò Ruggeri', 'Carina Schnuck', 'Fanny Yang']",poster,"['Interpretable predictions', 'interpretable concepts', 'variational inference', 'variational autoencoders']","In safety-critical applications, practitioners are reluctant to trust neural networks when no interpretable explanations are available. Many attempts to provide such explanations revolve around pixel-level attributions or use previously known concepts. In this paper we aim to provide explanations by provably identifying \emph{high-level, previously unknown concepts}. To this end, we propose a probabilistic modeling framework to derive (C)oncept (L)earning and (P)rediction (CLAP) - a VAE-based classifier that uses visually interpretable concepts as linear predictors. Assuming that the data generating mechanism involves interpretable concepts, we prove that our method is able to identify them while attaining optimal classification accuracy. We use synthetic experiments for validation, and also show that on the ChestXRay dataset, CLAP effectively discovers interpretable factors for classifying diseases. ",https://api.openreview.net/pdf/fd97dcfcf99783fc1723a83fc695a3826f9df7f6.pdf
Towards Learning Self-Organized Criticality of Rydberg Atoms using Graph Neural Networks,2022,ICML,"['Simon Ohler', 'Daniel Steven Brady', 'Winfried Lötzsch', 'Michael Fleischhauer', 'Johannes Otterbach']",poster,"['GNN', 'Graph Neural Network', 'Atom', 'Rydberg', 'Physics', 'SOC', 'Self-Organized Criticality']","Self-Organized Criticality (SOC) is a ubiquitous dynamical phenomenon believed to be responsible for the emergence of universal scale-invariant behavior in many, seemingly unrelated systems, such as forest fires, virus spreading or atomic excitation dynamics. SOC describes the buildup of large-scale and long-range spatio-temporal correlations as a result of only local interactions and dissipation. The simulation of SOC dynamics is typically based on Monte-Carlo (MC) methods, which are however numerically expensive and do not scale beyond certain system sizes. We investigate the use of Graph Neural Networks (GNNs) as an effective surrogate model to learn the dynamics operator for a paradigmatic SOC system, inspired by an experimentally accessible physics example: driven Rydberg atoms. To this end, we generalize existing GNN simulation approaches to predict dynamics for the internal state of the node. We show that we can accurately reproduce the MC dynamics as well as generalize along the two important axes of particle number and particle density. This paves the way to model much larger systems beyond the limits of traditional MC methods. While the exact system is inspired by the dynamics of Rydberg atoms, the approach is quite general and can readily be applied to other systems.",https://api.openreview.net/pdf/a0b56365f6890cb03bb5bc5092707d24956e2f96.pdf
Learning the Solution Operator of Boundary Value Problems using Graph Neural Networks,2022,ICML,"['Winfried Lötzsch', 'Simon Ohler', 'Johannes Otterbach']",poster,"['GNN', 'physics simlations', 'generalization', 'PDE', 'boundary value problems']","As an alternative to classical numerical solvers for partial differential equations (PDEs) subject to boundary value constraints, there has been a surge of interest in investigating neural networks that can solve such problems efficiently. In this work, we design a general solution operator for two different time-independent PDEs using graph neural networks (GNNs) and spectral graph convolutions. We train the networks on simulated data from a finite elements solver on a variety of shapes and inhomogeneities. In contrast to previous works, we focus on the ability of the trained operator to generalize to previously unseen scenarios. Specifically, we test generalization to meshes with different shapes and superposition of solutions for a different number of inhomogeneities. We find that training on a diverse dataset with lots of variation in the finite element meshes is a key ingredient for achieving good generalization results in all cases. With this, we believe that GNNs can be used to learn solution operators that generalize over a range of properties and produce solutions much faster than a generic solver. Our dataset, which we make publicly available, can be used and extended to verify the robustness of these models under varying conditions.",https://api.openreview.net/pdf/1b1cc27b643c9359c29a3ea246d7461d944a752f.pdf
Pre-training Transformers for Molecular Property Prediction Using Reaction Prediction,2022,ICML,"['Johan Broberg', 'Maria Margareta Bånkestad', 'Erik Ylipää Hellqvist']",poster,"['molecular property prediction', 'pre-training', 'transfer learning', 'transformers', 'cheminformatics']","Molecular property prediction is essential in chemistry, especially for drug discovery applications. However, available molecular property data is often limited, encouraging the transfer of information from related data. Transfer learning has had a tremendous impact in fields like Computer Vision and Natural Language Processing signalling for its potential in molecular property prediction. We present a pre-training procedure for molecular representation learning using reaction data and use it to pre-train a SMILES Transformer. We fine-tune and evaluate the pre-trained model on 12 molecular property prediction tasks from MoleculeNet within physical chemistry, biophysics, and physiology and show a statistically significant positive effect on 5 of the 12 tasks compared to a non-pre-trained baseline model.",https://api.openreview.net/pdf/84ae4d0c9ffc467bd823d056de7d22ecc4352d74.pdf
Featurizations Matter: A Multiview Contrastive Learning Approach to Molecular Pretraining,2022,ICML,"['Yanqiao Zhu', 'Dingshuo Chen', 'Yuanqi Du', 'Yingze Wang', 'Qiang Liu', 'Shu Wu']",poster,[],"Molecular representation learning, which aims to automate feature learning for molecules, is a vital task in computational chemistry and drug discovery. Despite rapid advances in molecular pretraining models with various types of featurizations, from SMILES strings, 2D graphs to 3D geometry, there is a paucity of research on how to utilize different molecular featurization techniques to obtain better representations. To bridge that gap, we present a novel multiview contrastive learning approach dubbed MEMO in this paper.
Our pretraining framework, in particular, is capable of learning from four basic but nontrivial featurizations of molecules and adaptively learning to optimize the combinations of featurization techniques for different downstream tasks. Extensive experiments on a broad range of molecular property prediction benchmarks show that our MEMO outperforms state-of-the-art baselines and also yields reasonable an interpretation of molecular featurizations weights in accordance with chemical knowledge.",https://api.openreview.net/pdf/34b5b56d1a12e0014725942393eb80c896dd68ba.pdf
Sample Efficiency Matters: A Benchmark for Practical Molecular Optimization,2022,ICML,"['Wenhao Gao', 'Tianfan Fu', 'Jimeng Sun', 'Connor W. Coley']",poster,"['Molecular design', 'Optimization', 'Sample efficiency']","Molecular optimization is a fundamental goal in the chemical sciences and is of central interest to drug and material design. In recent years, significant progress has been made in solving challenging problems across various aspects of computational molecular optimizations, emphasizing high validity, diversity, and, most recently, synthesizability. Despite this progress, many papers report results on trivial or self-designed tasks, bringing additional challenges to directly assessing the performance of new methods. Moreover, the sample efficiency of the optimization---the number of molecules evaluated by the oracle---is rarely discussed, despite being an essential consideration for realistic discovery applications. To fill this gap, we have created an open-source benchmark for practical molecular optimization, PMO, to facilitate the transparent and reproducible evaluation of algorithmic advances in molecular optimization. This paper thoroughly investigates the performance of 25 molecular design algorithms on 23 tasks with a particular focus on sample efficiency. Our results show that most ""state-of-the-art"" methods fail to outperform their predecessors under a limited oracle budget allowing 10K queries and that no existing algorithm can efficiently solve certain molecular optimization problems in this setting. We analyze the influence of the optimization algorithm choices, molecular assembly strategies, and oracle landscapes on the optimization performance to inform future algorithm development and benchmarking. PMO provides a standardized experimental setup to comprehensively evaluate and compare new molecule optimization methods with existing ones. All code can be found at https://github.com/wenhao-gao/mol_opt.",https://api.openreview.net/pdf/5058f46a4f753ee5c89ac61c627b80ab467d241b.pdf
The Bearable Lightness of Big Data: Towards Massive Public Datasets in Scientific Machine Learning,2022,ICML,"['Wai Tong Chung', 'Ki Sung Jung', 'Jacqueline Chen', 'Matthias Ihme']",poster,"['Big data', 'Deep learning', 'Lossy compression', 'High performance computing', 'Turbulent reacting flows']","In general, large datasets enable deep learning models to perform with good accuracy and generalizability. However, massive high-fidelity simulation datasets (from molecular chemistry, astrophysics, computational fluid dynamics (CFD), etc.) can be challenging to curate due to dimensionality and storage constraints. Lossy compression algorithms can help mitigate limitations from storage, as long as the overall data fidelity is preserved. To illustrate this point, we demonstrate that deep learning models, trained and tested on data from a petascale CFD simulation, are robust to errors introduced during lossy compression in a semantic segmentation problem. Our results demonstrate that lossy compression algorithms offer a realistic pathway for exposing high-fidelity scientific data to open-source data repositories for building community datasets. In this paper, we outline, construct, and evaluate the requirements for establishing a big data framework, demonstrated at https://blastnet.github.io/, for scientific machine learning.",https://api.openreview.net/pdf/213150d5203e0063294ff8e99703dff91659e424.pdf
DEQGAN: Learning the Loss Function for PINNs with Generative Adversarial Networks,2022,ICML,"['Blake Bullwinkel', 'Dylan Randle', 'Pavlos Protopapas', 'David Sondak']",poster,"['differential equations', 'generative adversarial networks', 'GANs', 'physics-informed neural networks', 'deep learning']","Solutions to differential equations are of significant scientific and engineering relevance. Physics-Informed Neural Networks (PINNs) have emerged as a promising method for solving differential equations, but they lack a theoretical justification for the use of any particular loss function. This work presents Differential Equation GAN (DEQGAN), a novel method for solving differential equations using generative adversarial networks to ""learn the loss function"" for optimizing the neural network. Presenting results on a suite of twelve ordinary and partial differential equations, including the nonlinear Burgers', Allen-Cahn, Hamilton, and modified Einstein's gravity equations, we show that DEQGAN can obtain multiple orders of magnitude lower mean squared errors than PINNs that use $L_2$, $L_1$, and Huber loss functions. We also show that DEQGAN achieves solution accuracies that are competitive with popular numerical methods. Finally, we present two methods to improve the robustness of DEQGAN to different hyperparameter settings.",https://api.openreview.net/pdf/b3de9caf10b853a2960729a5ed8f742394900e20.pdf
Target-aware Molecular Graph Generation,2022,ICML,"['Cheng Tan', 'Zhangyang Gao', 'Stan Z. Li']",poster,"['drug discovery', 'molecular generation']","Generating molecules with desired biological activities has attracted growing attention in drug discovery. Previous molecular generation models are designed as chemocentric methods that hardly consider the drug-target interaction, limiting their practical applications. In this paper, we aim to generate molecular drugs in a target-aware manner that bridges biological activity and molecular design. To solve this problem, we compile a benchmark dataset from several publicly available datasets and build baselines in a unified framework. Building on the recent advantages of flow-based molecular generation models, we propose SiamFlow, which forces the flow to fit the distribution of target sequence embeddings in latent space. Specifically, we employ an alignment loss and a uniform loss to bring target sequence embeddings and drug graph embeddings into agreements while avoiding collapse. Furthermore, we formulate the alignment into a one-to-many problem by learning spaces of target sequence embeddings. Experiments quantitatively show that our proposed method learns meaningful representations in the latent space toward the target-aware molecular graph generation and provides an alternative approach to bridge biology and chemistry in drug discovery.",https://api.openreview.net/pdf/567131bab8db193eedbb8d443fb8a8db43ab930b.pdf
Pre-training Graph Neural Networks for Molecular Representations: Retrospect and Prospect,2022,ICML,"['Jun Xia', 'Yanqiao Zhu', 'Yuanqi Du', 'Stan Z. Li']",poster,"['molecular representation learning', 'molecular property prediction', 'pre-training on graphs']"," Recent years have witnessed remarkable advances in molecular representation learning using Graph Neural Networks (GNNs). To fully exploit the unlabeled molecular data, researchers first pre-train GNNs on large-scale molecular databases and then fine-tune these pre-trained Graph Models (GMs) in downstream tasks. The knowledge implicitly encoded in model parameters can benefit various downstream tasks and help to alleviate several fundamental challenges of molecular representation learning. In this paper, we provide a comprehensive survey of pre-trained GMs for molecular representations. We first briefly present the limitations of molecular graph representation learning and thus introduce the motivation for molecular graph pre-training. Next, we systematically categorize existing pre-trained GMs based on a taxonomy from four different perspectives including model architectures, pre-training strategies, tuning strategies, and applications. Finally, we outline several promising research directions that can serve as a guideline for future studies.",https://api.openreview.net/pdf/bf96669f3ce8f21400f30916f404b187c4244feb.pdf
Mesh-Independent Operator Learning for Partial Differential Equations,2022,ICML,['Seungjun Lee'],poster,"['partial differential equations', 'operator learning', 'permutation-symmetry', 'set representations']","Operator learning, learning the mapping between function spaces, has been attracted as an alternative
approach to traditional numerical methods to solve partial differential equations. In this paper, we propose to represent the discretized system as a set-valued data without a prior structure and construct the permutation-symmetric model, called mesh-independent neural operator (MINO), to provide proper treatments of input functions and query coordinates of the solution function. Our models pre-trained with a benchmark dataset of operator learning are evaluated by downstream tasks to demonstrate the generalization abilities to varying discretization formats of the system, which are natural characteristics of the continuous solution of the PDEs.",https://api.openreview.net/pdf/653db2c319d5eb0d602cc17ea7707635af992055.pdf
Removing parasitic elements from Quantum Optical Coherence Tomography data with Convolutional Neural Networks,2022,ICML,"['Krzysztof Maliszewski', 'Sylwia M. Kolenderska', 'Varvara Vetrova']",poster,"['quantum', 'OCT', 'artefacts', 'machine learning', 'CNN', 'VGG']","Quantum Optical Coherence Tomography (Q-OCT) is a non-contact and non-invasive light-based imaging method which is gaining attention due to its increased image resolution and quality. The biggest, yet unresolved, disadvantage of Q-OCT is artefacts, additional elements cluttering the images, and leading to a loss of the structural information in the obtained images. In our work, Convolutional Neural Network (CNN) is applied to remove artefacts from Quantum Optical Coherence Tomography (Q-OCT) images. In our approach, we train our model with computer-generated data instead of experimental images. The preliminary results show that such an approach is successful in retrieving artefact-free structural information, even for multilayer objects, for which this information is lost due to the number of induced artefacts. The limitations and challenges associated with our approach are identified and discussed.  ",https://api.openreview.net/pdf/dbc6cb0da301474d158bf5d7bcac7ac5ba58c317.pdf
Multiresolution Equivariant Graph Variational Autoencoder,2022,ICML,"['Truong Son Hy', 'Risi Kondor']",poster,"['Graph neural networks', 'graph variational autoencoders', 'hierarchical generative models', 'molecule generation', 'supervised and unsupervised molecular representation learning']","In this paper, we propose Multiresolution Equivariant Graph Variational Autoencoders (MGVAE), the first hierarchical generative model to learn and generate graphs in a multiresolution and equivariant manner. At each resolution level, MGVAE employs higher order message passing to encode the graph while learning to partition it into mutually exclusive clusters and coarsening into a lower resolution that eventually creates a hierarchy of latent distributions. MGVAE then constructs a hierarchical generative model to variationally decode into a hierarchy of coarsened graphs. Importantly, our proposed framework is end-to-end permutation equivariant with respect to node ordering. MGVAE achieves competitive results with several generative tasks including general graph generation, molecular generation, unsupervised molecular representation learning to predict molecular properties, link prediction on citation graphs, and graph-based image generation.",https://api.openreview.net/pdf/38ef14fba92f5536e0cca925f57e59a7797d1d2b.pdf
Multiresolution Matrix Factorization and Wavelet Networks on Graphs,2022,ICML,"['Truong Son Hy', 'Risi Kondor']",poster,"['Multiresolution matrix factorization', 'wavelet theory', 'graph neural networks', 'Stiefel manifold optimization', 'reinforcement learning', 'molecular representation learning']","Multiresolution Matrix Factorization (MMF) is unusual amongst fast matrix factorization algorithms in that it does not make a low rank assumption. This makes MMF especially well suited to modeling certain types of graphs with complex multiscale or hierarchical strucutre. While MMF promises to yields a useful wavelet basis, finding the factorization itself is hard, and existing greedy methods tend to be brittle. In this paper, we propose a ``learnable'' version of MMF that carfully optimizes the factorization with a combination of reinforcement learning and Stiefel manifold optimization through backpropagating errors. We show that the resulting wavelet basis far outperforms prior MMF algorithms and provides the first version of this type of factorization that can be robustly deployed on standard learning tasks. Furthermore, we construct the wavelet neural networks (WNNs) learning graphs on the spectral domain with the wavelet basis produced by our MMF learning algorithm. Our wavelet networks are competitive against other state-of-the-art methods in molecular graphs classification and node classification on citation graphs.",https://api.openreview.net/pdf/96d9f0d89170b6c4dc3d4506483b57329c6164b0.pdf
Quantum Neural Architecture Search with Quantum Circuits Metric and Bayesian Optimization,2022,ICML,"['Trong Duong', 'Sang T. Truong', 'Minh Pham', 'Bao Bach', 'June-Koo Rhee']",poster,"['quantum neural network', 'quantum neural architecture search', 'Bayesian optimization']","Quantum neural networks are promising for a wide range of applications in the Noisy Intermediate-Scale Quantum era. As such, there is an increasing demand for automatic quantum neural architecture search. We tackle this challenge by designing a quantum circuits metric for Bayesian optimization with Gaussian process. To this goal, we develop quantum gates distance that characterizes the gates' action over every quantum state and provide a theoretical perspective on its geometric properties. Our approach significantly outperforms the benchmark on three empirical quantum machine learning problems including training a quantum generative adversarial network, solving combinatorial optimization in the MaxCut problem, and simulating quantum Fourier transform. Our method can be extended to characterize behaviors of various quantum machine learning models.",https://api.openreview.net/pdf/db18a5cbd1e78bad1dd28950abf70ed03aee86bb.pdf
Variational Inference for Soil Biogeochemical Models,2022,ICML,"['Debora Sujono', 'Hua Wally Xie', 'Steven Allison', 'Erik B. Sudderth']",poster,[],"Soil biogeochemical models (SBMs) are an important tool used by Earth scientists to quantify the impact of rising global surface temperatures. SBMs represent the soil carbon and microbial dynamics across time as differential equations, and inference on model parameters is conducted to project changes in parameter values under warming climate conditions. Traditionally, the field has relied on MCMC algorithms for posterior inference, often implemented via probabilistic programming languages like Stan. However, computational cost makes it difficult to scale MCMC methods to more complex SBM models and large-scale datasets. In this paper, we develop variational inference methods for time-discretized SBMs as an alternative to MCMC. We propose an efficient family of variational approximations based on Gauss-Markov distributions that leverages the temporal structure of sequential models, scaling linearly in both time and space with respect to the sequence length. We show in experiments with simulated data and real CO$_2$ response ratios that our approach converges faster, and recovers posterior that more accurately captures uncertainty than previous variational methods. Our black-box inference approach is designed to integrate with probabilistic programming languages to enable future scientific applications.",https://api.openreview.net/pdf/4da7b898af12e3a43ada53a28e4d289e8bc1b740.pdf
Centralized vs Individual Models for Decision Making in Interconnected Infrastructure,2022,ICML,"['Stephanie Allen', 'John P Dickerson', 'Steven A. Gabriel']",poster,"['markov Decision processes', 'reinforcement learning', 'interdependent infrastructure']","The 2013 National Infrastructure Protection Plan outlines the need for interconnected infrastructure systems to coordinate more and recognize their interdependencies.  We model the two extremes of this coordination spectrum using two different multi-agent models: (a) a model called the centralized model in which the agents are fully centralized and act as one unit in making decisions and (b) a model called the individual model in which the agents act completely separately and have either a pessimistic or optimistic assumption regarding the damages of the other infrastructure systems controlled by the other agents.  We then use the individual model to establish a point along the coordination spectrum by providing the individual agents with delayed information regarding the other player(s). To test this framework, we use a small but illustrative model from a 2020 paper in which there is a power and a water network, and we assume that there are operators for both networks that would like to maximize flow according to a specific metric.  Our results comparing partially repaired networks using the two models find that (i) the centralized model acts as an upper bound upon the individual model in terms of our flow metric and (ii) the delayed information individual model leads to less variability in results compared to the other individual model assumptions which points to the value of at least delayed coordination in decision making.",https://api.openreview.net/pdf/f5cd714e90a755e8032eae3d3195b07323abda78.pdf
An Optical Controlling Environment and Reinforcement Learning Benchmarks,2022,ICML,"['ABULIKEMU ABUDUWEILI', 'Changliu Liu']",poster,"['Reinforcement Learning', 'Optics', 'Simulation', 'Optical Control']","Deep reinforcement learning has the potential to address various scientific problems. In this paper, we implement an optics simulation environment for reinforcement learning based controllers. The environment incorporates nonconvex and nonlinear optical phenomena as well as more realistic time-dependent noise. Then we provide the benchmark results of several state-of-the-art reinforcement learning algorithms on the proposed simulation environment. In the end, we discuss the difficulty of controlling the real-world optical environment with reinforcement learning algorithms.  ",https://api.openreview.net/pdf/aca0a83b92021715889aa1ec3b5e078f07a43b22.pdf
$O(N^2)$ Universal Antisymmetry in Fermionic Neural Networks,2022,ICML,"['Tianyu Pang', 'Shuicheng YAN', 'Min Lin']",poster,"['Universal Antisymmetry', 'Fermionic Neural Networks']","Fermionic neural network (FermiNet) is a recently proposed wavefunction Ansatz, which is used in variational Monte Carlo (VMC) methods to solve the many-electron Schr\""{o}dinger equation. FermiNet proposes permutation-equivariant architectures, on which a Slater determinant is applied to induce antisymmetry. FermiNet is proved to have universal approximation capability with a single determinant, namely, it suffices to represent any antisymmetric function given sufficient parameters. However, the asymptotic computational bottleneck comes from the Slater determinant, which scales with $O(N^3)$ for $N$ electrons. In this paper, we substitute the Slater determinant with a pairwise antisymmetry construction, which is easy to implement and can reduce the computational cost to $O(N^2)$. We formally prove that the pairwise construction built upon permutation-equivariant architectures can universally represent any antisymmetric function. Besides, this universality can be achieved via continuous approximators when we aim to represent ground-state wavefunctions.",https://api.openreview.net/pdf/0c88391e50f009bef5510e47c71579cc97695b6a.pdf
GAUCHE: A Library for Gaussian Processes in Chemistry,2022,ICML,"['Ryan-Rhys Griffiths', 'Leo Klarner', 'Henry Moss', 'Aditya Ravuri', 'Sang T. Truong', 'Bojana Rankovic', 'Yuanqi Du', 'Arian Rokkum Jamasb', 'Julius Schwartz', 'Austin Tripp', 'Gregory Kell', 'Anthony Bourached', 'Alex Chan', 'Jacob Moss', 'Chengzhi Guo', 'Alpha Lee', 'Philippe Schwaller', 'Jian Tang']",poster,"['Chemistry', 'Molecules', 'Gaussian processes', 'Bayesian optimization']","We introduce GAUCHE, a library for GAUssian processes in CHEmistry. Gaussian processes have long been a cornerstone of probabilistic machine learning, affording particular advantages for uncertainty quantification and Bayesian optimisation. Extending Gaussian processes to chemical representations however is nontrivial, necessitating kernels defined over structured inputs such as graphs, strings and bit vectors. By defining such kernels in GAUCHE, we seek to open the door to powerful tools for uncertainty quantification and Bayesian optimisation in chemistry. Motivated by scenarios frequently encountered in experimental chemistry, we showcase applications for GAUCHE in molecular discovery and chemical reaction optimisation. The codebase is made available at https://github.com/leojklarner/gauche",https://api.openreview.net/pdf/f4f82c5c40a69c8bcafeb5cab1c949e53e95760c.pdf
Bias in the Benchmark: Systematic experimental errors in bioactivity databases confound multi-task and meta-learning algorithms,2022,ICML,"['Leo Klarner', 'Michael Reutlinger', 'Torsten Schindler', 'Charlotte Deane', 'Garrett Morris']",poster,[],"There is considerable interest in employing deep learning algorithms to predict pharmaceutically relevant properties of small molecules. To overcome the issues inherent in this low-data regime, researchers are increasingly exploring multi-task and meta-learning algorithms that leverage sets of related biochemical and toxicological assays to learn robust and generalisable representations.
However, we show that the data from which commonly used multi-task benchmarks are derived often exhibits systematic experimental errors that lead to confounding statistical dependencies across tasks. Representation learning models that aim to acquire an inductive bias in this domain risk compounding these biases and may overfit to patterns that are counterproductive to many downstream applications of interest. We investigate to what extent these issues are reflected in the molecular embeddings learned by multi-task graph neural networks and discuss methods to address this pathology.",https://api.openreview.net/pdf/0b5556e97220011e4ae29b5de1308b76c0689c85.pdf
Deep Learning and Symbolic Regression for Discovering Parametric Equations,2022,ICML,"['Samuel Kim', 'Michael Zhang', 'Peter Y Lu', 'Marin Soljacic']",poster,"['Deep learning', 'neural network', 'parametric', 'PDE', 'symbolic regression', 'physics']","Symbolic regression is a machine learning technique that can learn the governing formulas from data and thus has the potential to transform scientific discovery. However, symbolic regression is still limited in the complexity of the systems that it can analyze. Deep learning on the other hand has transformed machine learning in its ability to analyze extremely complex and high-dimensional datasets. Here we develop a method that uses neural networks to extend symbolic regression to parametric systems where some coefficient may vary as a function of time but the underlying governing equation remains constant. We demonstrate our method on various analytic expressions and PDEs with varying coefficients and show that it extrapolate well outside of the training domain. The neural network-based architecture can also integrate with other deep learning architectures so that it can analyze high-dimensional data while being trained end-to-end in a single step. To this end we integrate our architecture with convolutional neural networks and train the system end-to-end to discover various physical quantities from 1D images of spring systems where the spring constant may vary.",https://api.openreview.net/pdf/53cbfbf16b22a293458613dc4cfb89e87dccd14f.pdf
Graph Self-Supervised Learning for Optoelectronic Properties of Organic Semiconductors,2022,ICML,"['ZAIXI ZHANG', 'Qi Liu', 'Shengyu Zhang', 'Chang-Yu Hsieh', 'Liang Shi', 'Chee-Kong Lee']",poster,"['Self-Supervised Learning', 'Graph Neural Networks', 'Organic semiconductors']","The search for new high-performance organic semiconducting molecules is challenging due to the vastness of the chemical space, machine learning methods, particularly deep learning models like graph neural networks (GNNs), have shown promising potential to address such challenges. However, practical applications of GNNs for chemistry are often limited by the availability of labelled data. Meanwhile, unlabelled molecular data is abundant and could potentially be utilized to alleviate the scarcity issue of labelled data. Here, we advocate the use of self-supervised learning to improve the performance of GNNs by pre-training them with unlabeled molecular data. We investigate regression problems involving ground and excited state properties, both relevant for optoelectronic properties of organic semiconductors. Additionally, we extend the self-supervised learning strategy to molecules in non-equilibrium configurations which are important for studying
the effects of disorder. In all cases, we obtain considerable performance improvement over results without pre-training, in particular when labelled training data is limited, and such improvement is attributed to the capability of self-supervised learning in identifying structural similarity among unlabeled molecules.
",https://api.openreview.net/pdf/5ae7c3f47cf2dbce76c969f249f91b11f05b4b8e.pdf
Multimodal Masked Autoencoders Learn Transferable Representations,2022,ICML,"['Xinyang Geng', 'Hao Liu', 'Lisa Lee', 'Dale Schuurmans', 'Sergey Levine', 'Pieter Abbeel']",oral,"['Self-supervised pre-training', 'multi-modal', 'representation learning']","Building scalable models to learn from diverse, multimodal data remains an open challenge. For vision-language data, the dominant approaches are based on contrastive learning objectives that train a separate encoder for each modality. While effective, contrastive learning approaches introduce sampling bias depending on the data augmentations used, which can degrade performance on downstream tasks. Moreover, these methods are limited to paired image-text data, and cannot leverage widely-available unpaired data. In this paper, we investigate whether a large multimodal model trained purely via masked token prediction, without using modality-specific encoders or contrastive learning, can learn transferable representations for downstream tasks. We propose a simple and scalable network architecture, the Multimodal Masked Autoencoder (M3AE), which learns a unified encoder for both vision and language data via masked token prediction. We provide an empirical study of M3AE trained on a large-scale image-text dataset, and find that M3AE is able to learn generalizable representations that transfer well to downstream tasks. We demonstrate the scalability of M3AE with larger model size and training time, and its flexibility to train on both paired image-text data as well as unpaired data.",https://api.openreview.net/pdf/12751398b54b104064d6ea866ea0d22b3873e9ca.pdf
Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative Prior,2022,ICML,"['Ravid Shwartz-Ziv', 'Micah Goldblum', 'Hossein Souri', 'Sanyam Kapoor', 'Chen Zhu', 'Yann LeCun', 'Andrew Gordon Wilson']",oral,"['Bayesian Deep Learning', 'Transfer Learning', 'Self Supervised Learning']","Deep learning is increasingly moving towards a transfer learning paradigm whereby large ``foundation models'' are fine-tuned on downstream tasks, starting from an initialization learned on the source task. But an initialization contains relatively little information about the source task.  %, and would not affect the final solution at all if we do a good job of optimization. 
Instead, we show that we can learn highly informative posteriors from the source task, which serves as the basis for priors that modify the whole loss surface on the downstream task. This simple modular approach enables significant performance gains and more data-efficient learning on various downstream classification and segmentation tasks, serving as a drop-in replacement for standard pre-training strategies.",https://api.openreview.net/pdf/7a1ecf1984f441128b055d16d7bfb418bc9fa036.pdf
Plex: Towards Reliability using Pretrained Large Model Extensions,2022,ICML,"['Dustin Tran', 'Jeremiah Zhe Liu', 'Michael W Dusenberry', 'Du Phan', 'Mark Collier', 'Jie Ren', 'Kehang Han', 'Zi Wang', 'Zelda E Mariet', 'Huiyi Hu', 'Neil Band', 'Tim G. J. Rudner', 'Karan Singhal', 'Zachary Nado', 'Joost van Amersfoort', 'Andreas Kirsch', 'Rodolphe Jenatton', 'Nithum Thain', 'Honglin Yuan', 'E. Kelly Buchanan', 'Kevin Patrick Murphy', 'D. Sculley', 'Yarin Gal', 'Zoubin Ghahramani', 'Jasper Snoek', 'Balaji Lakshminarayanan']",oral,"['reliability', 'large models', 'uncertainty', 'robustness', 'adaptation']","A recent trend in artificial intelligence is the use of pretrained models for language and vision tasks, which have achieved extraordinary performance but also puzzling failures. Probing these models' abilities in diverse ways is therefore critical to the field. In this paper, we explore the reliability of models, where we define a reliable model as one that not only achieves strong predictive performance but also performs well consistently over many decision-making tasks involving uncertainty (e.g., selective prediction, open set recognition), robust generalization (e.g., accuracy and proper scoring rules such as log-likelihood on in- and out-of-distribution datasets), and adaptation (e.g., active learning, few-shot uncertainty). We devise 10 types of tasks over 38 datasets in order to evaluate different aspects of reliability on both vision and language domains. To improve reliability, we developed ViT-Plex and T5-Plex, pretrained large model extensions (plex) for vision and language modalities, respectively. Plex greatly improves the state-of-the-art across reliability tasks, and simplifies the traditional protocol as it does not require designing scores or tuning the model for each individual task. We demonstrate scaling effects over model sizes up to 1B parameters and pretraining dataset sizes up to 4B examples. We also demonstrate Plex's capabilities on challenging tasks including zero-shot open set recognition, active learning, and uncertainty in conversational language understanding.",https://api.openreview.net/pdf/99b15deb9a66c6af60390b9fe676c27e5f368160.pdf
OOD-CV: A Benchmark for Robustness to Individual Nuisances in Real-World Out-of-Distribution Shifts,2022,ICML,"['Bingchen Zhao', 'Shaozuo Yu', 'Wufei Ma', 'Mingxin Yu', 'Shenxiao Mei', 'Angtian Wang', 'Ju He', 'Alan Yuille', 'Adam Kortylewski']",poster,[],"Enhancing the robustness of vision algorithms in real-world scenarios is challenging. One reason is that existing robustness benchmarks are limited, as they either rely on synthetic data or ignore the effects of individual nuisance factors. We introduce ROBIN, a benchmark dataset that includes out-of-distribution examples of 10 object categories in terms of pose, shape, texture, context and the weather conditions, and enables benchmarking models for image classification, object detection, and 3D pose estimation. Our experiments using popular baseline methods reveal that: 1) Some nuisance factors have a much stronger negative effect on the performance compared to others, also depending on the vision task. 2) Current approaches to enhance robustness have only marginal effects, and can even reduce robustness. 3) We do not observe significant differences between convolutional and transformer architectures. We believe our dataset provides a rich testbed to study robustness and will help push forward research in this area.",https://api.openreview.net/pdf/8d4f2c9577af2b881e37d332f4cb6dd97e7c70ad.pdf
Wild-Time: A Benchmark of in-the-Wild Distribution Shift over Time,2022,ICML,"['Huaxiu Yao', 'Caroline Choi', 'Yoonho Lee', 'Pang Wei Koh', 'Chelsea Finn']",poster,[],"Distribution shifts occur when the test distribution differs from the training distribution, and can considerably degrade performance of machine learning models deployed in the real world. While recent works have studied robustness to distribution shifts, distribution shifts arising from the passage of time have the additional structure of timestamp metadata. Real-world examples of such shifts are underexplored, and it is unclear whether existing models can leverage trends in past distribution shifts to reliably extrapolate into the future. To address this gap, we curate Wild-Time, a benchmark of 7 datasets that reflect temporal distribution shifts arising in a variety of real-world applications. On these datasets, we systematically benchmark 9 approaches with various inductive biases. Our experiments demonstrate that existing methods are limited in tackling temporal distribution shift: across all settings, we observe an average performance drop of 21% from in-distribution to out-of-distribution data.",https://api.openreview.net/pdf/26431d69ad58b0be7588c06236570f52edefd940.pdf
"Growing ObjectNet: Adding speech, VQA, occlusion, and measuring dataset difficulty",2022,ICML,"['David Mayo', 'David Lu', 'Chris Zhang', 'Jesse Cummings', 'Xinyu Lin', 'Boris Katz', 'James R. Glass', 'Andrei Barbu']",poster,[],"Building more difficult datasets is largely an ad-hoc enterprise, generally relying on scale from the web or focusing on particular domains thought to be challenging. ObjectNet is an attempt to create a more difficult dataset, one that eliminates biases that may artificially inflate machine performance, in a systematic way. ObjectNet images are meant to decorrelate objects from their backgrounds, have randomized object orientations, and randomized viewpoints. ObjectNet appears to be much more difficult for machines. Spoken ObjectNet is a retrieval benchmark constructed from spoken descriptions of ObjectNet images. These descriptions are being used to create a captioning and VQA benchmark. In each case large performance drops were seen. The next variant of ObjectNet will focus on real-world occlusions since it is suspected that models are brittle when shown partially-occluded objects. Using large-scale psychophysics on ObjectNet we have constructed a new objective difficulty benchmark applicable to any dataset: the minimum presentation time for an image before the object contained within it can be reliably recognized by humans. This difficulty metric is well predicted by quantities computable from the activations of models, although not necessarily their ultimate performance. We hope that this suite of benchmarks will enable more robust models, prove better images for neuroscientific and behavioral experiments, and contribute to a systematic understanding of the dataset difficulty and progress in computer vision.",https://api.openreview.net/pdf/74271083ece3be2f48ae98c25ad273684006978c.pdf
Classifiers Should Do Well Even on Their Worst Classes,2022,ICML,"['Julian Bitterwolf', 'Alexander Meinke', 'Valentyn Boreiko', 'Matthias Hein']",poster,[],"The performance of a vision classifier on a given test set is usually measured by its accuracy. For reliable machine learning systems, however, it is important to avoid the existence of areas of the input space where they fail severely. To reflect this, we argue, that a single number does not provide a complete enough picture even for a fixed test set, as there might be particular classes or subtasks where a model that is generally accurate performs unexpectedly poorly. Without using new data, we motivate and establish a wide selection of interesting worst-case performance metrics which can be evaluated besides accuracy on a given test set. Some of these metrics can be extended when a grouping of the original classes into superclasses is available, indicating if the model is exceptionally bad at handling inputs from one superclass.",https://api.openreview.net/pdf/0628b94f7f7db235a19799743e1d6de2d8348414.pdf
Lost in Translation: Modern Image Classifiers still degrade even under simple Translations,2022,ICML,"['Leander Kurscheidt', 'Matthias Hein']",poster,[],"Modern image classifiers are used potentially in safety-critical applications and thus should not be vulnerable to natural transformations of the image as it can happen due to variations in the image acquisition.
While it is known that image classifiers can degrade significantly in performance with respect to translations and rotations, the corresponding works did not ensure that the object of interest is fully contained in the image and also introduce boundary artefacts so that the input is not a natural image. In this paper we leverage pixelwise segmentations of the ImageNet-S dataset in order to search for the translation and rotation which ensures that the object is i) fully contained in the image (potentially together with a zoom) and ii) the image is natural (no padding with black pixels) such that the resulting natural image is misclassified. We observe a consistent drop in accuracy over a large set of image classifiers showing that natural adversarial changes are an important threat model which deserves more attention. ",https://api.openreview.net/pdf/6a0469f944bbaa0abbf08595e8b179f237f10dc1.pdf
Towards Systematic Robustness for Scalable Visual Recognition,2022,ICML,"['Mohamed Omran', 'Bernt Schiele']",poster,[],"There is widespread interest in developing robust classification models, that can handle challenging object, scene, or image properties. While work in this area targets diverse kinds of robust behaviour, we argue in this work in favour requirement that should apply more generally: For robust behaviour to be scalable, it should transfer flexibly across familiar object classes, and not be separately learned for every class of interest. To this end, we propose the systematic robustness setting, in which certain combinations of classes and attributes are systematically excluded during training. Unlike prior work which studies systematic generalisation in DNNs or their susceptibility to spurious correlations, we use synthetic operations and data sampling to scale such experiments up to large-scale naturalistic datasets. This allows for a compromise between ecological validity of the task and strict experimental controls. We analyse a variety of models and learning objectives, and find that robustness to different shifts such as image corruptions, image rotations, and abstract object depictions are perhaps harder to deal with than previous results would suggest. This extended abstract describes the general experimental setting, our specific instantiations, and a metric to measure systematic robustness.",https://api.openreview.net/pdf/fea96ed8aac8dc5cd6650449b97d3b35f90c312f.pdf
Evaluating Model Robustness to Patch Perturbations,2022,ICML,"['Jindong Gu', 'Volker Tresp', 'Yao Qin']",poster,"['Natural Patch Corruption', 'Adversarial Patch', 'Vision Transformer']","Recent advances in Vision Transformer (ViT) have demonstrated its impressive performance in image classification, which makes it a promising alternative to Convolutional Neural Network (CNN). Unlike CNNs, ViT represents an input image as a sequence of image patches. The patch-based input image representation makes the following question interesting: How does ViT perform when individual input image patches are perturbed with natural corruptions or adversarial perturbations, compared to CNNs? In this submission, we propose to evaluate model robustness to patch-wise perturbations. Two types of patch perturbations are considered to model robustness. One is natural corruptions, which is to test models' robustness under distributional shifts. The other is adversarial perturbations, which are created by an adversary to specifically fool a model to make a wrong prediction. The experimental results on the popular CNNs and ViTs are surprising. We find that ViTs are more robust to naturally corrupted patches than CNNs, whereas they are more vulnerable to adversarial patches. Given the architectural traits of state-of-the-art ViTs and the interesting results above, we propose to add the robustness to natural patch corruption and adversarial patch attack into the robustness benchmark.",https://api.openreview.net/pdf/d1beaaf2ecfedd7f613e348b86d58b54fda3af18.pdf
ImageNet-Cartoon and ImageNet-Drawing: two domain shift datasets for ImageNet,2022,ICML,"['Tiago Salvador', 'Adam M Oberman']",poster,"['domain shift', 'dataset', 'imagenet', 'cartoon', 'drawing']","Benchmarking the robustness to distribution shifts traditionally relies on dataset collection which is typically laborious and expensive, in particular for datasets with a large number of classes like ImageNet. An exception to this procedure is ImageNet-C (Hendrycks & Dietterich, 2019), a dataset created by applying common real-world corruptions at different levels of intensity to the (clean) ImageNet images. Inspired by this work, we introduce ImageNet-Cartoon and ImageNet-Drawing, two datasets constructed by converting ImageNet images into cartoons and colored pencil drawings, using a GAN framework (Wang & Yu, 2020) and simple image processing (Lu et al., 2012), respectively.",https://api.openreview.net/pdf/4ca1c9495b0fff9c3c8361340b5be1002550106d.pdf
CCC: Continuously Changing Corruptions,2022,ICML,"['Ori Press', 'Steffen Schneider', 'Matthias Kuemmerer', 'Matthias Bethge']",poster,"['robustness', 'test-time adaptation', 'continual adaptation', 'gradual adaptation']",Many existing datasets for robustness and adaptation evaluation are limited to static distribution shifts. We propose a well-calibrated dataset for continuously changing image corruptions on ImageNet scale. Our benchmark builds on the established common corruptions of ImageNet-C and extends them by applying two corruptions at the same time with finer-grained severities to allow for smooth transitions between corruptions. The benchmark contains random walks through different corruption types with different controlled difficulties and speeds of domain shift. Our dataset can be used to benchmark test-time and domain adaptation algorithms in challenging settings that are closer to real-world applications than typically used static adaptation benchmarks.,https://api.openreview.net/pdf/7b7ecc3a9635d1dd0f968341c6d41d81f5516680.pdf
"SI-Score: An image dataset for fine-grained analysis of robustness to object location, rotation and size",2022,ICML,"['Jessica Yung', 'Rob Romijnders', 'Alexander Kolesnikov', 'Lucas Beyer', 'Josip Djolonga', 'Neil Houlsby', 'Sylvain Gelly', 'Mario Lucic', 'Xiaohua Zhai']",poster,"['machine learning', 'robustness', 'computer vision', 'image classification', 'synthetic', 'synthetic data']","Before deploying machine learning models it is critical to assess their robustness. In the context of deep neural networks for image understanding, changing the object location, rotation and size may affect the predictions in non-trivial ways. In this work we perform a fine-grained analysis of robustness with respect to these factors of variation using SI-Score, a synthetic dataset. In particular, we investigate ResNets, Vision Transformers and CLIP, and identify interesting qualitative differences between these.",https://api.openreview.net/pdf/baa197f45651fdbeb992cbf5439c5447b981db07.pdf
ImageNet-D: A new challenging robustness dataset inspired by domain adaptation,2022,ICML,"['Evgenia Rusak', 'Steffen Schneider', 'Peter Vincent Gehler', 'Oliver Bringmann', 'Wieland Brendel', 'Matthias Bethge']",poster,"['robustness', 'benchmarking', 'datasets']","We propose a new challenging dataset to benchmark robustness of ImageNet-trained models with respect to domain shifts: ImageNet-D. ImageNet- D has six different domains (“Real”, “Painting”, “Clipart”, “Sketch”, “Infograph” and “Quickdraw”). We show that even state-of-the-art models struggle on this dataset and find that they make well-interpretable errors. For example, our best EfficientNet-L2 model experiences a large performance drop even on the “Real” domain from 11.6% on ImageNet clean to 29.2% on the “Real” domain.",https://api.openreview.net/pdf/479ff4f9dfb692cb7871d3b650a5b027f25bf64b.pdf
The Semantic Shift Benchmark,2022,ICML,"['Sagar Vaze', 'Kai Han', 'Andrea Vedaldi', 'Andrew Zisserman']",poster,"['open-set recognition', 'out-of-distribution detection']","Most benchmarks for detecting semantic distribution shift do not consider how the semantics of the training set are defined. In other words, it is often unclear whether the ‘unseen’ images contain semantically different objects from the same distribution (e.g ‘birds’ for a model trained on ‘cats’ and ‘dogs’) or to a different distribution entirely (e.g Gaussian noise for a model trained on ‘cats’ and ‘dogs’). In this work, we propose ‘open-set’ class splits for models trained on ImageNet-1K which come from ImageNet-21K. Critically, we structure the open-set classes based on semantic similarity to the closed-set using the WordNet hierarchy — we create ‘Easy’ and ‘Hard’ open-set splits to allow more principled analysis of the se- mantic shift phenomenon. Together with similar challenges based on FGVC datasets, these evaluations comprise the ‘Semantic Shift Benchmark’.
",https://api.openreview.net/pdf/888da1827867b0ae3441c909117414754f431aed.pdf
3D Common Corruptions for Object Recognition,2022,ICML,"['Oguzhan Fatih Kar', 'Teresa Yeo', 'Amir Zamir']",poster,"['robustness', 'distribution shifts', 'image corruptions', '3D scene geometry']","We introduce a set of image transformations that can be used as corruptions to evaluate the robustness of models. The primary distinction of the proposed transformations is that, unlike existing approaches such as Common Corruptions, the geometry of the scene is incorporated in the transformations – thus leading to corruptions that are more likely to occur in the real world. We apply these corruptions to the ImageNet validation set to create 3D Common Corruptions (ImageNet-3DCC) benchmark. The evaluations on recent ImageNet models with robustness mechanisms show that ImageNet-3DCC is a challenging benchmark for object recognition task. Furthermore, it exposes vulnerabilities that are not captured by Common Corruptions, which can be informative during model development. ",https://api.openreview.net/pdf/623fec32438eaebf0c31bb9088587168268318a2.pdf
